{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.5490034222602844}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "\n",
    "class PerformanceBenchMark:\n",
    "    def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "    \n",
    "    def compute_accuracy(self):\n",
    "        preds, labels = [], []\n",
    "        for example in self.dataset:\n",
    "            pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
    "            label = example[\"intent\"]\n",
    "            preds.append(intents.str2int(pred))\n",
    "            labels.append(label)\n",
    "        accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
    "        print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "        return accuracy\n",
    "    \n",
    "    def compute_size(self):\n",
    "        state_dict = self.pipeline.model.state_dict()\n",
    "        tmp_path = Path(\"data/model.pt\")\n",
    "        torch.save(state_dict, tmp_path)\n",
    "        size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "        tmp_path.unlink()\n",
    "        print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "        return {\"size_mb\": size_mb}\n",
    "\n",
    "    def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
    "        latencies = []\n",
    "        for _ in range(10):\n",
    "            _ = self.pipeline(query)\n",
    "        for _ in range(100):\n",
    "            start_time = perf_counter()\n",
    "            _ = self.pipeline(query)\n",
    "            latency = perf_counter() - start_time\n",
    "            latencies.append(latency)\n",
    "        \n",
    "        time_avg_ms = 1000 * np.mean(latencies)\n",
    "        time_std_ms = 1000 * np.std(latencies)\n",
    "        print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "        return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.time_pipeline())\n",
    "        #metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset clinc_oos (/home/guhangsong/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/aeddd4060bedd3ac78e70c84f136f930a3827295b4cefb62a3430d007cea91d7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d629488d8b984622b0ae4338e1cc4636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "clinc = load_dataset(\"/home/guhangsong/Data/huggingface/clinc_oos\", \"plus\", ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinc[\"test\"][42]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc[\"test\"].features[\"intent\"]\n",
    "intents.int2str(sample[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy_score = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert.encoder.layer.2.attention.self.value.weight',\n",
       " tensor([[-1.0526e-02, -3.2215e-02,  2.2097e-02,  ..., -6.0953e-03,\n",
       "           4.6521e-03,  2.9844e-02],\n",
       "         [-1.4964e-02, -1.0915e-02,  5.2396e-04,  ...,  3.2047e-05,\n",
       "          -2.6890e-02, -2.1943e-02],\n",
       "         [-2.9640e-02, -3.7842e-03, -1.2582e-02,  ..., -1.0917e-02,\n",
       "           3.1152e-02, -9.7786e-03],\n",
       "         ...,\n",
       "         [-1.5116e-02, -3.3226e-02,  4.2063e-02,  ..., -5.2652e-03,\n",
       "           1.1093e-02,  2.9703e-03],\n",
       "         [-3.6809e-02,  5.6848e-02, -2.6544e-02,  ..., -4.0114e-02,\n",
       "           6.7487e-03,  1.0511e-03],\n",
       "         [-2.4961e-02,  1.4747e-03, -5.4271e-02,  ...,  2.0004e-02,\n",
       "           2.3981e-02, -4.2880e-02]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipe.model.state_dict().items())[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency (ms) - 115.146\n",
      "Latency (ms) - 28.346\n",
      "Latency (ms) - 16.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/pipelines/base.py:1036: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "for _ in range(3):\n",
    "    start_time = perf_counter()\n",
    "    _ = pipe(query)\n",
    "    latency = perf_counter() - start_time\n",
    "    print(f\"Latency (ms) - {1000 * latency:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 418.17\n",
      "Average latency (ms) - 6.40 +\\- 0.93\n",
      "Accuracy on test set - 0.867\n"
     ]
    }
   ],
   "source": [
    "pb = PerformanceBenchMark(pipe, clinc[\"test\"])\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sample[\"text\"])[0][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs_stu = model(**inputs)\n",
    "        loss_ce = outputs_stu.loss\n",
    "        logits_stu = outputs_stu.logits\n",
    "        with torch.no_grad():\n",
    "            outputs_tea = self.teacher_model(**inputs)\n",
    "            logits_tea = outputs_tea.logits\n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "            F.log_softmax(logits_stu / self.args.temperature, dim=-1),\n",
    "            F.softmax(logits_tea / self.args.temperature, dim=-1))\n",
    "        loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "        return (loss, outputs_stu) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_text at 0x7f2338ddf550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb65cf13e7a4464a2d5c5885894aecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999b0ec971224e07a610b7056e1768db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2c4973fb6b4d02b4e580fb7a06ed50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "student_ckpt = \"distilbert-base-uncased\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)\n",
    "\n",
    "def tokenize_text(batch):\n",
    "    return student_tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"])\n",
    "clinc_enc = clinc_enc.rename_column(\"intent\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_score.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "batch_size = 48\n",
    "\n",
    "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=f\"data/{finetuned_ckpt}\", evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=5, learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, alpha=1,\n",
    "    report_to=\"none\", weight_decay=0.01, save_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "num_labels = intents.num_classes\n",
    "student_config = (AutoConfig.from_pretrained(student_ckpt, num_labels=num_labels,id2label=id2label, label2id=label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def student_init():\n",
    "    return (AutoModelForSequenceClassification\n",
    "            .from_pretrained(student_ckpt, config=student_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = (AutoModelForSequenceClassification\n",
    "                .from_pretrained(bert_ckpt, num_labels=num_labels)\n",
    "                .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.290131</td>\n",
       "      <td>0.734516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.792600</td>\n",
       "      <td>1.881477</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.792600</td>\n",
       "      <td>1.172134</td>\n",
       "      <td>0.887097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.707500</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.908387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.920900</td>\n",
       "      <td>0.785922</td>\n",
       "      <td>0.914194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1590, training_loss=2.0637315906068814, metrics={'train_runtime': 97.4859, 'train_samples_per_second': 782.164, 'train_steps_per_second': 16.31, 'total_flos': 413896353421488.0, 'train_loss': 2.0637315906068814, 'epoch': 5.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer = DistillationTrainer(model_init=student_init,\n",
    "    teacher_model=teacher_model, args=student_training_args,\n",
    "    train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
    "    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_ckpt = \"data/distilbert-base-uncased-finetuned-clinc/checkpoint-1590\"\n",
    "pipe = pipeline(\"text-classification\", model=finetuned_ckpt, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/pipelines/base.py:1036: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 4.16 +\\- 2.25\n",
      "Accuracy on test set - 0.858\n"
     ]
    }
   ],
   "source": [
    "optim_type = \"DistillBERT\"\n",
    "pb = PerformanceBenchMark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(perf_metrics, current_optim_type):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        if idx == current_optim_type:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "                        alpha=0.5, s=df_opt[\"size_mb\"], label=idx,\n",
    "                        marker='$\\u25CC$')\n",
    "        else:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100,\n",
    "                        s =df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
    "    \n",
    "    legend = plt.legend(bbox_to_anchor=(1,1))\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_sizes([20])\n",
    "    \n",
    "    plt.ylim(80, 90)\n",
    "    xlim = int(perf_metrics[\"BERT baseline\"][\"time_avg_ms\"] + 3)\n",
    "    plt.xlim(1, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency (ms)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -2, 2)\n",
    "    y = trial.suggest_float(\"y\", -2, 2)\n",
    "    return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-25 09:07:47,174]\u001b[0m A new study created in memory with name: no-name-356c6d5d-0999-4525-8a44-865b29f8a5a8\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,177]\u001b[0m Trial 0 finished with value: 314.07050804721297 and parameters: {'x': 0.3536048565848433, 'y': -1.6459878326923456}. Best is trial 0 with value: 314.07050804721297.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,178]\u001b[0m Trial 1 finished with value: 330.0221454264095 and parameters: {'x': 1.3036196737958519, 'y': -0.11697317099723747}. Best is trial 0 with value: 314.07050804721297.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,179]\u001b[0m Trial 2 finished with value: 207.60916132739618 and parameters: {'x': -0.5891121228297385, 'y': -1.0850219186966044}. Best is trial 2 with value: 207.60916132739618.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,180]\u001b[0m Trial 3 finished with value: 266.15800981636573 and parameters: {'x': 0.009497800022193914, 'y': 1.6285155678954282}. Best is trial 2 with value: 207.60916132739618.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,181]\u001b[0m Trial 4 finished with value: 893.1457044352705 and parameters: {'x': 1.1502079970047423, 'y': -1.6655381555041657}. Best is trial 2 with value: 207.60916132739618.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,182]\u001b[0m Trial 5 finished with value: 8.874939326066908 and parameters: {'x': 0.8422984783184333, 'y': 0.4119760619151722}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,182]\u001b[0m Trial 6 finished with value: 9.57569200316043 and parameters: {'x': 1.259456838237003, 'y': 1.8945880442946366}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,183]\u001b[0m Trial 7 finished with value: 95.42784507492145 and parameters: {'x': -0.10263924345878239, 'y': 0.9811636402333601}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,184]\u001b[0m Trial 8 finished with value: 626.7965055741034 and parameters: {'x': -0.7879650815625876, 'y': -1.8763088326582422}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,184]\u001b[0m Trial 9 finished with value: 72.6013043906643 and parameters: {'x': 0.8994326247136324, 'y': -0.043025593222457914}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,191]\u001b[0m Trial 10 finished with value: 894.8467270322931 and parameters: {'x': -1.9452547323868508, 'y': 0.8071515134156801}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,196]\u001b[0m Trial 11 finished with value: 346.11008868408067 and parameters: {'x': 1.9615267908005682, 'y': 1.9896703590326263}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,202]\u001b[0m Trial 12 finished with value: 258.9927764043105 and parameters: {'x': 1.5648717305590354, 'y': 0.8404899348331003}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,208]\u001b[0m Trial 13 finished with value: 116.16139344415596 and parameters: {'x': 0.6090331135075404, 'y': -0.7061512655870672}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,215]\u001b[0m Trial 14 finished with value: 295.7671547970203 and parameters: {'x': 1.8016666570337267, 'y': 1.5280839866410985}. Best is trial 5 with value: 8.874939326066908.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,219]\u001b[0m Trial 15 finished with value: 1.7368962459641375 and parameters: {'x': 0.8348388238254971, 'y': 0.5662034991930844}. Best is trial 15 with value: 1.7368962459641375.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,225]\u001b[0m Trial 16 finished with value: 1.302030026430662 and parameters: {'x': 0.5523504721941046, 'y': 0.41005008027028916}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,229]\u001b[0m Trial 17 finished with value: 9.542972700931644 and parameters: {'x': 0.09734357876966876, 'y': 0.304910775097218}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,235]\u001b[0m Trial 18 finished with value: 45.31167058723226 and parameters: {'x': -0.5377675761804893, 'y': -0.3661451940542029}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,242]\u001b[0m Trial 19 finished with value: 9.349242295481606 and parameters: {'x': -1.1777949604583995, 'y': 1.172574516511426}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,249]\u001b[0m Trial 20 finished with value: 3.7831794461452986 and parameters: {'x': 0.4818513240405003, 'y': 0.41965606741499073}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,255]\u001b[0m Trial 21 finished with value: 3.7081833031327274 and parameters: {'x': 0.5162489072533326, 'y': 0.4529041406690809}. Best is trial 16 with value: 1.302030026430662.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,260]\u001b[0m Trial 22 finished with value: 0.5168527901205356 and parameters: {'x': 0.7969631736984069, 'y': 0.5661844509083183}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,266]\u001b[0m Trial 23 finished with value: 18.760778681446354 and parameters: {'x': 0.8921995905139204, 'y': 1.2290230856674234}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,272]\u001b[0m Trial 24 finished with value: 33.55163500652528 and parameters: {'x': -0.1976136504120003, 'y': -0.527670615979696}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,278]\u001b[0m Trial 25 finished with value: 439.86450079757014 and parameters: {'x': 1.4982962864558615, 'y': 0.1481891087719347}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,282]\u001b[0m Trial 26 finished with value: 35.33803519863058 and parameters: {'x': 0.3082232572121888, 'y': 0.6854207505751355}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,285]\u001b[0m Trial 27 finished with value: 73.29340228741677 and parameters: {'x': 0.7816235852365047, 'y': -0.24490167015637396}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,290]\u001b[0m Trial 28 finished with value: 358.9490383166225 and parameters: {'x': 0.9935519875237873, 'y': -0.9074493830004215}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,296]\u001b[0m Trial 29 finished with value: 32.86119480040241 and parameters: {'x': 0.2094583207846561, 'y': 0.6116424479008834}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,300]\u001b[0m Trial 30 finished with value: 1.9312033493710865 and parameters: {'x': -0.26569512011119256, 'y': 0.1279715242241029}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,304]\u001b[0m Trial 31 finished with value: 1.8081037320325386 and parameters: {'x': -0.32590840461761983, 'y': 0.12859275677721216}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,308]\u001b[0m Trial 32 finished with value: 125.30063737990814 and parameters: {'x': -1.070626284135591, 'y': 0.04618089567101427}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,313]\u001b[0m Trial 33 finished with value: 94.0679281513711 and parameters: {'x': 0.3357835439942277, 'y': 1.0803597277444705}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,319]\u001b[0m Trial 34 finished with value: 37.462498422764 and parameters: {'x': 0.6579583641702902, 'y': -0.17820048609873124}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,324]\u001b[0m Trial 35 finished with value: 153.93767200901817 and parameters: {'x': -0.3767897695337997, 'y': 1.3750241462082213}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,329]\u001b[0m Trial 36 finished with value: 267.4024069092216 and parameters: {'x': 1.4832616673070722, 'y': 0.5655350728168815}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,333]\u001b[0m Trial 37 finished with value: 116.418870929931 and parameters: {'x': 1.1473247730302631, 'y': 0.23747895045635914}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,339]\u001b[0m Trial 38 finished with value: 93.13508542691214 and parameters: {'x': 0.017444039954272295, 'y': 0.9603546536897505}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,343]\u001b[0m Trial 39 finished with value: 304.03335042700587 and parameters: {'x': -0.7005521330770621, 'y': -1.2445695362666207}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,347]\u001b[0m Trial 40 finished with value: 225.14557253651517 and parameters: {'x': 1.035902321562825, 'y': -0.42738724830210495}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,353]\u001b[0m Trial 41 finished with value: 47.75892800838515 and parameters: {'x': -0.8745032108716086, 'y': 0.09958546870220258}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,357]\u001b[0m Trial 42 finished with value: 6.249219346072726 and parameters: {'x': -0.24494619110986787, 'y': 0.27677797889716416}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,361]\u001b[0m Trial 43 finished with value: 2.067926420819189 and parameters: {'x': 0.14733488970201203, 'y': -0.09408917593455446}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,365]\u001b[0m Trial 44 finished with value: 39.49586208278646 and parameters: {'x': -0.3745264068399913, 'y': 0.7535117373928368}. Best is trial 22 with value: 0.5168527901205356.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,371]\u001b[0m Trial 45 finished with value: 0.12724655347201852 and parameters: {'x': 0.6848848853474268, 'y': 0.452349346376738}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,376]\u001b[0m Trial 46 finished with value: 162.20725251731253 and parameters: {'x': 1.302832884924407, 'y': 0.42412749812157197}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,383]\u001b[0m Trial 47 finished with value: 23.050732204410455 and parameters: {'x': 0.6499618432651124, 'y': 0.9012844555247947}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,387]\u001b[0m Trial 48 finished with value: 17.16476400308223 and parameters: {'x': 0.4299541985610375, 'y': 0.5952240101966254}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,393]\u001b[0m Trial 49 finished with value: 7.333999009708846 and parameters: {'x': 0.7024047786638438, 'y': 0.7625459504969716}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,398]\u001b[0m Trial 50 finished with value: 308.71281516722905 and parameters: {'x': -0.04586035423342194, 'y': 1.7560102143439997}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,403]\u001b[0m Trial 51 finished with value: 438.4662833709537 and parameters: {'x': -1.4495995609012158, 'y': 0.021757810492656182}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,407]\u001b[0m Trial 52 finished with value: 93.49578323274523 and parameters: {'x': 1.1157761429799886, 'y': 0.27809354066036346}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,412]\u001b[0m Trial 53 finished with value: 10.887454339676605 and parameters: {'x': -0.4711149755367172, 'y': 0.5173012300795399}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,418]\u001b[0m Trial 54 finished with value: 32.31022337856233 and parameters: {'x': 0.8665157297759726, 'y': 0.18258543992394627}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,422]\u001b[0m Trial 55 finished with value: 30.54702318955667 and parameters: {'x': 0.5401995617209128, 'y': -0.25896212684220776}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,427]\u001b[0m Trial 56 finished with value: 9.804202365324613 and parameters: {'x': 0.24424138271319168, 'y': 0.3635128874143701}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,433]\u001b[0m Trial 57 finished with value: 1.1951714277277612 and parameters: {'x': -0.08020028221403863, 'y': -0.010402040202343643}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,438]\u001b[0m Trial 58 finished with value: 7.6611980982189785 and parameters: {'x': 0.41072732727701616, 'y': -0.10174632498434594}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,443]\u001b[0m Trial 59 finished with value: 26.18740641164821 and parameters: {'x': -0.0848787783353202, 'y': 0.5073088405849839}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,447]\u001b[0m Trial 60 finished with value: 1222.158866475716 and parameters: {'x': 1.6900230245345975, 'y': -0.6390800135291068}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,452]\u001b[0m Trial 61 finished with value: 1.648334012220459 and parameters: {'x': 0.09235768755584994, 'y': 0.09933299553157615}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,458]\u001b[0m Trial 62 finished with value: 0.8914927317565097 and parameters: {'x': 0.09722438398878225, 'y': -0.01820404926582156}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,463]\u001b[0m Trial 63 finished with value: 1.038251395501822 and parameters: {'x': 0.05104199010073229, 'y': -0.03450672017081857}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,469]\u001b[0m Trial 64 finished with value: 1.949734672816007 and parameters: {'x': 0.0910180616759901, 'y': -0.09771035894642181}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,473]\u001b[0m Trial 65 finished with value: 10.322082143499426 and parameters: {'x': 0.186841291893399, 'y': -0.27590949223268246}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,478]\u001b[0m Trial 66 finished with value: 23.61951313387561 and parameters: {'x': -0.1786380028668485, 'y': -0.43957892610540916}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,482]\u001b[0m Trial 67 finished with value: 0.8988486356464412 and parameters: {'x': 0.05257551717688306, 'y': 0.006279131654362502}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,487]\u001b[0m Trial 68 finished with value: 7.772184846750817 and parameters: {'x': 0.31164302214853745, 'y': 0.36727594970583805}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,493]\u001b[0m Trial 69 finished with value: 87.99518020776057 and parameters: {'x': 0.771207233445791, 'y': -0.3430178101565322}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,498]\u001b[0m Trial 70 finished with value: 8.298559970977237 and parameters: {'x': 0.5304100172869138, 'y': -0.0028842350770187193}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,504]\u001b[0m Trial 71 finished with value: 5.441898920739123 and parameters: {'x': 0.018202028038056747, 'y': 0.21194349832716342}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,511]\u001b[0m Trial 72 finished with value: 3.6214673641358335 and parameters: {'x': 0.06983532751162055, 'y': -0.161142936867196}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,516]\u001b[0m Trial 73 finished with value: 1.8922670371897194 and parameters: {'x': 0.36821002922551294, 'y': 0.01338580791112523}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,520]\u001b[0m Trial 74 finished with value: 40.35571825167935 and parameters: {'x': -0.14052759340521706, 'y': 0.6446873220452581}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,525]\u001b[0m Trial 75 finished with value: 46.03296868535332 and parameters: {'x': 0.9978119355718296, 'y': 0.3171526908994973}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,530]\u001b[0m Trial 76 finished with value: 40.551546364693614 and parameters: {'x': 0.243541279002242, 'y': -0.5729796394256723}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,537]\u001b[0m Trial 77 finished with value: 128.22474059863742 and parameters: {'x': -0.6007452071739352, 'y': -0.760097414497741}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,544]\u001b[0m Trial 78 finished with value: 8.798539420635366 and parameters: {'x': 0.5937220106118261, 'y': 0.058678025703038816}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,548]\u001b[0m Trial 79 finished with value: 4.478491161588675 and parameters: {'x': -0.031025253796591677, 'y': 0.18577268751433879}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,553]\u001b[0m Trial 80 finished with value: 1.1269538414937144 and parameters: {'x': 0.7355983014061397, 'y': 0.4382921388969129}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,558]\u001b[0m Trial 81 finished with value: 3.0039350983421116 and parameters: {'x': 0.7525037661140356, 'y': 0.3947194826665801}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,562]\u001b[0m Trial 82 finished with value: 23.513142678643135 and parameters: {'x': 0.496999559464065, 'y': 0.7292961654673764}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,567]\u001b[0m Trial 83 finished with value: 15.90941481019796 and parameters: {'x': 0.9436415681304837, 'y': 0.4916331494698775}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,572]\u001b[0m Trial 84 finished with value: 391.84249110052605 and parameters: {'x': 0.15991159067450433, 'y': -1.952146014708634}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,579]\u001b[0m Trial 85 finished with value: 2.2818497124134063 and parameters: {'x': 0.28740329691440847, 'y': -0.05059302537210073}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,585]\u001b[0m Trial 86 finished with value: 0.5080318293355794 and parameters: {'x': 0.43547434689502657, 'y': 0.1461243897862928}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,591]\u001b[0m Trial 87 finished with value: 15.477862009036967 and parameters: {'x': 0.4245685801278344, 'y': -0.20892965894899773}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,597]\u001b[0m Trial 88 finished with value: 25.010038372614186 and parameters: {'x': 0.6150924985959165, 'y': 0.8769557148344267}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,603]\u001b[0m Trial 89 finished with value: 14.2166111393848 and parameters: {'x': 0.8359577262437843, 'y': 1.0755175189745618}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,609]\u001b[0m Trial 90 finished with value: 284.16223947995326 and parameters: {'x': 1.402449268600682, 'y': 0.28163318322179465}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,613]\u001b[0m Trial 91 finished with value: 1.6970781349218493 and parameters: {'x': -0.27449008406101183, 'y': 0.10231760005046708}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,618]\u001b[0m Trial 92 finished with value: 168.71728059828305 and parameters: {'x': 1.2114421635106987, 'y': 0.16885206144146947}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,623]\u001b[0m Trial 93 finished with value: 0.8429556898169772 and parameters: {'x': 0.7086052586990845, 'y': 0.4150556447239815}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,627]\u001b[0m Trial 94 finished with value: 0.616960449816952 and parameters: {'x': 0.682001887694003, 'y': 0.5369484134459139}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,634]\u001b[0m Trial 95 finished with value: 2.967752087243528 and parameters: {'x': 0.7141924700722402, 'y': 0.6799551432337847}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,640]\u001b[0m Trial 96 finished with value: 36.02153721715958 and parameters: {'x': 1.0781848092863704, 'y': 0.5623539604679457}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,645]\u001b[0m Trial 97 finished with value: 10.553762341747596 and parameters: {'x': 0.8741679275454459, 'y': 0.43954780670830096}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,650]\u001b[0m Trial 98 finished with value: 38.38185551385182 and parameters: {'x': 0.47045198959193324, 'y': 0.8385886682740351}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,654]\u001b[0m Trial 99 finished with value: 2.447479996716752 and parameters: {'x': 0.6541358429201078, 'y': 0.27532050604807295}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,658]\u001b[0m Trial 100 finished with value: 25.795057821563297 and parameters: {'x': 0.38626819040535443, 'y': -0.35496343581054063}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,662]\u001b[0m Trial 101 finished with value: 0.47275300373494555 and parameters: {'x': 0.5540953201019281, 'y': 0.3593591839025966}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,667]\u001b[0m Trial 102 finished with value: 20.09037918204962 and parameters: {'x': 0.9648745356908119, 'y': 0.4827737065789269}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,672]\u001b[0m Trial 103 finished with value: 0.6462848435769188 and parameters: {'x': 0.8353919250203987, 'y': 0.6191911034494928}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,677]\u001b[0m Trial 104 finished with value: 0.40541721575031536 and parameters: {'x': 0.7990169515406714, 'y': 0.5780109530365412}. Best is trial 45 with value: 0.12724655347201852.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,681]\u001b[0m Trial 105 finished with value: 0.05376542412802747 and parameters: {'x': 0.8093132491127175, 'y': 0.6417955179870363}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,686]\u001b[0m Trial 106 finished with value: 46.72366882707451 and parameters: {'x': 0.5800712925528139, 'y': 1.0187387319565573}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,690]\u001b[0m Trial 107 finished with value: 2.8238887655308136 and parameters: {'x': 0.7789132218930319, 'y': 0.7732894019325712}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,696]\u001b[0m Trial 108 finished with value: 0.375952162508521 and parameters: {'x': 0.9294936755021018, 'y': 0.9248667041261346}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,701]\u001b[0m Trial 109 finished with value: 65.30061428468265 and parameters: {'x': 1.1928579442786327, 'y': 0.6150522901079519}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,705]\u001b[0m Trial 110 finished with value: 0.7319221812018901 and parameters: {'x': 1.056781162192275, 'y': 1.202150239160368}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,711]\u001b[0m Trial 111 finished with value: 23.239462116916474 and parameters: {'x': 0.8991665479754284, 'y': 1.2904682675965853}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,715]\u001b[0m Trial 112 finished with value: 48.26750931235671 and parameters: {'x': 0.8291858144629882, 'y': 1.382087319949223}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,720]\u001b[0m Trial 113 finished with value: 1.9077499298113623 and parameters: {'x': 1.0523807343441633, 'y': 0.9694832484155096}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,725]\u001b[0m Trial 114 finished with value: 27.686102139594205 and parameters: {'x': 1.2981173508947932, 'y': 1.159778016195299}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,730]\u001b[0m Trial 115 finished with value: 6.474959577405969 and parameters: {'x': 0.6745317944440947, 'y': 0.7073625143541372}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,735]\u001b[0m Trial 116 finished with value: 0.08095823803279066 and parameters: {'x': 0.9372907924862796, 'y': 0.9062675507761309}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,741]\u001b[0m Trial 117 finished with value: 13.339232562015313 and parameters: {'x': 0.9542775678928581, 'y': 0.545445156030518}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,746]\u001b[0m Trial 118 finished with value: 10.898645145495854 and parameters: {'x': 1.1122728977839338, 'y': 0.907211005480381}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,752]\u001b[0m Trial 119 finished with value: 121.3074612380415 and parameters: {'x': 1.3901627867657034, 'y': 0.8318471897027083}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,757]\u001b[0m Trial 120 finished with value: 0.09514272452755315 and parameters: {'x': 0.8154224403607134, 'y': 0.640200632401385}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,762]\u001b[0m Trial 121 finished with value: 0.27413366960983776 and parameters: {'x': 0.8008198498217712, 'y': 0.5928912652794768}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,766]\u001b[0m Trial 122 finished with value: 16.995032188212207 and parameters: {'x': 1.0302135157058103, 'y': 0.6491006451277749}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,771]\u001b[0m Trial 123 finished with value: 17.065780840570795 and parameters: {'x': 0.8492388317631653, 'y': 1.1340389069198404}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,776]\u001b[0m Trial 124 finished with value: 1.9738639451519109 and parameters: {'x': 0.8048255926257467, 'y': 0.7868762184979616}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,783]\u001b[0m Trial 125 finished with value: 15.79480379540843 and parameters: {'x': 0.9311342335534265, 'y': 1.2643780619694378}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,790]\u001b[0m Trial 126 finished with value: 3.652697702708578 and parameters: {'x': 1.1666190630166902, 'y': 1.5513926796102515}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,795]\u001b[0m Trial 127 finished with value: 5.7168291428707905 and parameters: {'x': 0.5936620199278448, 'y': 0.5880554458857333}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,800]\u001b[0m Trial 128 finished with value: 0.8859154742651284 and parameters: {'x': 1.0165510887392304, 'y': 0.9392675863436339}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,806]\u001b[0m Trial 129 finished with value: 1133.279959600106 and parameters: {'x': -1.9229052796324213, 'y': 0.34385544807897117}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,812]\u001b[0m Trial 130 finished with value: 20.31759302838525 and parameters: {'x': 0.7802171503933502, 'y': 1.0589530677280736}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,817]\u001b[0m Trial 131 finished with value: 4.199408343860942 and parameters: {'x': 0.6931248319466723, 'y': 0.6830358519107577}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,822]\u001b[0m Trial 132 finished with value: 6.046084734073418 and parameters: {'x': 0.5256782505356594, 'y': 0.5176072567341173}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,828]\u001b[0m Trial 133 finished with value: 0.9455369470448309 and parameters: {'x': 0.7270121536453628, 'y': 0.4352185095181921}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,834]\u001b[0m Trial 134 finished with value: 5.491934390845377 and parameters: {'x': 0.9204971063647015, 'y': 0.6131010530240838}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,841]\u001b[0m Trial 135 finished with value: 0.4472990273853019 and parameters: {'x': 0.6549475878858543, 'y': 0.3716642962846678}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,848]\u001b[0m Trial 136 finished with value: 336.067715563533 and parameters: {'x': 0.6216420627534838, 'y': -1.4463856350530535}. Best is trial 105 with value: 0.05376542412802747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,853]\u001b[0m Trial 137 finished with value: 0.04717249421718482 and parameters: {'x': 0.8564601518734145, 'y': 0.7172240511897843}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,858]\u001b[0m Trial 138 finished with value: 0.3333067892004269 and parameters: {'x': 0.8294189054516083, 'y': 0.7430908546051698}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,863]\u001b[0m Trial 139 finished with value: 26.360997971082725 and parameters: {'x': 0.5047294527459062, 'y': 0.7657870937733381}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,868]\u001b[0m Trial 140 finished with value: 22.68396386697897 and parameters: {'x': 0.9047141207277677, 'y': 0.3423261153171131}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,873]\u001b[0m Trial 141 finished with value: 3.0073554529182216 and parameters: {'x': 0.8183886116771876, 'y': 0.8422236189917659}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,880]\u001b[0m Trial 142 finished with value: 8.055907949611532 and parameters: {'x': 0.6477969608850339, 'y': 0.7012764998708894}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,885]\u001b[0m Trial 143 finished with value: 0.2596957578720232 and parameters: {'x': 0.7669585975577405, 'y': 0.5429057967875973}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,890]\u001b[0m Trial 144 finished with value: 0.06761651438222047 and parameters: {'x': 0.7482059735725685, 'y': 0.5533188880154862}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,895]\u001b[0m Trial 145 finished with value: 0.9550044191140672 and parameters: {'x': 0.7527938726575361, 'y': 0.4721526708676228}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,900]\u001b[0m Trial 146 finished with value: 6.146336954474851 and parameters: {'x': 0.989140663907019, 'y': 0.7304835610889953}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,905]\u001b[0m Trial 147 finished with value: 1.3623581764584074 and parameters: {'x': 0.5909275007021417, 'y': 0.23987843833641626}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,910]\u001b[0m Trial 148 finished with value: 3.7275473521000557 and parameters: {'x': 0.8795271330784997, 'y': 0.9662603139541932}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,915]\u001b[0m Trial 149 finished with value: 1.1638874152397685 and parameters: {'x': 0.7952720453981865, 'y': 0.5265343577450605}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,920]\u001b[0m Trial 150 finished with value: 40.558677812825024 and parameters: {'x': 0.43105188880061146, 'y': 0.8201161899955058}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,926]\u001b[0m Trial 151 finished with value: 2.3682864770919934 and parameters: {'x': 0.6571699799010883, 'y': 0.5818975155246633}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,935]\u001b[0m Trial 152 finished with value: 0.08384387474491109 and parameters: {'x': 0.7109438751150413, 'y': 0.5071453983969441}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,942]\u001b[0m Trial 153 finished with value: 1.803305934733267 and parameters: {'x': 0.7345690079044478, 'y': 0.40795377859274384}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,951]\u001b[0m Trial 154 finished with value: 5.613957713779488 and parameters: {'x': 0.9514310508879635, 'y': 0.6683329112700127}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,959]\u001b[0m Trial 155 finished with value: 33.896945837228145 and parameters: {'x': 0.5519442427066088, 'y': 0.8851266576569191}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,965]\u001b[0m Trial 156 finished with value: 17.231719125840257 and parameters: {'x': 0.8694771197747655, 'y': 0.34108465438587177}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,971]\u001b[0m Trial 157 finished with value: 1.2894944280888723 and parameters: {'x': 0.7834109736649858, 'y': 0.5022615187252135}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,980]\u001b[0m Trial 158 finished with value: 25.66836902383209 and parameters: {'x': 1.0693216992704024, 'y': 0.6368567180887261}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,986]\u001b[0m Trial 159 finished with value: 27.769747205342302 and parameters: {'x': 0.4940725026764162, 'y': 0.7686434762646682}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,991]\u001b[0m Trial 160 finished with value: 6.84210756553619 and parameters: {'x': 0.7022977523888642, 'y': 0.23334752983993148}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:47,996]\u001b[0m Trial 161 finished with value: 1.284945547394112 and parameters: {'x': 0.671391543309581, 'y': 0.5592544852985114}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,002]\u001b[0m Trial 162 finished with value: 9.50727260472921 and parameters: {'x': 0.8720482820663163, 'y': 0.4523951473449662}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,008]\u001b[0m Trial 163 finished with value: 4.613463095365906 and parameters: {'x': 0.5794262025935789, 'y': 0.5463666490948805}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,013]\u001b[0m Trial 164 finished with value: 34.716359829306704 and parameters: {'x': 0.975381373485138, 'y': 0.3621680620947989}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,019]\u001b[0m Trial 165 finished with value: 0.680923600167028 and parameters: {'x': 0.7896651218185542, 'y': 0.7033634127259691}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,025]\u001b[0m Trial 166 finished with value: 1.9657354717466713 and parameters: {'x': 0.7111541203405205, 'y': 0.642937250249398}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,031]\u001b[0m Trial 167 finished with value: 65.78060191920879 and parameters: {'x': 1.1329461136180856, 'y': 0.4726234504298556}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,039]\u001b[0m Trial 168 finished with value: 1.5734839904540947 and parameters: {'x': 0.6378964032781662, 'y': 0.28681332108748253}. Best is trial 137 with value: 0.04717249421718482.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,044]\u001b[0m Trial 169 finished with value: 0.03293340235777065 and parameters: {'x': 0.8926837103237575, 'y': 0.7822497895971319}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,051]\u001b[0m Trial 170 finished with value: 0.03808242275577211 and parameters: {'x': 0.91819896191929, 'y': 0.8608068427848534}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,057]\u001b[0m Trial 171 finished with value: 0.18913944909458652 and parameters: {'x': 0.9632779325544102, 'y': 0.8845695234534968}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,062]\u001b[0m Trial 172 finished with value: 1.4657005838807609 and parameters: {'x': 0.9416868116208171, 'y': 1.0076996545878742}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,067]\u001b[0m Trial 173 finished with value: 3.858751497352999 and parameters: {'x': 0.8461230411691938, 'y': 0.9117576345847436}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,073]\u001b[0m Trial 174 finished with value: 5.4500426838399205 and parameters: {'x': 1.0269271662637491, 'y': 0.8211416698241185}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,078]\u001b[0m Trial 175 finished with value: 0.7043986793631802 and parameters: {'x': 0.9168476518575556, 'y': 0.757094087240958}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,086]\u001b[0m Trial 176 finished with value: 1.4431398733800638 and parameters: {'x': 1.0984990806207415, 'y': 1.0869739671537468}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,091]\u001b[0m Trial 177 finished with value: 8.425835747624461 and parameters: {'x': 0.7730718662254458, 'y': 0.8870246187412608}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,097]\u001b[0m Trial 178 finished with value: 0.0781429829338535 and parameters: {'x': 0.9834568221240301, 'y': 0.9950923933168409}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,104]\u001b[0m Trial 179 finished with value: 31.334789654824082 and parameters: {'x': 1.214096885839613, 'y': 0.9146659634558666}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,109]\u001b[0m Trial 180 finished with value: 0.7727532648322502 and parameters: {'x': 0.9839459861595392, 'y': 1.0560414287434274}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,115]\u001b[0m Trial 181 finished with value: 0.176335441459197 and parameters: {'x': 0.8607252192681186, 'y': 0.7804633012155952}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,123]\u001b[0m Trial 182 finished with value: 0.053465114612683294 and parameters: {'x': 0.875211962838251, 'y': 0.7854621198294394}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,129]\u001b[0m Trial 183 finished with value: 5.1106943656431305 and parameters: {'x': 0.8767988707610593, 'y': 0.9945087529405926}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,133]\u001b[0m Trial 184 finished with value: 7.2344440453538725 and parameters: {'x': 1.031843778869158, 'y': 0.7957512164675091}. Best is trial 169 with value: 0.03293340235777065.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,140]\u001b[0m Trial 185 finished with value: 0.02858925121764372 and parameters: {'x': 0.8509589111137057, 'y': 0.7321160574715879}. Best is trial 185 with value: 0.02858925121764372.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,148]\u001b[0m Trial 186 finished with value: 2.4594133172654056 and parameters: {'x': 0.9335740478587138, 'y': 0.714876077631408}. Best is trial 185 with value: 0.02858925121764372.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,154]\u001b[0m Trial 187 finished with value: 21.648533051672757 and parameters: {'x': 1.1415176116981973, 'y': 0.8379978836207121}. Best is trial 185 with value: 0.02858925121764372.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,160]\u001b[0m Trial 188 finished with value: 0.4605452313629547 and parameters: {'x': 0.8322141024550588, 'y': 0.7583369183770944}. Best is trial 185 with value: 0.02858925121764372.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,165]\u001b[0m Trial 189 finished with value: 0.006383026670268596 and parameters: {'x': 0.9903679023234816, 'y': 0.988759691184378}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,170]\u001b[0m Trial 190 finished with value: 43.36391614357531 and parameters: {'x': 1.276965203966121, 'y': 0.9727099958843629}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,176]\u001b[0m Trial 191 finished with value: 978.1282228590364 and parameters: {'x': 1.998610392085018, 'y': 0.8685340314611542}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,182]\u001b[0m Trial 192 finished with value: 6.986446189321734 and parameters: {'x': 0.9655018676058932, 'y': 0.6678975062397813}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,189]\u001b[0m Trial 193 finished with value: 14.319958358522605 and parameters: {'x': 0.8644671531922007, 'y': 1.1254778791032507}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,195]\u001b[0m Trial 194 finished with value: 3.5475096488243483 and parameters: {'x': 1.0647915596566675, 'y': 0.9455442013629163}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,201]\u001b[0m Trial 195 finished with value: 3.2284480755084175 and parameters: {'x': 0.7977608375952963, 'y': 0.8149593920824381}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,207]\u001b[0m Trial 196 finished with value: 4.9501105816859585 and parameters: {'x': 0.9301337906369819, 'y': 0.6427701533504886}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,212]\u001b[0m Trial 197 finished with value: 0.018922614943242665 and parameters: {'x': 1.0115826554493244, 'y': 1.0370065680745282}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,216]\u001b[0m Trial 198 finished with value: 0.00939396990544629 and parameters: {'x': 1.0070660191322673, 'y': 1.0238484250215145}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,222]\u001b[0m Trial 199 finished with value: 4.171345422966101 and parameters: {'x': 1.1132075638251446, 'y': 1.0353063521214345}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,228]\u001b[0m Trial 200 finished with value: 3.2579649237199653 and parameters: {'x': 1.01484331552138, 'y': 1.210399187570087}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,233]\u001b[0m Trial 201 finished with value: 0.12044403165577117 and parameters: {'x': 0.9894533769187264, 'y': 0.9443289666033637}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,238]\u001b[0m Trial 202 finished with value: 19.379999571968376 and parameters: {'x': 1.2004952629094645, 'y': 1.0014184677419875}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,244]\u001b[0m Trial 203 finished with value: 1.697438440388822 and parameters: {'x': 0.9994732972124011, 'y': 1.1292326409396747}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,250]\u001b[0m Trial 204 finished with value: 0.45246646112672695 and parameters: {'x': 0.8968117761260106, 'y': 0.8707408022638494}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,257]\u001b[0m Trial 205 finished with value: 0.17690231084752933 and parameters: {'x': 0.8456287922865104, 'y': 0.7542124509624982}. Best is trial 189 with value: 0.006383026670268596.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,262]\u001b[0m Trial 206 finished with value: 0.0008187613312552456 and parameters: {'x': 1.023047781441506, 'y': 1.0449310004465646}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,268]\u001b[0m Trial 207 finished with value: 0.7448103324887918 and parameters: {'x': 1.085537937268659, 'y': 1.0925151660484627}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,273]\u001b[0m Trial 208 finished with value: 0.16692686291374448 and parameters: {'x': 0.9942516467178545, 'y': 0.9476836970193614}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,278]\u001b[0m Trial 209 finished with value: 8.855847632312836 and parameters: {'x': 1.033676705552361, 'y': 1.3660562381521197}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,282]\u001b[0m Trial 210 finished with value: 16.32109187518357 and parameters: {'x': 1.1607133480351242, 'y': 0.9435815596991222}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,287]\u001b[0m Trial 211 finished with value: 0.4052451469306879 and parameters: {'x': 0.9881386687533731, 'y': 1.0400658452823122}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,291]\u001b[0m Trial 212 finished with value: 0.9972087328151154 and parameters: {'x': 0.8982373599963898, 'y': 0.9061708349562779}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,296]\u001b[0m Trial 213 finished with value: 447.92359221076526 and parameters: {'x': 1.8188264600458521, 'y': 1.1932937278189275}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,301]\u001b[0m Trial 214 finished with value: 10.362894079915531 and parameters: {'x': 1.077316645651871, 'y': 0.8387895240254671}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,308]\u001b[0m Trial 215 finished with value: 0.26829574623038427 and parameters: {'x': 0.971283752843915, 'y': 0.995109739018903}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,314]\u001b[0m Trial 216 finished with value: 0.43713431526489116 and parameters: {'x': 0.8870000533185439, 'y': 0.8519124232796742}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,320]\u001b[0m Trial 217 finished with value: 3.378030796120205 and parameters: {'x': 0.7631156932891542, 'y': 0.7646068194698322}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,324]\u001b[0m Trial 218 finished with value: 18.937573419910194 and parameters: {'x': 1.2177871900426078, 'y': 1.048377728567611}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,331]\u001b[0m Trial 219 finished with value: 3.5929434985411657 and parameters: {'x': 0.8712499646257928, 'y': 0.9481893488357298}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,337]\u001b[0m Trial 220 finished with value: 6.873278291688114 and parameters: {'x': 0.992606284366028, 'y': 0.7230989000574691}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,343]\u001b[0m Trial 221 finished with value: 0.31873795631032503 and parameters: {'x': 0.9608273900720916, 'y': 0.979510092304892}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,347]\u001b[0m Trial 222 finished with value: 0.6123300513639113 and parameters: {'x': 1.0733812876984699, 'y': 1.0742406985691757}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,352]\u001b[0m Trial 223 finished with value: 0.21419661742427518 and parameters: {'x': 0.9270577660346256, 'y': 0.8137331423689694}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,357]\u001b[0m Trial 224 finished with value: 5.868968790045787 and parameters: {'x': 0.7540092413859337, 'y': 0.8095373496063093}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,362]\u001b[0m Trial 225 finished with value: 0.380189993177869 and parameters: {'x': 0.857310063496215, 'y': 0.6749947487199034}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,368]\u001b[0m Trial 226 finished with value: 0.009553921551934227 and parameters: {'x': 0.9520282997842784, 'y': 0.8978416417368689}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,375]\u001b[0m Trial 227 finished with value: 14.01367733329258 and parameters: {'x': 1.1300134160426174, 'y': 0.9028076955532132}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,381]\u001b[0m Trial 228 finished with value: 6.855773377078403 and parameters: {'x': 1.026893308390233, 'y': 0.7926883603080583}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,386]\u001b[0m Trial 229 finished with value: 0.16234202022110425 and parameters: {'x': 0.929084229387223, 'y': 0.9028602048637169}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,393]\u001b[0m Trial 230 finished with value: 47.885902186104246 and parameters: {'x': 1.353714693199517, 'y': 1.141451666972622}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,398]\u001b[0m Trial 231 finished with value: 0.012807394834629237 and parameters: {'x': 0.9323717324999962, 'y': 0.8783910831995221}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,404]\u001b[0m Trial 232 finished with value: 0.06683697141423818 and parameters: {'x': 0.9507488068785632, 'y': 0.9293026734799626}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,410]\u001b[0m Trial 233 finished with value: 5.872802107973577 and parameters: {'x': 0.856871728031916, 'y': 0.9761447718051321}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,417]\u001b[0m Trial 234 finished with value: 0.03538161860563834 and parameters: {'x': 0.9324177423171935, 'y': 0.8869568363474353}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,424]\u001b[0m Trial 235 finished with value: 3.447631022637995 and parameters: {'x': 1.0511819315959894, 'y': 0.9193760334051848}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,434]\u001b[0m Trial 236 finished with value: 1.8199915041537 and parameters: {'x': 0.9435913510980611, 'y': 1.025153716374292}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,441]\u001b[0m Trial 237 finished with value: 1.2212684008958623 and parameters: {'x': 1.0001793343883265, 'y': 0.8898476893261872}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,447]\u001b[0m Trial 238 finished with value: 1.6714327843718184 and parameters: {'x': 1.111677998585034, 'y': 1.1070273200162382}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,456]\u001b[0m Trial 239 finished with value: 2.1096567684416967 and parameters: {'x': 0.910967622263868, 'y': 0.9748354548008367}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,462]\u001b[0m Trial 240 finished with value: 5.61881306427027 and parameters: {'x': 0.7978516339067362, 'y': 0.8727440512482223}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,471]\u001b[0m Trial 241 finished with value: 0.04453688411340098 and parameters: {'x': 0.8426572734722275, 'y': 0.7241354728417169}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,480]\u001b[0m Trial 242 finished with value: 2.9546379883968656 and parameters: {'x': 0.9261969427948581, 'y': 0.686108686156379}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,487]\u001b[0m Trial 243 finished with value: 9.29725561990367 and parameters: {'x': 0.7233750974002342, 'y': 0.8269281514759461}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,495]\u001b[0m Trial 244 finished with value: 0.14687357563422868 and parameters: {'x': 0.8442337859663825, 'y': 0.7477464621255963}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,503]\u001b[0m Trial 245 finished with value: 0.1649188076845969 and parameters: {'x': 1.0396339106887327, 'y': 1.04042233977051}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,511]\u001b[0m Trial 246 finished with value: 37.70134679291646 and parameters: {'x': 0.8231478709306372, 'y': 1.2913318989522247}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,520]\u001b[0m Trial 247 finished with value: 0.32144290817755133 and parameters: {'x': 1.0656293907529062, 'y': 1.0792511965414415}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,526]\u001b[0m Trial 248 finished with value: 1.8601290780392759 and parameters: {'x': 0.9233371330084522, 'y': 0.7163805434872049}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,532]\u001b[0m Trial 249 finished with value: 26.270751129417498 and parameters: {'x': 0.7185545139613954, 'y': 1.028097294434061}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,537]\u001b[0m Trial 250 finished with value: 15.813230938868909 and parameters: {'x': 1.0155642079344067, 'y': 0.6337151726807592}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,543]\u001b[0m Trial 251 finished with value: 3.359441210280791 and parameters: {'x': 0.8341331232362731, 'y': 0.8783138004795511}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,548]\u001b[0m Trial 252 finished with value: 1.9808282418628542 and parameters: {'x': 1.1349364269359965, 'y': 1.1479871386397007}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,556]\u001b[0m Trial 253 finished with value: 1.0183927820725989 and parameters: {'x': 0.9188407650359642, 'y': 0.7436797855088255}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,562]\u001b[0m Trial 254 finished with value: 11.37864876969988 and parameters: {'x': 0.7929811615401281, 'y': 0.9655058013884967}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,567]\u001b[0m Trial 255 finished with value: 5.089539332287574 and parameters: {'x': 1.0188355855517957, 'y': 0.8124337396832753}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,573]\u001b[0m Trial 256 finished with value: 5.642402184802351 and parameters: {'x': 0.8929125925102595, 'y': 1.0345887990492217}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,580]\u001b[0m Trial 257 finished with value: 0.1996014027192959 and parameters: {'x': 0.9679973113746436, 'y': 0.8924567896402571}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,586]\u001b[0m Trial 258 finished with value: 64.09487643387 and parameters: {'x': 1.1907476243979789, 'y': 0.6175144148884697}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,591]\u001b[0m Trial 259 finished with value: 4.421788361160259 and parameters: {'x': 0.7259201385834094, 'y': 0.7354467040259209}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,597]\u001b[0m Trial 260 finished with value: 24.533511285774548 and parameters: {'x': 0.8375647889319745, 'y': 1.1965615016147069}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,602]\u001b[0m Trial 261 finished with value: 5.353799185838178 and parameters: {'x': 1.076973586507796, 'y': 0.928617392509053}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,609]\u001b[0m Trial 262 finished with value: 1.2866611083481396 and parameters: {'x': 0.9712703516254052, 'y': 0.829971399613226}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,615]\u001b[0m Trial 263 finished with value: 3.691191115058593 and parameters: {'x': 0.9031790746519646, 'y': 1.0076130502136582}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,620]\u001b[0m Trial 264 finished with value: 2.022210473933234 and parameters: {'x': 0.7353541297362923, 'y': 0.6804658821094175}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,626]\u001b[0m Trial 265 finished with value: 13.165859147788458 and parameters: {'x': 0.8441572578403711, 'y': 1.0751145403843916}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,632]\u001b[0m Trial 266 finished with value: 545.6133117565768 and parameters: {'x': 1.1116902025836362, 'y': -1.099954896573178}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,638]\u001b[0m Trial 267 finished with value: 13.195843230870606 and parameters: {'x': 0.9766035150307033, 'y': 0.5905011277826563}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,643]\u001b[0m Trial 268 finished with value: 5.475366473095219 and parameters: {'x': 0.783446326326777, 'y': 0.8467789396048294}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,649]\u001b[0m Trial 269 finished with value: 8.578179719047878 and parameters: {'x': 1.0226142063137327, 'y': 0.7528632485188942}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,654]\u001b[0m Trial 270 finished with value: 3.96279564455883 and parameters: {'x': -0.9856863400825385, 'y': 0.9574901895996522}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,660]\u001b[0m Trial 271 finished with value: 1.2726342017658845 and parameters: {'x': 0.8980235664511332, 'y': 0.9187955585988832}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,665]\u001b[0m Trial 272 finished with value: 10.83406296898302 and parameters: {'x': 0.6866745851892792, 'y': 0.79917866836439}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,671]\u001b[0m Trial 273 finished with value: 16.988688957636242 and parameters: {'x': 1.0449727905705415, 'y': 0.6798192957695391}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,677]\u001b[0m Trial 274 finished with value: 11.352574553221924 and parameters: {'x': 0.8323927293273068, 'y': 1.029396338171831}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,683]\u001b[0m Trial 275 finished with value: 7.694578851846262 and parameters: {'x': 0.9260510500908307, 'y': 1.1348629995733324}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,690]\u001b[0m Trial 276 finished with value: 846.8469824080314 and parameters: {'x': 1.1187694705259157, 'y': -1.6583941777751874}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,695]\u001b[0m Trial 277 finished with value: 51.97353289539813 and parameters: {'x': 1.2515459828808788, 'y': 0.8458796130608955}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,702]\u001b[0m Trial 278 finished with value: 0.11128793868048231 and parameters: {'x': 0.7579764436111432, 'y': 0.551569078100077}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,708]\u001b[0m Trial 279 finished with value: 1.3370293857382787 and parameters: {'x': 0.6478319858689723, 'y': 0.5298228823509987}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,713]\u001b[0m Trial 280 finished with value: 0.26506977474815074 and parameters: {'x': 0.766977942014128, 'y': 0.6341649114379722}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,719]\u001b[0m Trial 281 finished with value: 158.624924160917 and parameters: {'x': -1.350389989926695, 'y': 0.5862148887753744}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,725]\u001b[0m Trial 282 finished with value: 3.7163498008516695 and parameters: {'x': 0.8167254225056163, 'y': 0.47513522484979764}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,731]\u001b[0m Trial 283 finished with value: 4.7151599716135815 and parameters: {'x': 0.7141786037911526, 'y': 0.7253059526474982}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,738]\u001b[0m Trial 284 finished with value: 0.09235306900391105 and parameters: {'x': 0.859334259273799, 'y': 0.7653934868371399}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,747]\u001b[0m Trial 285 finished with value: 0.645976826749873 and parameters: {'x': 0.7705185387362338, 'y': 0.6707257674363377}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,757]\u001b[0m Trial 286 finished with value: 0.05887319670811754 and parameters: {'x': 0.8631760314331818, 'y': 0.7651109246036832}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,765]\u001b[0m Trial 287 finished with value: 0.2516080183868574 and parameters: {'x': 0.9180132198245704, 'y': 0.7932622953487098}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,775]\u001b[0m Trial 288 finished with value: 2.1384811963902135 and parameters: {'x': 0.6637797441523416, 'y': 0.5829214020172933}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,781]\u001b[0m Trial 289 finished with value: 0.12093222363432829 and parameters: {'x': 0.8480802475125802, 'y': 0.6879587040084242}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,789]\u001b[0m Trial 290 finished with value: 0.19764130680273795 and parameters: {'x': 0.8692878708658507, 'y': 0.7981532423687531}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,796]\u001b[0m Trial 291 finished with value: 10.210720030909737 and parameters: {'x': 0.9760032371511312, 'y': 0.6330491565459483}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,804]\u001b[0m Trial 292 finished with value: 0.37530203824315117 and parameters: {'x': 0.8627100643872544, 'y': 0.6845649273531076}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,810]\u001b[0m Trial 293 finished with value: 8.534579874068363 and parameters: {'x': 0.7661882863430034, 'y': 0.8782473739855723}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,817]\u001b[0m Trial 294 finished with value: 5.435220042892266 and parameters: {'x': 0.9802491386836112, 'y': 0.7277611565520985}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,823]\u001b[0m Trial 295 finished with value: 3.854896396099231 and parameters: {'x': 0.8781096724425449, 'y': 0.96703677504046}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,829]\u001b[0m Trial 296 finished with value: 8.212326379249017 and parameters: {'x': 1.04364929213072, 'y': 0.8026655208520084}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,835]\u001b[0m Trial 297 finished with value: 5.984543206539866 and parameters: {'x': 0.8019920504013699, 'y': 0.8870218470368346}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,840]\u001b[0m Trial 298 finished with value: 70.03727286786551 and parameters: {'x': 0.9450399863735396, 'y': 1.7299652737786082}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,848]\u001b[0m Trial 299 finished with value: 33.98464572669652 and parameters: {'x': 1.1455239739893985, 'y': 0.7294433247206553}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,854]\u001b[0m Trial 300 finished with value: 4.297218498929187 and parameters: {'x': 0.8822774645373963, 'y': 0.5714507281705942}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,860]\u001b[0m Trial 301 finished with value: 0.0009108917016504023 and parameters: {'x': 0.9765245459967183, 'y': 0.9554970146008102}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,866]\u001b[0m Trial 302 finished with value: 1.8784826145409532 and parameters: {'x': 1.0509105271733805, 'y': 0.9674497756475979}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,872]\u001b[0m Trial 303 finished with value: 3.2047321058409217 and parameters: {'x': 0.9677976702129722, 'y': 1.1156210204977481}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,878]\u001b[0m Trial 304 finished with value: 0.5631570842730884 and parameters: {'x': 1.0817609802726247, 'y': 1.2448038844938178}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,885]\u001b[0m Trial 305 finished with value: 28.41299425662259 and parameters: {'x': 1.2096167593242475, 'y': 0.9305466154147254}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,891]\u001b[0m Trial 306 finished with value: 1.4401618388280248 and parameters: {'x': 0.9782274728466324, 'y': 0.8369419978416828}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,898]\u001b[0m Trial 307 finished with value: 19.259392974711545 and parameters: {'x': 0.7515686905420926, 'y': 1.0030070098858623}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,904]\u001b[0m Trial 308 finished with value: 6.215041995920962 and parameters: {'x': 0.9087809162530094, 'y': 1.0750156715763088}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,910]\u001b[0m Trial 309 finished with value: 187.7556832422809 and parameters: {'x': 1.5053704949474336, 'y': 0.8968328966208446}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,916]\u001b[0m Trial 310 finished with value: 4.7988372572678815 and parameters: {'x': 1.0051971526859609, 'y': 0.7913594467247211}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,922]\u001b[0m Trial 311 finished with value: 10.714596157776118 and parameters: {'x': 0.8014953301364774, 'y': 0.9691238883352205}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,927]\u001b[0m Trial 312 finished with value: 899.0728810973106 and parameters: {'x': 1.1050921867287828, 'y': -1.777207245690812}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,933]\u001b[0m Trial 313 finished with value: 0.020261803696037667 and parameters: {'x': 0.9243333465680462, 'y': 0.8664488188921142}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,939]\u001b[0m Trial 314 finished with value: 458.6156833350509 and parameters: {'x': -1.7256222060180946, 'y': 0.8536564950990304}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,944]\u001b[0m Trial 315 finished with value: 13.287497452805043 and parameters: {'x': 0.6378676085873929, 'y': 0.7695920223299841}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,950]\u001b[0m Trial 316 finished with value: 0.17490036382970742 and parameters: {'x': 0.9139432650659026, 'y': 0.8762183961674129}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,956]\u001b[0m Trial 317 finished with value: 1.307285603443131 and parameters: {'x': 0.7274187381968751, 'y': 0.6401778810525472}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,962]\u001b[0m Trial 318 finished with value: 23.765880078695794 and parameters: {'x': 0.8214429855500626, 'y': 1.1619440856039844}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,967]\u001b[0m Trial 319 finished with value: 10.213170111606265 and parameters: {'x': 0.9208243895826413, 'y': 0.5284351416865938}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,973]\u001b[0m Trial 320 finished with value: 11.645593140944552 and parameters: {'x': 1.0408702980230713, 'y': 0.7421790509034347}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,978]\u001b[0m Trial 321 finished with value: 10.676242503389973 and parameters: {'x': 0.8327234708676949, 'y': 1.0197451125868662}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,986]\u001b[0m Trial 322 finished with value: 11.013967248986312 and parameters: {'x': 0.7115225349675922, 'y': 0.8368811352632597}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,992]\u001b[0m Trial 323 finished with value: 0.3888911368490184 and parameters: {'x': 0.9320846944927337, 'y': 0.9307720904937351}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:48,997]\u001b[0m Trial 324 finished with value: 57.148951528638364 and parameters: {'x': 1.1878726873769117, 'y': 0.6553057515733309}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,003]\u001b[0m Trial 325 finished with value: 0.06894744591222819 and parameters: {'x': 0.8726332674424944, 'y': 0.7844507795879645}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,009]\u001b[0m Trial 326 finished with value: 4.1988242703479814 and parameters: {'x': 0.9977934229092669, 'y': 0.7906815051635617}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,016]\u001b[0m Trial 327 finished with value: 0.7729004171055733 and parameters: {'x': 0.8807192713125567, 'y': 0.8627682445365145}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,024]\u001b[0m Trial 328 finished with value: 0.4978932623761309 and parameters: {'x': 1.0708251416851626, 'y': 1.0764612804344482}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,030]\u001b[0m Trial 329 finished with value: 5.664508174026776 and parameters: {'x': 0.9754489302567362, 'y': 0.7135110061229435}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,041]\u001b[0m Trial 330 finished with value: 3.152514540844758 and parameters: {'x': 0.8656800143101856, 'y': 0.9264463076554941}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,051]\u001b[0m Trial 331 finished with value: 1.9417873171376765 and parameters: {'x': 0.8027944253263034, 'y': 0.7824244321573403}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,059]\u001b[0m Trial 332 finished with value: 7.453472368145704 and parameters: {'x': 1.1383435475143515, 'y': 1.0231662912631332}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,069]\u001b[0m Trial 333 finished with value: 0.010094518763810397 and parameters: {'x': 0.9240653606103371, 'y': 0.8473176955258868}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,077]\u001b[0m Trial 334 finished with value: 0.22334896584013544 and parameters: {'x': 0.94985744327739, 'y': 0.8552361109518616}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,084]\u001b[0m Trial 335 finished with value: 3.601049276431521 and parameters: {'x': 1.0712179534941688, 'y': 0.9578772819008667}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,090]\u001b[0m Trial 336 finished with value: 1.7360801305708973 and parameters: {'x': 1.0102477162369214, 'y': 0.8888440397833159}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,097]\u001b[0m Trial 337 finished with value: 0.11797256860543105 and parameters: {'x': 0.9061272598889076, 'y': 0.7880271684324232}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,103]\u001b[0m Trial 338 finished with value: 55.041839029198485 and parameters: {'x': 1.3288722245359044, 'y': 1.0247287905593312}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,110]\u001b[0m Trial 339 finished with value: 3.754529143338521 and parameters: {'x': 0.9524789893121277, 'y': 1.1009240178226383}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,117]\u001b[0m Trial 340 finished with value: 371.24269922904136 and parameters: {'x': 1.7022880666730782, 'y': 0.9722990330624766}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,123]\u001b[0m Trial 341 finished with value: 1.1067670051569256 and parameters: {'x': 0.8585750187043633, 'y': 0.8413991313019223}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,132]\u001b[0m Trial 342 finished with value: 17.83916483856829 and parameters: {'x': 1.0739478192411145, 'y': 0.7310643025566643}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,140]\u001b[0m Trial 343 finished with value: 3.3204177526087055 and parameters: {'x': 1.1651736844066716, 'y': 1.1761597336637017}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,146]\u001b[0m Trial 344 finished with value: 0.4766900526310918 and parameters: {'x': 0.9973907929255529, 'y': 0.9257461426421274}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,153]\u001b[0m Trial 345 finished with value: 0.012467573220482621 and parameters: {'x': 0.8938181033127662, 'y': 0.8023647532227}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,159]\u001b[0m Trial 346 finished with value: 0.025354678469077824 and parameters: {'x': 0.928778726120933, 'y': 0.8483883601663966}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,164]\u001b[0m Trial 347 finished with value: 0.006093371335281747 and parameters: {'x': 0.9407014546338874, 'y': 0.8798427576498987}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,173]\u001b[0m Trial 348 finished with value: 5.449178042614237 and parameters: {'x': 1.036952921235608, 'y': 0.8418658655461527}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,179]\u001b[0m Trial 349 finished with value: 34.734388479381586 and parameters: {'x': 1.2602245382296218, 'y': 0.9993817865199518}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,184]\u001b[0m Trial 350 finished with value: 0.139089413971896 and parameters: {'x': 0.9251153332742378, 'y': 0.8923735274106424}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,190]\u001b[0m Trial 351 finished with value: 89.5001632032412 and parameters: {'x': 1.0127628837689326, 'y': 1.9717330568103675}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,196]\u001b[0m Trial 352 finished with value: 14.668859397773453 and parameters: {'x': -0.678827669885376, 'y': 0.8050510620333573}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,204]\u001b[0m Trial 353 finished with value: 4.858332648735189 and parameters: {'x': 1.1321836348033896, 'y': 1.0618202352526551}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,212]\u001b[0m Trial 354 finished with value: 0.6731628789954686 and parameters: {'x': 0.9223580505163803, 'y': 0.9324226817748622}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,220]\u001b[0m Trial 355 finished with value: 0.19528582111741244 and parameters: {'x': 0.8288036913250001, 'y': 0.7276559128286797}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,228]\u001b[0m Trial 356 finished with value: 1.7107130529883645 and parameters: {'x': 0.9783581620085694, 'y': 0.8264083694768916}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,235]\u001b[0m Trial 357 finished with value: 5.908829934909589 and parameters: {'x': 1.086626583639183, 'y': 0.9378308872326102}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,241]\u001b[0m Trial 358 finished with value: 5.842850412340591 and parameters: {'x': 0.8812701055909428, 'y': 1.018065117182485}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,247]\u001b[0m Trial 359 finished with value: 50.97136853307733 and parameters: {'x': 0.7712112546972862, 'y': 1.3083424733062103}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,255]\u001b[0m Trial 360 finished with value: 2.867604145472024 and parameters: {'x': 1.0122812323616779, 'y': 0.855377729589985}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,262]\u001b[0m Trial 361 finished with value: 2.63265394981665 and parameters: {'x': 0.9286584816672215, 'y': 0.7003089402541641}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,267]\u001b[0m Trial 362 finished with value: 18.691297317522807 and parameters: {'x': 0.8299022155602742, 'y': 1.1207372714339143}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,273]\u001b[0m Trial 363 finished with value: 14.221408606265479 and parameters: {'x': 1.0733498503174652, 'y': 0.7750384126673175}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,278]\u001b[0m Trial 364 finished with value: 0.5521815570191408 and parameters: {'x': 0.9017186113465318, 'y': 0.8867525689111977}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,284]\u001b[0m Trial 365 finished with value: 1.10707487518285 and parameters: {'x': 1.1440805120277322, 'y': 1.204693749135199}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,290]\u001b[0m Trial 366 finished with value: 0.11582399977564617 and parameters: {'x': 0.9884185154436445, 'y': 1.010984375132342}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,295]\u001b[0m Trial 367 finished with value: 35.19740895479418 and parameters: {'x': -0.46617303765948653, 'y': 0.7921889874058525}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,302]\u001b[0m Trial 368 finished with value: 11.009794618136432 and parameters: {'x': 0.7781488413237672, 'y': 0.9365832359352265}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,308]\u001b[0m Trial 369 finished with value: 0.47285860741224095 and parameters: {'x': 0.8715489915495734, 'y': 0.6920433001890016}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,316]\u001b[0m Trial 370 finished with value: 0.5452014316142081 and parameters: {'x': 0.9634019854340462, 'y': 0.8543963844504865}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,323]\u001b[0m Trial 371 finished with value: 1.747295328351188 and parameters: {'x': 1.0536329525564105, 'y': 0.978065949837428}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,335]\u001b[0m Trial 372 finished with value: 18.958803911767664 and parameters: {'x': 0.8113182065314836, 'y': 1.0932453136983158}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,344]\u001b[0m Trial 373 finished with value: 7.087007190423287 and parameters: {'x': 0.7072350819097616, 'y': 0.7647810811357678}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,353]\u001b[0m Trial 374 finished with value: 2.9472591703985853 and parameters: {'x': 0.9216506258371364, 'y': 0.6779429214401116}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,362]\u001b[0m Trial 375 finished with value: 2.2173528991321048 and parameters: {'x': 1.0195814157107348, 'y': 0.8906513517549294}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,370]\u001b[0m Trial 376 finished with value: 0.26009283098040376 and parameters: {'x': 0.8653254359790142, 'y': 0.7979770919252415}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,378]\u001b[0m Trial 377 finished with value: 19.497391948667637 and parameters: {'x': 1.1930400363427223, 'y': 0.9822081832595129}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,386]\u001b[0m Trial 378 finished with value: 2.4332973493143935 and parameters: {'x': 0.9557146633108377, 'y': 1.0693179417552459}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,394]\u001b[0m Trial 379 finished with value: 70.67897660229222 and parameters: {'x': 0.7798500467810122, 'y': 1.448585696618377}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,402]\u001b[0m Trial 380 finished with value: 14.404669534543773 and parameters: {'x': 1.1178902035194591, 'y': 0.8703268044205733}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,409]\u001b[0m Trial 381 finished with value: 1.305722288055706 and parameters: {'x': 0.8815896913828605, 'y': 0.6635473467353503}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,415]\u001b[0m Trial 382 finished with value: 9.791607146852863 and parameters: {'x': 1.033986150931218, 'y': 0.7562303790537896}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,421]\u001b[0m Trial 383 finished with value: 0.29777561394723345 and parameters: {'x': 0.9416004853432671, 'y': 0.9408668986707854}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,427]\u001b[0m Trial 384 finished with value: 13.649897697389513 and parameters: {'x': 0.6842426884492965, 'y': 0.8362939520252574}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,432]\u001b[0m Trial 385 finished with value: 29.578710581644486 and parameters: {'x': 0.8010287504720761, 'y': 1.1851461025365289}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,438]\u001b[0m Trial 386 finished with value: 322.84698559486304 and parameters: {'x': 0.6122188084829486, 'y': -1.421563957983321}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,444]\u001b[0m Trial 387 finished with value: 2.5897605239163326 and parameters: {'x': 1.0937721527849305, 'y': 1.0356836300271555}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,450]\u001b[0m Trial 388 finished with value: 5.136123060600274 and parameters: {'x': 0.9760285745758868, 'y': 0.7260142938168724}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,457]\u001b[0m Trial 389 finished with value: 2.104294415993412 and parameters: {'x': 0.8756344124455597, 'y': 0.6222078547256297}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,465]\u001b[0m Trial 390 finished with value: 41.601290460182 and parameters: {'x': 1.2534824344326696, 'y': 0.9267258774363535}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,472]\u001b[0m Trial 391 finished with value: 168.6109421980389 and parameters: {'x': 0.750979770435465, 'y': -0.7342933449351783}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,479]\u001b[0m Trial 392 finished with value: 4.951607497183507 and parameters: {'x': 1.02925206028669, 'y': 0.8368569538664098}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,486]\u001b[0m Trial 393 finished with value: 8.680356234979303 and parameters: {'x': 0.8400325583971979, 'y': 0.999844546929061}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,494]\u001b[0m Trial 394 finished with value: 1.835190139327703 and parameters: {'x': 0.9442666944282818, 'y': 0.7562850949735241}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,500]\u001b[0m Trial 395 finished with value: 10.182856858357157 and parameters: {'x': 0.8851999454614273, 'y': 1.1024782662073667}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,507]\u001b[0m Trial 396 finished with value: 20.72194667706511 and parameters: {'x': 1.1627054495176108, 'y': 0.8969611819261262}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,513]\u001b[0m Trial 397 finished with value: 17.661193786049804 and parameters: {'x': 1.0176140793293111, 'y': 0.6152898745319779}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,520]\u001b[0m Trial 398 finished with value: 2.7841132892743383 and parameters: {'x': 0.8059987692956678, 'y': 0.8153589934559423}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,526]\u001b[0m Trial 399 finished with value: 0.13893833503878264 and parameters: {'x': 0.9572738598944973, 'y': 0.9534019900468046}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,534]\u001b[0m Trial 400 finished with value: 22.756196317893835 and parameters: {'x': 1.0857743501211863, 'y': 0.7019485085892461}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,540]\u001b[0m Trial 401 finished with value: 12.653260943297546 and parameters: {'x': 0.7211224978470655, 'y': 0.8746370060925526}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,547]\u001b[0m Trial 402 finished with value: 8.836164422146371 and parameters: {'x': 0.8707649949240672, 'y': 1.055207479029188}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,556]\u001b[0m Trial 403 finished with value: 2.255940240392049 and parameters: {'x': 0.9752362387437754, 'y': 0.800908259783792}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,562]\u001b[0m Trial 404 finished with value: 1.784188310641854 and parameters: {'x': 0.9092664573782755, 'y': 0.9600304797221522}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,568]\u001b[0m Trial 405 finished with value: 25.022145075842108 and parameters: {'x': 0.8074552522852421, 'y': 1.1518346781103386}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,575]\u001b[0m Trial 406 finished with value: 1.1683444923175548 and parameters: {'x': 1.0704066109932733, 'y': 1.2536307505285498}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,581]\u001b[0m Trial 407 finished with value: 9.707295962452042 and parameters: {'x': 1.0110247667464995, 'y': 0.7106076918933046}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,589]\u001b[0m Trial 408 finished with value: 10.383998313531905 and parameters: {'x': 0.7454320811699956, 'y': 0.876904002669019}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,598]\u001b[0m Trial 409 finished with value: 0.33531980768771613 and parameters: {'x': 0.914342415119086, 'y': 0.7787522881749848}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,606]\u001b[0m Trial 410 finished with value: 34.98113073169562 and parameters: {'x': 0.6483528036770824, 'y': 1.0107635512992532}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,612]\u001b[0m Trial 411 finished with value: 61.76413884641117 and parameters: {'x': 1.1811403501398, 'y': 0.6093996667635964}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,618]\u001b[0m Trial 412 finished with value: 2.751095551978672 and parameters: {'x': 0.8607500664305572, 'y': 0.9061693811139502}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,627]\u001b[0m Trial 413 finished with value: 1.1406262304328865 and parameters: {'x': 0.9670143849749937, 'y': 0.8283676671390725}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,633]\u001b[0m Trial 414 finished with value: 17.69102257342776 and parameters: {'x': 1.0649232803670077, 'y': 0.7135047295985589}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,642]\u001b[0m Trial 415 finished with value: 8.92457506819413 and parameters: {'x': 0.8155884637192631, 'y': 0.9633550882070654}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,649]\u001b[0m Trial 416 finished with value: 5.629713070179113 and parameters: {'x': 0.9142511909024736, 'y': 1.072970406429215}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,658]\u001b[0m Trial 417 finished with value: 443.630649961138 and parameters: {'x': 1.1170408535981768, 'y': -0.858441351734939}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,669]\u001b[0m Trial 418 finished with value: 5.301908124036858 and parameters: {'x': 0.7393216209644315, 'y': 0.7753748434041432}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,678]\u001b[0m Trial 419 finished with value: 9.48403830848381 and parameters: {'x': 0.9781972762147777, 'y': 0.6489159706490099}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,684]\u001b[0m Trial 420 finished with value: 4.486099658291497 and parameters: {'x': 0.8227584009911532, 'y': 0.887992635186612}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,693]\u001b[0m Trial 421 finished with value: 3.781039036284475 and parameters: {'x': 0.9084029045940037, 'y': 1.01942891892232}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,699]\u001b[0m Trial 422 finished with value: 5.470025823206486 and parameters: {'x': 1.0306277642435222, 'y': 0.8283327801853824}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,706]\u001b[0m Trial 423 finished with value: 3.141721519155159 and parameters: {'x': 0.8704292710667834, 'y': 0.9344219146246565}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,713]\u001b[0m Trial 424 finished with value: 111.49697649043719 and parameters: {'x': 0.7694441096312108, 'y': -0.46362531495837167}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,722]\u001b[0m Trial 425 finished with value: 2.5414206505527166 and parameters: {'x': 0.9806466786009166, 'y': 1.1210744984379757}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,729]\u001b[0m Trial 426 finished with value: 16.2424563335386 and parameters: {'x': 0.5851989160168181, 'y': 0.7433367604581618}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,736]\u001b[0m Trial 427 finished with value: 17.204354879436774 and parameters: {'x': 1.1203209433927679, 'y': 0.840512241657568}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,744]\u001b[0m Trial 428 finished with value: 0.30680861808796506 and parameters: {'x': 1.0230809255835482, 'y': 0.9913523822011829}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,751]\u001b[0m Trial 429 finished with value: 6.596675152497763 and parameters: {'x': 0.6622471573990789, 'y': 0.693180766470721}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,757]\u001b[0m Trial 430 finished with value: 5.279325372767397 and parameters: {'x': 0.9148208868277856, 'y': 0.6072873707935171}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,763]\u001b[0m Trial 431 finished with value: 4.6096609074919135 and parameters: {'x': 0.8367905722146646, 'y': 0.9142984372278633}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,771]\u001b[0m Trial 432 finished with value: 1.50035952694899 and parameters: {'x': 0.946669535793133, 'y': 0.7738101987366424}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,777]\u001b[0m Trial 433 finished with value: 1.0365458814423987 and parameters: {'x': 1.0668008857610694, 'y': 1.0364726182514163}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,784]\u001b[0m Trial 434 finished with value: 720.4298308679641 and parameters: {'x': 1.877477198153187, 'y': 0.8422729362890474}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,790]\u001b[0m Trial 435 finished with value: 58.305470836189684 and parameters: {'x': 1.2985652334817692, 'y': 0.9232754032474788}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,796]\u001b[0m Trial 436 finished with value: 5.256675233068641 and parameters: {'x': 1.1985097844180999, 'y': 1.2080122821430732}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,801]\u001b[0m Trial 437 finished with value: 0.5956422529860093 and parameters: {'x': 0.7549640833989327, 'y': 0.6431554413394136}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,807]\u001b[0m Trial 438 finished with value: 0.13869108278872683 and parameters: {'x': 0.8437405888172727, 'y': 0.745702630511495}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,813]\u001b[0m Trial 439 finished with value: 1.3925259410680284 and parameters: {'x': 0.9893424685647997, 'y': 1.0967990437526847}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,818]\u001b[0m Trial 440 finished with value: 0.0695769720519845 and parameters: {'x': 0.9165907880796524, 'y': 0.8651626363911593}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,826]\u001b[0m Trial 441 finished with value: 12.22873732528939 and parameters: {'x': 0.6842554167512526, 'y': 0.8164732269963073}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,835]\u001b[0m Trial 442 finished with value: 7.024909771214517 and parameters: {'x': 0.89384501076343, 'y': 0.53412610904597}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,841]\u001b[0m Trial 443 finished with value: 0.518733816408914 and parameters: {'x': 0.7893494798577975, 'y': 0.6919464116698298}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,849]\u001b[0m Trial 444 finished with value: 1.6718582451350845 and parameters: {'x': 0.8585202226556891, 'y': 0.8655809672676767}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,856]\u001b[0m Trial 445 finished with value: 1.1171903692625318 and parameters: {'x': 0.93716545873319, 'y': 0.772768804194626}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,865]\u001b[0m Trial 446 finished with value: 9.390636659358718 and parameters: {'x': 0.7704911741788951, 'y': 0.8992374466301438}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,873]\u001b[0m Trial 447 finished with value: 17.878778662710005 and parameters: {'x': 1.055295691873878, 'y': 0.6908521069351166}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,881]\u001b[0m Trial 448 finished with value: 0.019537417088543972 and parameters: {'x': 0.9011370402487672, 'y': 0.8021669065200153}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,888]\u001b[0m Trial 449 finished with value: 1.6917222145755761 and parameters: {'x': 0.8328609268108391, 'y': 0.5646694656545034}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,896]\u001b[0m Trial 450 finished with value: 5.448389362618486 and parameters: {'x': 1.0029635398961356, 'y': 0.7725181985039054}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,905]\u001b[0m Trial 451 finished with value: 4.935334849824484 and parameters: {'x': 0.7116338532028743, 'y': 0.7266993810751449}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,913]\u001b[0m Trial 452 finished with value: 2.73720285418937 and parameters: {'x': 0.9040600265781524, 'y': 0.9824910650610866}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,921]\u001b[0m Trial 453 finished with value: 42.429467255088106 and parameters: {'x': 1.1422563767338203, 'y': 0.6535259329976519}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,927]\u001b[0m Trial 454 finished with value: 1.2544096461012257 and parameters: {'x': 0.8386504140582179, 'y': 0.8141666403766679}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,933]\u001b[0m Trial 455 finished with value: 0.0009739196991672189 and parameters: {'x': 0.9707832536426338, 'y': 0.9413233054608185}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,939]\u001b[0m Trial 456 finished with value: 1.7398475755009695 and parameters: {'x': 1.0444865718085343, 'y': 0.9591239573881705}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,946]\u001b[0m Trial 457 finished with value: 17.00417403728362 and parameters: {'x': 1.1461429890227377, 'y': 0.9015416248167818}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,956]\u001b[0m Trial 458 finished with value: 2.0206098980534377 and parameters: {'x': 0.9830011667768709, 'y': 1.108429288021461}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,963]\u001b[0m Trial 459 finished with value: 1.703727356404203 and parameters: {'x': 1.088357090921099, 'y': 1.0542936494772919}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,971]\u001b[0m Trial 460 finished with value: 0.4677981536360239 and parameters: {'x': 0.9514985004744395, 'y': 0.9735729816363007}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,979]\u001b[0m Trial 461 finished with value: 40.46801160901784 and parameters: {'x': 1.2343421373868275, 'y': 0.8878875629789668}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,989]\u001b[0m Trial 462 finished with value: 0.7496348333855913 and parameters: {'x': 1.0462322204566972, 'y': 1.0081439262770875}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:49,995]\u001b[0m Trial 463 finished with value: 0.5279267399864503 and parameters: {'x': 0.9552801661506403, 'y': 0.8400393797638273}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,009]\u001b[0m Trial 464 finished with value: 27.406909810957323 and parameters: {'x': -0.8172078057970019, 'y': 1.1587936231018277}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,019]\u001b[0m Trial 465 finished with value: 318.613553856561 and parameters: {'x': 1.6446614289257935, 'y': 0.9211007844481698}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,028]\u001b[0m Trial 466 finished with value: 2.6209158409963855 and parameters: {'x': 0.7639211943175045, 'y': 0.7437374666941701}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,035]\u001b[0m Trial 467 finished with value: 38.03296053621209 and parameters: {'x': -1.18317780939312, 'y': 0.823136851427915}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,041]\u001b[0m Trial 468 finished with value: 2.8218164220685606 and parameters: {'x': 0.8724639540978872, 'y': 0.5936955607948671}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,048]\u001b[0m Trial 469 finished with value: 3.5077120918810167 and parameters: {'x': 1.0968930195597508, 'y': 1.016136229788447}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,056]\u001b[0m Trial 470 finished with value: 0.3670175709265946 and parameters: {'x': 1.0031059349010374, 'y': 0.9456403377003733}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,063]\u001b[0m Trial 471 finished with value: 0.041963904806083765 and parameters: {'x': 0.8220850434100961, 'y': 0.6656699163793851}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,070]\u001b[0m Trial 472 finished with value: 21.9725492626269 and parameters: {'x': 0.9336054142936253, 'y': 1.3403209046877576}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,078]\u001b[0m Trial 473 finished with value: 0.09824659554745983 and parameters: {'x': 0.8147217936923261, 'y': 0.6890537255957875}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,084]\u001b[0m Trial 474 finished with value: 3.167361974421027 and parameters: {'x': 1.0128443660884026, 'y': 0.8478875053533196}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,091]\u001b[0m Trial 475 finished with value: 48.13222210046383 and parameters: {'x': 0.5936073989070181, 'y': 1.0449523539418566}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,099]\u001b[0m Trial 476 finished with value: 0.05611594112395822 and parameters: {'x': 0.8908230863106248, 'y': 0.7725428448944363}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,109]\u001b[0m Trial 477 finished with value: 6.1542963606041265 and parameters: {'x': 0.6986350375413883, 'y': 0.7343321697384733}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,116]\u001b[0m Trial 478 finished with value: 1.2390953897158807 and parameters: {'x': 0.8194878267821809, 'y': 0.7814015812408793}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,123]\u001b[0m Trial 479 finished with value: 1.8814830492024557 and parameters: {'x': 0.8874000062111692, 'y': 0.6507745541683152}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,129]\u001b[0m Trial 480 finished with value: 2.1387648449358077 and parameters: {'x': 0.7818182377240641, 'y': 0.46663126595495763}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,136]\u001b[0m Trial 481 finished with value: 0.12586572397098297 and parameters: {'x': 0.9063247726974226, 'y': 0.7872060787686492}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,143]\u001b[0m Trial 482 finished with value: 38.88837791876354 and parameters: {'x': 1.1269646745588822, 'y': 0.6465731721417776}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,151]\u001b[0m Trial 483 finished with value: 16.316408223722533 and parameters: {'x': 0.6823390869375514, 'y': 0.8682713668950282}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,158]\u001b[0m Trial 484 finished with value: 6.162347429476825 and parameters: {'x': 0.9896282940202066, 'y': 0.731125568297596}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,165]\u001b[0m Trial 485 finished with value: 0.6742814258695317 and parameters: {'x': 0.8608908392454718, 'y': 0.8220607868037616}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,172]\u001b[0m Trial 486 finished with value: 5.310082445329774 and parameters: {'x': 1.0568077094853376, 'y': 0.8864764060353947}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,179]\u001b[0m Trial 487 finished with value: 0.09396322107277914 and parameters: {'x': 0.7602226001830971, 'y': 0.597035527165132}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,185]\u001b[0m Trial 488 finished with value: 12.655827220257676 and parameters: {'x': 0.9432043621180606, 'y': 1.245339423361782}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,192]\u001b[0m Trial 489 finished with value: 190.35597212418404 and parameters: {'x': 1.4395353697784667, 'y': 0.693266864089747}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,199]\u001b[0m Trial 490 finished with value: 5.698158937464456 and parameters: {'x': 0.8425748669149891, 'y': 0.9481209087018581}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,206]\u001b[0m Trial 491 finished with value: 0.7233499656749109 and parameters: {'x': 0.9347121279568822, 'y': 0.7888877374242185}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,212]\u001b[0m Trial 492 finished with value: 1.1609380484913037 and parameters: {'x': 1.0299397561174772, 'y': 0.9530706711125023}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,219]\u001b[0m Trial 493 finished with value: 19.678306203093655 and parameters: {'x': 0.8049992864265147, 'y': 1.091197416748752}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,225]\u001b[0m Trial 494 finished with value: 45.336391829971134 and parameters: {'x': 1.1876702101074246, 'y': 0.7374990766795622}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,232]\u001b[0m Trial 495 finished with value: 0.007782751452132111 and parameters: {'x': 0.9158105815174614, 'y': 0.8413451040475338}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,239]\u001b[0m Trial 496 finished with value: 10.827994541902392 and parameters: {'x': 1.0932421500538816, 'y': 0.8662513483323947}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,249]\u001b[0m Trial 497 finished with value: 0.0923393866338932 and parameters: {'x': 0.9829403078576341, 'y': 0.9965111203850867}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,259]\u001b[0m Trial 498 finished with value: 14.226790305336607 and parameters: {'x': -0.28133273286833926, 'y': -0.2756050009862617}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,267]\u001b[0m Trial 499 finished with value: 131.2745528959485 and parameters: {'x': -0.15624216081244896, 'y': 1.1643136128202043}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,273]\u001b[0m Trial 500 finished with value: 51.789185860003165 and parameters: {'x': 0.9337659994066135, 'y': 1.5915354986917103}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,281]\u001b[0m Trial 501 finished with value: 2.2301065636824107 and parameters: {'x': 1.0282946993264324, 'y': 0.9080813829606736}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,289]\u001b[0m Trial 502 finished with value: 0.02161544159401566 and parameters: {'x': 0.9042546316103546, 'y': 0.8288336185515796}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,296]\u001b[0m Trial 503 finished with value: 7.167890646560171 and parameters: {'x': 1.1391303937270494, 'y': 1.0302506404139857}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,302]\u001b[0m Trial 504 finished with value: 11.505697728196017 and parameters: {'x': 0.7266716836515159, 'y': 0.8661491975043629}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,308]\u001b[0m Trial 505 finished with value: 112.34380452733798 and parameters: {'x': 0.9589143999871459, 'y': -0.14039881401218482}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,314]\u001b[0m Trial 506 finished with value: 2.2889801136324364 and parameters: {'x': 1.0524230004407846, 'y': 0.9563912637280965}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,321]\u001b[0m Trial 507 finished with value: 104.32466442401463 and parameters: {'x': 0.22841377539218646, 'y': 1.0706487686652284}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,328]\u001b[0m Trial 508 finished with value: 2.1634177693565926 and parameters: {'x': 0.8317824890645563, 'y': 0.8379826291782199}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,335]\u001b[0m Trial 509 finished with value: 40.41447343363911 and parameters: {'x': 1.2453385688681446, 'y': 0.9156179451266107}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,344]\u001b[0m Trial 510 finished with value: 86.50687568151602 and parameters: {'x': 0.9082005801837567, 'y': 1.7548737150382034}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,355]\u001b[0m Trial 511 finished with value: 0.053705844628335365 and parameters: {'x': 0.9782895024864438, 'y': 0.9801229532431652}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,363]\u001b[0m Trial 512 finished with value: 1.5762002899934562 and parameters: {'x': 1.1050118446867951, 'y': 1.0959443104810809}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,371]\u001b[0m Trial 513 finished with value: 0.17217755617439862 and parameters: {'x': 1.0209490225466253, 'y': 1.000895539066309}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,381]\u001b[0m Trial 514 finished with value: 18.138326736043116 and parameters: {'x': 1.1836177115143678, 'y': 0.975455748706188}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,390]\u001b[0m Trial 515 finished with value: 2.959605290210453 and parameters: {'x': 0.99023265592188, 'y': 1.152592974049497}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,397]\u001b[0m Trial 516 finished with value: 1.4543578018483638 and parameters: {'x': 1.0788082352970825, 'y': 1.0434882263363072}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,406]\u001b[0m Trial 517 finished with value: 0.10579751773553896 and parameters: {'x': 0.9373485420650001, 'y': 0.9105397316516061}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,413]\u001b[0m Trial 518 finished with value: 3.048327467118395 and parameters: {'x': 1.0085753741239274, 'y': 0.8426317903165831}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,424]\u001b[0m Trial 519 finished with value: 2.24001290473079 and parameters: {'x': 0.883555985709142, 'y': 0.9298842388373124}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,432]\u001b[0m Trial 520 finished with value: 2.1884474793941098 and parameters: {'x': 1.1008990435581565, 'y': 1.064389176619601}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,439]\u001b[0m Trial 521 finished with value: 292.9619047984769 and parameters: {'x': -1.6318666452756427, 'y': 0.9717312786228007}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,447]\u001b[0m Trial 522 finished with value: 0.4762593017202711 and parameters: {'x': 0.9531190654526547, 'y': 0.8395838302535493}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,455]\u001b[0m Trial 523 finished with value: 14.519886750642282 and parameters: {'x': 0.8769762797324486, 'y': 1.1499384410947422}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,464]\u001b[0m Trial 524 finished with value: 7.693686280856621 and parameters: {'x': 0.7839842040456081, 'y': 0.8911637521026162}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,471]\u001b[0m Trial 525 finished with value: 8.16338586993534 and parameters: {'x': 1.0406501322420951, 'y': 0.7972652209941382}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,478]\u001b[0m Trial 526 finished with value: 0.19127946670621065 and parameters: {'x': 0.9763745304633882, 'y': 0.9969788740264773}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,484]\u001b[0m Trial 527 finished with value: 43.808634612247126 and parameters: {'x': 0.8670567964958292, 'y': 1.413534877591828}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,490]\u001b[0m Trial 528 finished with value: 13.605404119635722 and parameters: {'x': 1.128510935644148, 'y': 0.9049058282016944}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,497]\u001b[0m Trial 529 finished with value: 752.323403057345 and parameters: {'x': 1.293823130898405, 'y': -1.0687157665887868}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,503]\u001b[0m Trial 530 finished with value: 1.4644022194820112 and parameters: {'x': 0.9541711107751316, 'y': 0.7895168317782821}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,511]\u001b[0m Trial 531 finished with value: 85.98208133582388 and parameters: {'x': 0.34424323777211546, 'y': 1.0434469964080648}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,518]\u001b[0m Trial 532 finished with value: 32.74214948929175 and parameters: {'x': 0.8262524632527832, 'y': 1.2546368477687302}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,525]\u001b[0m Trial 533 finished with value: 5.882602809333574 and parameters: {'x': 1.0418940971538018, 'y': 0.8430387180994208}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,531]\u001b[0m Trial 534 finished with value: 1.8895004009123704 and parameters: {'x': 0.9069928462754222, 'y': 0.959780110572572}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,539]\u001b[0m Trial 535 finished with value: 0.810234080132777 and parameters: {'x': 0.79144976246164, 'y': 0.7139564677726147}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,545]\u001b[0m Trial 536 finished with value: 399.38135786887153 and parameters: {'x': 1.1868140963535578, 'y': -0.5898377786866256}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,553]\u001b[0m Trial 537 finished with value: 39.38392323661845 and parameters: {'x': 0.7015076464252287, 'y': 1.1189688270642504}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,561]\u001b[0m Trial 538 finished with value: 79.70654446025468 and parameters: {'x': -0.03994763354504283, 'y': 0.8883035069739469}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,568]\u001b[0m Trial 539 finished with value: 3.9334789930778715 and parameters: {'x': 0.9909003096490385, 'y': 0.7835555086149457}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,576]\u001b[0m Trial 540 finished with value: 3.667780489935084 and parameters: {'x': 0.8999354266243842, 'y': 1.001136682426769}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,583]\u001b[0m Trial 541 finished with value: 22.36791507257242 and parameters: {'x': 1.0871912754474826, 'y': 0.7091179456974072}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,589]\u001b[0m Trial 542 finished with value: 12.116218262155131 and parameters: {'x': 0.7671357147850333, 'y': 0.935800998238616}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,596]\u001b[0m Trial 543 finished with value: 0.6413170161032392 and parameters: {'x': 0.9498817807081461, 'y': 0.8223501084448377}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,602]\u001b[0m Trial 544 finished with value: 46.2074904545913 and parameters: {'x': 0.6268107879423352, 'y': 1.0716275023431816}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,610]\u001b[0m Trial 545 finished with value: 21.77509912239314 and parameters: {'x': 0.8559977114621674, 'y': 1.199147802853667}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,617]\u001b[0m Trial 546 finished with value: 2.6069537636137383 and parameters: {'x': 1.0194044873226662, 'y': 0.8777365314003793}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,624]\u001b[0m Trial 547 finished with value: 1.454896647829371 and parameters: {'x': 0.8989224199751092, 'y': 0.6878666765355814}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,631]\u001b[0m Trial 548 finished with value: 3.055963693696111 and parameters: {'x': 1.075890527834607, 'y': 0.982892086309478}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,638]\u001b[0m Trial 549 finished with value: 0.934371853542042 and parameters: {'x': 0.812729681721352, 'y': 0.7553610535938834}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,644]\u001b[0m Trial 550 finished with value: 1.2168611116963168 and parameters: {'x': 0.9750135712961597, 'y': 0.840368338119032}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,650]\u001b[0m Trial 551 finished with value: 24.338237559066418 and parameters: {'x': 1.190875978597375, 'y': 0.9252169978073949}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,656]\u001b[0m Trial 552 finished with value: 5.415394642837304 and parameters: {'x': 0.9090759546855919, 'y': 1.0589514001280687}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,662]\u001b[0m Trial 553 finished with value: 1.6050710857907562 and parameters: {'x': 0.7189640758887992, 'y': 0.6404443534539572}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,669]\u001b[0m Trial 554 finished with value: 4.272166242358217 and parameters: {'x': 1.0050800348863493, 'y': 0.8034943083487657}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,677]\u001b[0m Trial 555 finished with value: 4.5616917415228215 and parameters: {'x': 0.847156578233022, 'y': 0.9307078482590293}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,684]\u001b[0m Trial 556 finished with value: 28.812089906432433 and parameters: {'x': 1.1262057643333203, 'y': 0.7317188685558165}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,694]\u001b[0m Trial 557 finished with value: 2.3121331661779334 and parameters: {'x': 0.9276247074003836, 'y': 1.0123722574131684}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,705]\u001b[0m Trial 558 finished with value: 6.789886364424334 and parameters: {'x': 0.7787036628799189, 'y': 0.8660121023757764}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,711]\u001b[0m Trial 559 finished with value: 0.03572361754201417 and parameters: {'x': 1.0428647529267137, 'y': 1.1059751058733216}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,718]\u001b[0m Trial 560 finished with value: 14.027862413049139 and parameters: {'x': 1.2450606224469112, 'y': 1.1764406501193787}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,725]\u001b[0m Trial 561 finished with value: 33.512173803435616 and parameters: {'x': 1.3593493604904077, 'y': 1.2700500867481348}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,732]\u001b[0m Trial 562 finished with value: 0.7279444878640413 and parameters: {'x': 1.07255222723623, 'y': 1.0653576536261737}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,739]\u001b[0m Trial 563 finished with value: 4.535675086296387 and parameters: {'x': 1.1588536229324515, 'y': 1.1305637399983843}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,745]\u001b[0m Trial 564 finished with value: 1.347747320098626 and parameters: {'x': 1.0539285251413686, 'y': 1.2267325312212576}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,751]\u001b[0m Trial 565 finished with value: 1.476169289676924 and parameters: {'x': 0.8675064564296447, 'y': 0.631794327842909}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,758]\u001b[0m Trial 566 finished with value: 5.664991633294489 and parameters: {'x': 1.0092765833210915, 'y': 0.7806286004845088}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,766]\u001b[0m Trial 567 finished with value: 34.509809109065515 and parameters: {'x': 0.5216634832565561, 'y': 0.8576326043305009}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,774]\u001b[0m Trial 568 finished with value: 11.733711743797784 and parameters: {'x': 0.9440526200937287, 'y': 0.5487359825797125}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,781]\u001b[0m Trial 569 finished with value: 20.788684083637985 and parameters: {'x': 0.8145786244995679, 'y': 1.119107243530178}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,788]\u001b[0m Trial 570 finished with value: 9.124926680508883 and parameters: {'x': 0.6484705643792688, 'y': 0.7205366342913551}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,794]\u001b[0m Trial 571 finished with value: 9.133363858980779 and parameters: {'x': 1.1081783122581081, 'y': 0.9260382898365089}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,800]\u001b[0m Trial 572 finished with value: 0.010630452542229446 and parameters: {'x': 0.8973475984112942, 'y': 0.8042686740438452}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,807]\u001b[0m Trial 573 finished with value: 0.03351283004336695 and parameters: {'x': 1.0159753326455723, 'y': 1.0139692050304796}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,813]\u001b[0m Trial 574 finished with value: 6.264162893312576 and parameters: {'x': 1.1555754484867193, 'y': 1.0855555144018834}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,821]\u001b[0m Trial 575 finished with value: 0.4800924604926357 and parameters: {'x': 1.0539131422140864, 'y': 1.1798115501129782}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,830]\u001b[0m Trial 576 finished with value: 0.04345774646723864 and parameters: {'x': 1.0072715701667323, 'y': 0.9937621804292512}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,837]\u001b[0m Trial 577 finished with value: 9.788518083134853 and parameters: {'x': 1.158688818805456, 'y': 1.0300964059005155}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,845]\u001b[0m Trial 578 finished with value: 2.899225529365307 and parameters: {'x': 1.2205220200770062, 'y': 1.3208369330503344}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,852]\u001b[0m Trial 579 finished with value: 0.010191744133710042 and parameters: {'x': 1.0725557214110366, 'y': 1.1433562232493633}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,860]\u001b[0m Trial 580 finished with value: 4.903586588537968 and parameters: {'x': 1.2932991591181795, 'y': 1.4531332575570217}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,867]\u001b[0m Trial 581 finished with value: 0.24641692212900498 and parameters: {'x': 1.0859304489008719, 'y': 1.2281359288030964}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,876]\u001b[0m Trial 582 finished with value: 2.2238268400022196 and parameters: {'x': 1.135235188723799, 'y': 1.1402483858175259}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,887]\u001b[0m Trial 583 finished with value: 0.15210149540209356 and parameters: {'x': 1.0596922874936137, 'y': 1.161488414408392}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,895]\u001b[0m Trial 584 finished with value: 13.960419242263917 and parameters: {'x': 1.2044557559215714, 'y': 1.077637039300498}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,909]\u001b[0m Trial 585 finished with value: 0.15344977235899998 and parameters: {'x': 1.0021589180800416, 'y': 1.0434945676774783}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,919]\u001b[0m Trial 586 finished with value: 0.040221070610998194 and parameters: {'x': 1.111296138524529, 'y': 1.2516627042821558}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,929]\u001b[0m Trial 587 finished with value: 20.504925368077036 and parameters: {'x': 1.336056993587983, 'y': 1.3334733675926662}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,939]\u001b[0m Trial 588 finished with value: 3.805918104139491 and parameters: {'x': 1.2518618052868782, 'y': 1.373702978691555}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,946]\u001b[0m Trial 589 finished with value: 0.7442289803436992 and parameters: {'x': 1.1443576393452055, 'y': 1.224502078581679}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,953]\u001b[0m Trial 590 finished with value: 0.9578628289439098 and parameters: {'x': 1.0907847072871508, 'y': 1.2872597751189825}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,961]\u001b[0m Trial 591 finished with value: 2.635816443754634 and parameters: {'x': 1.1914710383823008, 'y': 1.2583842759592025}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,969]\u001b[0m Trial 592 finished with value: 0.011313875900252856 and parameters: {'x': 1.0702650035373367, 'y': 1.1534526052606942}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,977]\u001b[0m Trial 593 finished with value: 0.7386137131629291 and parameters: {'x': 1.0317096919667672, 'y': 1.15030900860184}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,984]\u001b[0m Trial 594 finished with value: 2.3156077744245187 and parameters: {'x': 0.9831833517377029, 'y': 1.118811422639878}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,991]\u001b[0m Trial 595 finished with value: 0.02522477164628184 and parameters: {'x': 1.0674078369782047, 'y': 1.1249786159349358}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:50,998]\u001b[0m Trial 596 finished with value: 17.127050095962968 and parameters: {'x': 1.2647147071913072, 'y': 1.1865023678296447}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,006]\u001b[0m Trial 597 finished with value: 1.1996835998919513 and parameters: {'x': 1.104724712652898, 'y': 1.1113884221891204}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,013]\u001b[0m Trial 598 finished with value: 3.78230179806373 and parameters: {'x': 1.1800874921671685, 'y': 1.1989606709024208}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,020]\u001b[0m Trial 599 finished with value: 0.2942977006177792 and parameters: {'x': 1.0493727678028046, 'y': 1.0471591342808007}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,027]\u001b[0m Trial 600 finished with value: 1.9652906104570564 and parameters: {'x': 1.0742051523700902, 'y': 1.293909002231262}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,035]\u001b[0m Trial 601 finished with value: 2.708096361120078 and parameters: {'x': 0.9794589769002305, 'y': 1.1238900143671975}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,044]\u001b[0m Trial 602 finished with value: 10.357886267341216 and parameters: {'x': 1.1826532675991661, 'y': 1.0773507772131317}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,054]\u001b[0m Trial 603 finished with value: 662.3293278632984 and parameters: {'x': 1.0427884911060616, 'y': -1.4861645768131464}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,063]\u001b[0m Trial 604 finished with value: 4.453502075713566 and parameters: {'x': 1.1202650126008715, 'y': 1.0443034423360513}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,077]\u001b[0m Trial 605 finished with value: 3.9387953996310587 and parameters: {'x': 0.9827566690412126, 'y': 1.1642671662101127}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,086]\u001b[0m Trial 606 finished with value: 0.6489933348858492 and parameters: {'x': 0.9436674182413406, 'y': 0.9708711214781616}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,093]\u001b[0m Trial 607 finished with value: 0.4711128269106094 and parameters: {'x': 1.038706949547633, 'y': 1.010383695058288}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,102]\u001b[0m Trial 608 finished with value: 2.2097048571893754 and parameters: {'x': 1.127759405004654, 'y': 1.1237405533762461}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,111]\u001b[0m Trial 609 finished with value: 10.557763695842004 and parameters: {'x': 1.246487615419499, 'y': 1.229740518250244}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,119]\u001b[0m Trial 610 finished with value: 0.5474686988205018 and parameters: {'x': 0.9533658276161574, 'y': 0.982750422878459}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,130]\u001b[0m Trial 611 finished with value: 0.01363313250848471 and parameters: {'x': 1.0276557258825652, 'y': 1.0447324409162388}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,138]\u001b[0m Trial 612 finished with value: 0.5014342371289222 and parameters: {'x': 0.9399167635441693, 'y': 0.9540001834394648}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,146]\u001b[0m Trial 613 finished with value: 85.91136484364901 and parameters: {'x': 1.4002608771847211, 'y': 1.034711323110538}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,157]\u001b[0m Trial 614 finished with value: 0.6910081207025222 and parameters: {'x': 0.9145361439797892, 'y': 0.9190627571651709}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,168]\u001b[0m Trial 615 finished with value: 0.003972945130143798 and parameters: {'x': 1.0152760040347706, 'y': 1.0246701466041905}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,176]\u001b[0m Trial 616 finished with value: 2.756249538802753 and parameters: {'x': 1.1199898938536212, 'y': 1.0887919775874104}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,184]\u001b[0m Trial 617 finished with value: 0.4489696961881613 and parameters: {'x': 1.031792024138814, 'y': 0.9976650445321429}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,191]\u001b[0m Trial 618 finished with value: 10.805822129896832 and parameters: {'x': 1.1763126204795071, 'y': 1.0554624513256874}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,198]\u001b[0m Trial 619 finished with value: 0.007194845457499948 and parameters: {'x': 1.0766349403136533, 'y': 1.1627786321326488}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,206]\u001b[0m Trial 620 finished with value: 0.4339970020660673 and parameters: {'x': 1.115541653807814, 'y': 1.3092904961798713}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,213]\u001b[0m Trial 621 finished with value: 6.735908088395917 and parameters: {'x': 1.2089873450430284, 'y': 1.2029569065860028}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,221]\u001b[0m Trial 622 finished with value: 0.20216841792138027 and parameters: {'x': 1.0711194533917814, 'y': 1.1916940051057225}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,230]\u001b[0m Trial 623 finished with value: 18.36379782050299 and parameters: {'x': 0.9792334834799198, 'y': 1.3874232036145704}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,239]\u001b[0m Trial 624 finished with value: 20.389157159060552 and parameters: {'x': 1.284405815175944, 'y': 1.1990513132531047}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,248]\u001b[0m Trial 625 finished with value: 2.5171602203281345 and parameters: {'x': 1.1322966269799926, 'y': 1.12399258942472}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,260]\u001b[0m Trial 626 finished with value: 70.4833105080257 and parameters: {'x': 0.9127263711499503, 'y': 1.6725674561169401}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,269]\u001b[0m Trial 627 finished with value: 6.087115029139875 and parameters: {'x': 1.0297945243966826, 'y': 1.307179565774309}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,282]\u001b[0m Trial 628 finished with value: 0.13443827223609756 and parameters: {'x': 1.2176019691832063, 'y': 1.4530439377367372}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,293]\u001b[0m Trial 629 finished with value: 0.2445797130063701 and parameters: {'x': 1.0740668170895666, 'y': 1.1047223068326097}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,306]\u001b[0m Trial 630 finished with value: 82.4602603854124 and parameters: {'x': 0.9648522190661953, 'y': 1.839009323004954}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,324]\u001b[0m Trial 631 finished with value: 427.4507579237031 and parameters: {'x': -0.42076000264000046, 'y': -1.8855618030217405}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,337]\u001b[0m Trial 632 finished with value: 2.066057391469042 and parameters: {'x': 0.9082841093105142, 'y': 0.9684249808530949}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,345]\u001b[0m Trial 633 finished with value: 4.395205506374149 and parameters: {'x': 1.0128396205389854, 'y': 1.2354876193834174}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,354]\u001b[0m Trial 634 finished with value: 2.5106917640284654 and parameters: {'x': 1.1395673737767729, 'y': 1.140778039416794}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,364]\u001b[0m Trial 635 finished with value: 5.337108525562858 and parameters: {'x': 0.903237436748709, 'y': 1.0466569636662193}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,374]\u001b[0m Trial 636 finished with value: 75.39014945664587 and parameters: {'x': 1.3427700200577193, 'y': 0.9354331584298234}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,383]\u001b[0m Trial 637 finished with value: 15.381769189698536 and parameters: {'x': 1.060624206879413, 'y': 1.5170728366791577}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,390]\u001b[0m Trial 638 finished with value: 0.07680930006299626 and parameters: {'x': 0.9753175149180969, 'y': 0.9236398938387501}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,398]\u001b[0m Trial 639 finished with value: 10.101664857699298 and parameters: {'x': 0.8629012516990184, 'y': 1.0621339035076576}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,406]\u001b[0m Trial 640 finished with value: 0.012671607290431867 and parameters: {'x': 1.0780437184559672, 'y': 1.170290462856904}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,413]\u001b[0m Trial 641 finished with value: 6.805978809773687 and parameters: {'x': 1.1821249913608993, 'y': 1.1371732791411464}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,420]\u001b[0m Trial 642 finished with value: 0.038632856563964375 and parameters: {'x': 1.119930116980089, 'y': 1.2386711762702243}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,427]\u001b[0m Trial 643 finished with value: 69.25908618412873 and parameters: {'x': 1.4797670749961358, 'y': 1.3588742120015442}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,434]\u001b[0m Trial 644 finished with value: 29.94602936124883 and parameters: {'x': 1.2737198812005408, 'y': 1.0758176734744642}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,442]\u001b[0m Trial 645 finished with value: 10.998476390524788 and parameters: {'x': -0.9990903065693869, 'y': 1.262796525978502}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,449]\u001b[0m Trial 646 finished with value: 0.3133904024979338 and parameters: {'x': 1.0897328911188024, 'y': 1.242775208847834}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,455]\u001b[0m Trial 647 finished with value: 8.13624996686507 and parameters: {'x': 1.207210151113078, 'y': 1.172868846234774}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,463]\u001b[0m Trial 648 finished with value: 0.34888527398200225 and parameters: {'x': 1.044670740969606, 'y': 1.1502343083267517}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,470]\u001b[0m Trial 649 finished with value: 9.068726344923439 and parameters: {'x': 1.0000514570081072, 'y': 1.3012461772938522}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,477]\u001b[0m Trial 650 finished with value: 7.666355702502358 and parameters: {'x': 1.1365551601104151, 'y': 1.015212728011351}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,485]\u001b[0m Trial 651 finished with value: 5.369679007394259 and parameters: {'x': 0.976242966515976, 'y': 1.184763829726491}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,492]\u001b[0m Trial 652 finished with value: 244.08981673670894 and parameters: {'x': 1.6251253353066142, 'y': 1.0799460828495082}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,498]\u001b[0m Trial 653 finished with value: 5.295400112306834 and parameters: {'x': 1.102425056389835, 'y': 0.9854517007218891}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,509]\u001b[0m Trial 654 finished with value: 12.074987688446871 and parameters: {'x': 1.2052179533288416, 'y': 1.1056659930962367}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,517]\u001b[0m Trial 655 finished with value: 1.4617708970171783 and parameters: {'x': 1.0536232474354967, 'y': 0.9893372032866107}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,530]\u001b[0m Trial 656 finished with value: 0.03717399306436496 and parameters: {'x': 0.9579438169859696, 'y': 0.9364726448005285}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,542]\u001b[0m Trial 657 finished with value: 12.38144170298557 and parameters: {'x': 0.898909159610566, 'y': 1.1597651618697382}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,552]\u001b[0m Trial 658 finished with value: 79.79960878861432 and parameters: {'x': 0.09101408750877577, 'y': 0.8969530943752309}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,560]\u001b[0m Trial 659 finished with value: 0.07725447801173277 and parameters: {'x': 1.0306439532184064, 'y': 1.0346017114935762}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,569]\u001b[0m Trial 660 finished with value: 0.039033064933617204 and parameters: {'x': 1.1389903566272965, 'y': 1.3113399532924854}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,578]\u001b[0m Trial 661 finished with value: 55.55338857198301 and parameters: {'x': 1.2732769818653418, 'y': 0.8763939657496326}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,589]\u001b[0m Trial 662 finished with value: 604.5854755089259 and parameters: {'x': 1.8809564182537206, 'y': 1.0807437203845027}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,599]\u001b[0m Trial 663 finished with value: 0.26183598736221547 and parameters: {'x': 0.964916675371032, 'y': 0.9821136906706154}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,610]\u001b[0m Trial 664 finished with value: 0.03882347740531264 and parameters: {'x': 1.0648992567408029, 'y': 1.1526146103753259}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,620]\u001b[0m Trial 665 finished with value: 2.4526248941493973 and parameters: {'x': 0.877579065420702, 'y': 0.9262743857849828}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,630]\u001b[0m Trial 666 finished with value: 0.6801137188545436 and parameters: {'x': 0.9716109237937827, 'y': 1.0264479170100387}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,640]\u001b[0m Trial 667 finished with value: 23.29357770482888 and parameters: {'x': 1.1623505031017907, 'y': 0.8686976237835857}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,650]\u001b[0m Trial 668 finished with value: 120.84079714467488 and parameters: {'x': -0.5313839089142289, 'y': 1.3709259791946184}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,659]\u001b[0m Trial 669 finished with value: 0.8147359513786379 and parameters: {'x': 1.0636235876759996, 'y': 1.2213333498408816}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,669]\u001b[0m Trial 670 finished with value: 56.486499567804664 and parameters: {'x': 0.8999943347781897, 'y': 0.05848133006098148}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,677]\u001b[0m Trial 671 finished with value: 0.5536038844167371 and parameters: {'x': 1.0010711759612207, 'y': 1.076547984218566}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,689]\u001b[0m Trial 672 finished with value: 1.4992868762188696 and parameters: {'x': 0.9245225181032608, 'y': 0.9769544073583967}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,700]\u001b[0m Trial 673 finished with value: 2.8440595020565302 and parameters: {'x': 0.837485721627095, 'y': 0.8692408639889901}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,711]\u001b[0m Trial 674 finished with value: 46.63471262518029 and parameters: {'x': -1.3491338124884904, 'y': 1.1789422458321774}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,721]\u001b[0m Trial 675 finished with value: 6.46248205475187 and parameters: {'x': 1.0939269823951407, 'y': 0.9426356992619009}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,733]\u001b[0m Trial 676 finished with value: 19.13697299304501 and parameters: {'x': 1.2143595961544333, 'y': 1.0377364770063513}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,743]\u001b[0m Trial 677 finished with value: 789.2197245959089 and parameters: {'x': -1.9055183761773744, 'y': 0.8367603359865261}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,752]\u001b[0m Trial 678 finished with value: 2.281409608059702 and parameters: {'x': 0.9843030319455538, 'y': 1.1198876603309218}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,764]\u001b[0m Trial 679 finished with value: 3.310654430185618 and parameters: {'x': 0.8606442660903668, 'y': 0.9221261486376499}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,773]\u001b[0m Trial 680 finished with value: 1.1209530990201437 and parameters: {'x': 1.0431949169564374, 'y': 0.9824687122180353}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,783]\u001b[0m Trial 681 finished with value: 17.08473671350362 and parameters: {'x': -0.6766569945990597, 'y': 0.8356683150556916}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,792]\u001b[0m Trial 682 finished with value: 0.47538366934750637 and parameters: {'x': 1.1424825252096291, 'y': 1.2378065250229784}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,800]\u001b[0m Trial 683 finished with value: 5.402163179465366 and parameters: {'x': 0.919962927701359, 'y': 1.0786194816590569}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,808]\u001b[0m Trial 684 finished with value: 56.13736653839889 and parameters: {'x': 1.329548592002493, 'y': 1.0191758164917124}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,815]\u001b[0m Trial 685 finished with value: 9.428923849516366 and parameters: {'x': 0.7742610374960898, 'y': 0.905714799029353}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,824]\u001b[0m Trial 686 finished with value: 1.4899156200350336 and parameters: {'x': 1.0116214074096619, 'y': 1.1454344392630513}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,831]\u001b[0m Trial 687 finished with value: 0.28683587000529487 and parameters: {'x': 0.9450153410507904, 'y': 0.8397799338455222}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,840]\u001b[0m Trial 688 finished with value: 1.5234907169488736 and parameters: {'x': 1.0777078279067422, 'y': 1.2846390725449717}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,847]\u001b[0m Trial 689 finished with value: 9.373905402724725 and parameters: {'x': 0.822792741799913, 'y': 0.9826429791875078}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,855]\u001b[0m Trial 690 finished with value: 0.4662797451996295 and parameters: {'x': 1.0065160866349625, 'y': 1.0813562030685486}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,863]\u001b[0m Trial 691 finished with value: 12.782731434431511 and parameters: {'x': 1.1391806258546926, 'y': 0.940474045829005}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,872]\u001b[0m Trial 692 finished with value: 17.77353013415034 and parameters: {'x': 0.8798745908676975, 'y': 1.1955947678460108}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,879]\u001b[0m Trial 693 finished with value: 42.32852505557337 and parameters: {'x': 1.2115396653033574, 'y': 0.8175685969275253}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,887]\u001b[0m Trial 694 finished with value: 0.02237904768093245 and parameters: {'x': 0.9531283644816304, 'y': 0.894247308261855}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,895]\u001b[0m Trial 695 finished with value: 0.9659847566053774 and parameters: {'x': 1.0745063741016352, 'y': 1.0565622359171611}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,903]\u001b[0m Trial 696 finished with value: 0.33693370734630546 and parameters: {'x': 0.9708939803025681, 'y': 1.0006080928767118}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,910]\u001b[0m Trial 697 finished with value: 6.598385554845192 and parameters: {'x': 1.0755090612786842, 'y': 0.8999575174929683}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,918]\u001b[0m Trial 698 finished with value: 5.992587730523679 and parameters: {'x': 0.9424877194803896, 'y': 1.1330131581300753}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,925]\u001b[0m Trial 699 finished with value: 19.409565781764517 and parameters: {'x': 1.1660831194409549, 'y': 0.9195001148217093}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,932]\u001b[0m Trial 700 finished with value: 439.7162370914798 and parameters: {'x': 1.7621336324137504, 'y': 1.0095591901967869}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,940]\u001b[0m Trial 701 finished with value: 21.64118316538196 and parameters: {'x': 1.0201305676316483, 'y': 1.5058628703346173}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,951]\u001b[0m Trial 702 finished with value: 8.614049656107065 and parameters: {'x': 0.9132972299000051, 'y': 1.127480749522088}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,964]\u001b[0m Trial 703 finished with value: 11.37653803181327 and parameters: {'x': 1.103426513041053, 'y': 0.8804174401692564}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,975]\u001b[0m Trial 704 finished with value: 0.04385364027203567 and parameters: {'x': 1.0147800889166934, 'y': 1.0506676664757097}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,984]\u001b[0m Trial 705 finished with value: 11.092213229054904 and parameters: {'x': 1.248991647509595, 'y': 1.2278624397159845}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:51,993]\u001b[0m Trial 706 finished with value: 8.82420994011463 and parameters: {'x': 0.8142648858701425, 'y': 0.9595017958016749}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,004]\u001b[0m Trial 707 finished with value: 0.6562847173378044 and parameters: {'x': 0.9416536017881678, 'y': 0.8059104899778119}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,015]\u001b[0m Trial 708 finished with value: 9.588559241755732 and parameters: {'x': 1.0129835823665072, 'y': 1.3357870043831317}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,027]\u001b[0m Trial 709 finished with value: 8.663024160029991 and parameters: {'x': 0.8899022258575224, 'y': 1.0860501399259892}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,040]\u001b[0m Trial 710 finished with value: 230.55578077707642 and parameters: {'x': 1.062313297956568, 'y': -0.38988400883466756}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,051]\u001b[0m Trial 711 finished with value: 14.80125061687338 and parameters: {'x': 1.1602378597301972, 'y': 0.9617617970387984}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,060]\u001b[0m Trial 712 finished with value: 8.786835017631692 and parameters: {'x': 0.760292308579295, 'y': 0.8734995558935568}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,071]\u001b[0m Trial 713 finished with value: 20.037266873720327 and parameters: {'x': 0.8550577361045403, 'y': 1.17851906747322}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,085]\u001b[0m Trial 714 finished with value: 0.5441293536360007 and parameters: {'x': 0.9617175052009519, 'y': 0.9985662780395211}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,099]\u001b[0m Trial 715 finished with value: 13.260800610000574 and parameters: {'x': 1.0746797071387844, 'y': 0.7908592345462693}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,109]\u001b[0m Trial 716 finished with value: 113.34756140006832 and parameters: {'x': 1.4018249662564104, 'y': 0.9012236830277408}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,118]\u001b[0m Trial 717 finished with value: 0.4068924377539263 and parameters: {'x': 0.9983789282559017, 'y': 1.0605483993756522}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,126]\u001b[0m Trial 718 finished with value: 25.007091660353282 and parameters: {'x': 1.158521414325641, 'y': 0.8423522737819931}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,139]\u001b[0m Trial 719 finished with value: 13.9289090549102 and parameters: {'x': 0.8703359885884328, 'y': 1.1304739594054989}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,149]\u001b[0m Trial 720 finished with value: 7.818639561831572 and parameters: {'x': 1.2481539292523305, 'y': 1.2793732550434005}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,157]\u001b[0m Trial 721 finished with value: 1.3077871504479728 and parameters: {'x': 0.9217384546647258, 'y': 0.9636921938726866}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,167]\u001b[0m Trial 722 finished with value: 3.188096291805891 and parameters: {'x': 1.1000938248506174, 'y': 1.0319347903402836}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,177]\u001b[0m Trial 723 finished with value: 4.332873743943065 and parameters: {'x': 0.7779059746047658, 'y': 0.8121050454504297}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,188]\u001b[0m Trial 724 finished with value: 0.26395203743779727 and parameters: {'x': 0.9971295543614349, 'y': 0.9428918873091707}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,199]\u001b[0m Trial 725 finished with value: 28.224785692429005 and parameters: {'x': 0.9342590180894134, 'y': 1.40406927780512}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,208]\u001b[0m Trial 726 finished with value: 372.491400774842 and parameters: {'x': 0.8327040340268443, 'y': -1.2365351118194798}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,219]\u001b[0m Trial 727 finished with value: 0.0979515120469429 and parameters: {'x': 1.0420412555427219, 'y': 1.1168635309162565}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,227]\u001b[0m Trial 728 finished with value: 14.013216924899318 and parameters: {'x': 1.1237657926625437, 'y': 0.888711895549851}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,237]\u001b[0m Trial 729 finished with value: 37.56997794183841 and parameters: {'x': 0.7380363109449768, 'y': -0.06768588625589682}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,248]\u001b[0m Trial 730 finished with value: 7.373131681429495 and parameters: {'x': 0.9510173606506424, 'y': 1.1759249479613303}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,258]\u001b[0m Trial 731 finished with value: 8.66488261595888 and parameters: {'x': 0.8470444395472672, 'y': 1.0114483486114907}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,267]\u001b[0m Trial 732 finished with value: 7.3050297392096 and parameters: {'x': 1.0214461014752367, 'y': 0.7730824617115661}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,275]\u001b[0m Trial 733 finished with value: 0.865877913644046 and parameters: {'x': 1.1567672325027822, 'y': 1.2463879166822411}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,283]\u001b[0m Trial 734 finished with value: 0.3252953829101093 and parameters: {'x': 0.9090748643250336, 'y': 0.8827223487226292}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,292]\u001b[0m Trial 735 finished with value: 46.956119453778626 and parameters: {'x': 1.3098348045983297, 'y': 1.0311226817409864}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,299]\u001b[0m Trial 736 finished with value: 4.656301939666812 and parameters: {'x': 1.0726368408148905, 'y': 0.934887421215641}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,309]\u001b[0m Trial 737 finished with value: 3.022810477437379 and parameters: {'x': 0.9854999994899059, 'y': 0.7973539799841777}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,317]\u001b[0m Trial 738 finished with value: 26.697852303170983 and parameters: {'x': 1.2139488648473833, 'y': 1.989928354281842}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,326]\u001b[0m Trial 739 finished with value: 10.442504558811882 and parameters: {'x': 0.8716924350904396, 'y': 1.0827415187332674}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,338]\u001b[0m Trial 740 finished with value: 3.805907107326935 and parameters: {'x': 1.0793232010591987, 'y': 0.9700125623536879}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,349]\u001b[0m Trial 741 finished with value: 6.678574338900174 and parameters: {'x': 0.9572779306532284, 'y': 1.1747750992124328}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,358]\u001b[0m Trial 742 finished with value: 66.62281356678454 and parameters: {'x': 0.17916833716727565, 'y': 0.8441914909158863}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,366]\u001b[0m Trial 743 finished with value: 20.549745282540407 and parameters: {'x': 0.8007453088470452, 'y': 1.0940731976995473}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,381]\u001b[0m Trial 744 finished with value: 8.238059657671341 and parameters: {'x': 1.0222063167474802, 'y': 0.7578941420875752}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,393]\u001b[0m Trial 745 finished with value: 0.6142643813645184 and parameters: {'x': 0.9134704507023179, 'y': 0.9123241575525292}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,406]\u001b[0m Trial 746 finished with value: 7.411315371590248 and parameters: {'x': 1.1327832352131577, 'y': 1.0112845632694025}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,421]\u001b[0m Trial 747 finished with value: 4.265895611948888 and parameters: {'x': 1.0062075979002216, 'y': 1.218993243910944}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,437]\u001b[0m Trial 748 finished with value: 1.7712640377892759 and parameters: {'x': 0.8472174740278906, 'y': 0.8499864320151488}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,450]\u001b[0m Trial 749 finished with value: 22.39748954408799 and parameters: {'x': 0.7003629907035183, 'y': 0.9628186744112022}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,466]\u001b[0m Trial 750 finished with value: 1.7737606431310153 and parameters: {'x': 1.094021250180869, 'y': 1.0640321797902754}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,479]\u001b[0m Trial 751 finished with value: 16.123632215924314 and parameters: {'x': 0.9467031206164779, 'y': 1.2977538552922325}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,883]\u001b[0m Trial 752 finished with value: 13.793127212675124 and parameters: {'x': 1.2256594798897553, 'y': 1.1315363587889555}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,896]\u001b[0m Trial 753 finished with value: 1059.9042739433162 and parameters: {'x': 1.54334348283711, 'y': -0.8732545639138504}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,909]\u001b[0m Trial 754 finished with value: 8.032709712379589 and parameters: {'x': 1.0247621610109694, 'y': 0.7667279499661451}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,920]\u001b[0m Trial 755 finished with value: 9.647675471829206 and parameters: {'x': 0.7726241022203181, 'y': 0.9067217219222438}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,931]\u001b[0m Trial 756 finished with value: 4.028073624997874 and parameters: {'x': 0.8915962232184336, 'y': 0.9953514659844032}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,946]\u001b[0m Trial 757 finished with value: 56.291982830618586 and parameters: {'x': -0.3450420543616758, 'y': 0.8571789728098235}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,960]\u001b[0m Trial 758 finished with value: 10.343986849232207 and parameters: {'x': 1.1721083385179871, 'y': 1.052678097199688}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,969]\u001b[0m Trial 759 finished with value: 4.651922043106892 and parameters: {'x': 0.9962346705177583, 'y': 1.2081663383031478}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,980]\u001b[0m Trial 760 finished with value: 0.5042481480665453 and parameters: {'x': 0.9281688531867601, 'y': 0.9321436113185531}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,990]\u001b[0m Trial 761 finished with value: 100.22671097223068 and parameters: {'x': 1.0913562632440557, 'y': 0.18996726368610395}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:52,998]\u001b[0m Trial 762 finished with value: 1.0154998729786548 and parameters: {'x': 0.8362150043165764, 'y': 0.7986876383282401}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,006]\u001b[0m Trial 763 finished with value: 0.00902949100821716 and parameters: {'x': 1.0631197143946927, 'y': 1.1231204343836396}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,015]\u001b[0m Trial 764 finished with value: 13.396479990818808 and parameters: {'x': 1.2999695032213352, 'y': 1.3251399767009102}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,022]\u001b[0m Trial 765 finished with value: 7.68532711609416 and parameters: {'x': 1.2012332584892726, 'y': 1.166468442806564}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,031]\u001b[0m Trial 766 finished with value: 1.2047175743284952 and parameters: {'x': 1.1156612640956296, 'y': 1.1355515314165288}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,038]\u001b[0m Trial 767 finished with value: 0.7333492308875965 and parameters: {'x': 1.0640051224444194, 'y': 1.217503187110767}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,046]\u001b[0m Trial 768 finished with value: 2.1277531015242666 and parameters: {'x': 1.1220641047514945, 'y': 1.113671277891779}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,054]\u001b[0m Trial 769 finished with value: 2.5703288042538 and parameters: {'x': 1.1961734237808317, 'y': 1.2717131425796055}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,061]\u001b[0m Trial 770 finished with value: 11.442066827471795 and parameters: {'x': 1.0160657095622356, 'y': 1.3706469535677424}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,069]\u001b[0m Trial 771 finished with value: 0.14401342387316818 and parameters: {'x': 1.0441837222691759, 'y': 1.0526286359742751}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,077]\u001b[0m Trial 772 finished with value: 3.1160494876834037 and parameters: {'x': 0.9714679432621198, 'y': 1.1202502596701547}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,086]\u001b[0m Trial 773 finished with value: 11.184989891290645 and parameters: {'x': 1.2494387876501594, 'y': 1.2275891105340917}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,094]\u001b[0m Trial 774 finished with value: 6.529548129689853 and parameters: {'x': 1.1406522265962764, 'y': 1.0459450892409479}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,102]\u001b[0m Trial 775 finished with value: 2.417901202523682 and parameters: {'x': 1.068055290990546, 'y': 0.9853950840463029}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,110]\u001b[0m Trial 776 finished with value: 7.682692432821422 and parameters: {'x': 0.9511821376281304, 'y': 1.1818811676311505}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,119]\u001b[0m Trial 777 finished with value: 0.7847567277005635 and parameters: {'x': 1.0094150482583355, 'y': 1.1075002323317984}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,128]\u001b[0m Trial 778 finished with value: 5.180388775824264 and parameters: {'x': 0.8848503742220778, 'y': 1.0102733902618077}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,137]\u001b[0m Trial 779 finished with value: 65.02442360346083 and parameters: {'x': 1.3801584410870384, 'y': 1.0993567009918332}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,144]\u001b[0m Trial 780 finished with value: 10.023211290439061 and parameters: {'x': 1.1312856162423515, 'y': 0.9634849145970528}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,153]\u001b[0m Trial 781 finished with value: 56.349197975203246 and parameters: {'x': 1.0556429648210366, 'y': 1.8650224746678137}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,162]\u001b[0m Trial 782 finished with value: 15.00139528193313 and parameters: {'x': 0.9418027319677986, 'y': 1.2742650077464264}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,174]\u001b[0m Trial 783 finished with value: 18.31774182278568 and parameters: {'x': 0.7927320975255112, 'y': 1.0559143168058436}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,183]\u001b[0m Trial 784 finished with value: 3.5841164910562044 and parameters: {'x': 1.167291433096064, 'y': 1.1739922480307687}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,191]\u001b[0m Trial 785 finished with value: 4.036769088289939 and parameters: {'x': 0.8710093505418481, 'y': 0.9591599196527817}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,199]\u001b[0m Trial 786 finished with value: 0.6297541295438305 and parameters: {'x': 0.9910360171388759, 'y': 0.902800400740937}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,206]\u001b[0m Trial 787 finished with value: 14.01052678605555 and parameters: {'x': -1.1537158216834538, 'y': 1.0249224023213057}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,215]\u001b[0m Trial 788 finished with value: 0.013692330194285996 and parameters: {'x': 1.067908035943512, 'y': 1.1499569115353507}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,223]\u001b[0m Trial 789 finished with value: 70.39177292931143 and parameters: {'x': 0.7332949501003792, 'y': 1.376295519606224}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,237]\u001b[0m Trial 790 finished with value: 110.38421696299291 and parameters: {'x': 0.42828470442366284, 'y': 1.2325100468952428}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,250]\u001b[0m Trial 791 finished with value: 0.7517675103702858 and parameters: {'x': 1.24351620193871, 'y': 1.4631179201825957}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,265]\u001b[0m Trial 792 finished with value: 0.014056633275759324 and parameters: {'x': 0.9423000161372486, 'y': 0.8775720306422479}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,277]\u001b[0m Trial 793 finished with value: 0.40234361561698045 and parameters: {'x': 0.9003382210138671, 'y': 0.7479661835560794}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,285]\u001b[0m Trial 794 finished with value: 12.290178898813227 and parameters: {'x': 1.0966501947689036, 'y': 0.8522013888908523}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,297]\u001b[0m Trial 795 finished with value: 1.8490123129681952 and parameters: {'x': 1.0140447448733152, 'y': 1.1642578833850632}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,307]\u001b[0m Trial 796 finished with value: 11.664015065786645 and parameters: {'x': 0.8309493645395918, 'y': 1.0315844093533673}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,316]\u001b[0m Trial 797 finished with value: 0.029260675354931907 and parameters: {'x': 0.9720764189456923, 'y': 0.9618088639168373}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,325]\u001b[0m Trial 798 finished with value: 333.3492271463342 and parameters: {'x': 1.1570859310670147, 'y': -0.4868699553373984}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,336]\u001b[0m Trial 799 finished with value: 95.69587298466799 and parameters: {'x': 0.8794503757116268, 'y': -0.20473543102205805}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,349]\u001b[0m Trial 800 finished with value: 4.256754878639056 and parameters: {'x': 1.061674905672291, 'y': 1.3333804485106442}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,361]\u001b[0m Trial 801 finished with value: 4.687825992764462 and parameters: {'x': 0.6940937058908928, 'y': 0.6961080267331257}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,371]\u001b[0m Trial 802 finished with value: 3.86089235188768 and parameters: {'x': 0.9426570957087959, 'y': 1.0850102447200123}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,380]\u001b[0m Trial 803 finished with value: 3.0805609718815163 and parameters: {'x': 0.8034560628287477, 'y': 0.819952982046205}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,396]\u001b[0m Trial 804 finished with value: 60.2581059537253 and parameters: {'x': 1.2964831112079842, 'y': 0.9051739061745094}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,405]\u001b[0m Trial 805 finished with value: 1.8043411111886627 and parameters: {'x': 1.0370759697837666, 'y': 1.2098011545591394}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,417]\u001b[0m Trial 806 finished with value: 11.790824779132784 and parameters: {'x': 1.1636395506536696, 'y': 1.0110694402721772}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,427]\u001b[0m Trial 807 finished with value: 654.3593841816946 and parameters: {'x': 0.8889823399386823, 'y': -1.7677312343385978}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,436]\u001b[0m Trial 808 finished with value: 1.489458788009531 and parameters: {'x': 0.9894879692179884, 'y': 1.1011252991871496}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,446]\u001b[0m Trial 809 finished with value: 27.2021300943325 and parameters: {'x': 1.1299501900127074, 'y': 0.755392734559961}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,454]\u001b[0m Trial 810 finished with value: 3.148010769932415 and parameters: {'x': 1.057148809426781, 'y': 0.9402293225318261}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,463]\u001b[0m Trial 811 finished with value: 3.237695260748857 and parameters: {'x': 0.8059481457309398, 'y': 0.8284389457610056}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,472]\u001b[0m Trial 812 finished with value: 41.494552019324544 and parameters: {'x': 0.6159437693295057, 'y': 1.0224034672789803}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,481]\u001b[0m Trial 813 finished with value: 9.711454820464779 and parameters: {'x': 0.9177652014069235, 'y': 1.15381651552187}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,492]\u001b[0m Trial 814 finished with value: 9.305559942290408 and parameters: {'x': 0.9782488321424013, 'y': 1.2620131816728344}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,503]\u001b[0m Trial 815 finished with value: 618.4503511659726 and parameters: {'x': 1.2253430932211398, 'y': -0.9852984094273965}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,520]\u001b[0m Trial 816 finished with value: 9.181885787809252 and parameters: {'x': 1.097506944634682, 'y': 0.9016621502024261}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,533]\u001b[0m Trial 817 finished with value: 6.15917616709651 and parameters: {'x': 0.8584387948981465, 'y': 0.9846899756915698}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,550]\u001b[0m Trial 818 finished with value: 28.04350894265284 and parameters: {'x': 0.7517452757230315, 'y': 1.0940999623170624}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,566]\u001b[0m Trial 819 finished with value: 3.7400443348080796 and parameters: {'x': 0.997070244768489, 'y': 0.8007573526178146}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,579]\u001b[0m Trial 820 finished with value: 0.3073588482902165 and parameters: {'x': 0.9179020855439165, 'y': 0.897372951993184}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,592]\u001b[0m Trial 821 finished with value: 17.843659386634457 and parameters: {'x': 1.0745896847701997, 'y': 0.7323912916057367}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,602]\u001b[0m Trial 822 finished with value: 0.8127713631900262 and parameters: {'x': 0.9904155421738727, 'y': 1.0710716844601549}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,611]\u001b[0m Trial 823 finished with value: 5.907669526589158 and parameters: {'x': 1.1909454057960787, 'y': 1.1760451738821416}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,620]\u001b[0m Trial 824 finished with value: 6.839476041955476 and parameters: {'x': 0.8422826080320007, 'y': 0.9704879043729736}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,630]\u001b[0m Trial 825 finished with value: 1.4905511834716731 and parameters: {'x': 1.081487935742958, 'y': 1.2914320367083716}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,640]\u001b[0m Trial 826 finished with value: 0.00637658641106136 and parameters: {'x': 0.9224471772787066, 'y': 0.8490057812094369}. Best is trial 206 with value: 0.0008187613312552456.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,651]\u001b[0m Trial 827 finished with value: 0.00025181702927100575 and parameters: {'x': 1.0157192967949913, 'y': 1.0319029624649332}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,661]\u001b[0m Trial 828 finished with value: 3.566322861632617 and parameters: {'x': 1.151563168774932, 'y': 1.1378598112828977}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,669]\u001b[0m Trial 829 finished with value: 11.510201205651867 and parameters: {'x': 1.239134058463985, 'y': 1.1970301643932681}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,680]\u001b[0m Trial 830 finished with value: 0.11959252466219275 and parameters: {'x': 1.0490381957402641, 'y': 1.0662484353782946}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,691]\u001b[0m Trial 831 finished with value: 4.827636587121382 and parameters: {'x': 1.1202765254790408, 'y': 1.035630110374662}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,700]\u001b[0m Trial 832 finished with value: 1.308344286335386 and parameters: {'x': 1.0120387439331884, 'y': 1.138598962052111}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,709]\u001b[0m Trial 833 finished with value: 49.972538745840204 and parameters: {'x': 1.3062004239486524, 'y': 0.9999104410023364}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,718]\u001b[0m Trial 834 finished with value: 0.10245109261606063 and parameters: {'x': 1.1007881973008138, 'y': 1.24211439065152}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,728]\u001b[0m Trial 835 finished with value: 0.9616072230317877 and parameters: {'x': 0.9922251140467151, 'y': 1.0825691683764171}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,738]\u001b[0m Trial 836 finished with value: 14.827164923262872 and parameters: {'x': 1.1606605238371412, 'y': 0.9624075844311791}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,746]\u001b[0m Trial 837 finished with value: 318.0645776057885 and parameters: {'x': 1.0540574687974653, 'y': -0.6723911672521476}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,754]\u001b[0m Trial 838 finished with value: 110.71848950022259 and parameters: {'x': -0.11675356200996101, 'y': 1.0599169718065746}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,762]\u001b[0m Trial 839 finished with value: 8.912903471144379 and parameters: {'x': 0.9383520000690929, 'y': 1.1789856813925454}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,770]\u001b[0m Trial 840 finished with value: 12.689046366906474 and parameters: {'x': 0.979249931172665, 'y': 1.3151412613599134}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,778]\u001b[0m Trial 841 finished with value: 26.62864690848266 and parameters: {'x': 1.2067745112019415, 'y': 0.9406896395517819}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,787]\u001b[0m Trial 842 finished with value: 0.08483168529131895 and parameters: {'x': 1.043100624524305, 'y': 1.116864124469952}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,795]\u001b[0m Trial 843 finished with value: 4.1678909934932316 and parameters: {'x': 0.9049917400148786, 'y': 1.0229429900424813}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,806]\u001b[0m Trial 844 finished with value: 11.346394975596077 and parameters: {'x': 1.115918204355513, 'y': 0.9086288495863168}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,819]\u001b[0m Trial 845 finished with value: 9.336522278264065 and parameters: {'x': 0.9554629682253418, 'y': 1.2184342572946847}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,829]\u001b[0m Trial 846 finished with value: 9.011930081021662 and parameters: {'x': 0.8298249399248759, 'y': 0.9883254720327415}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,838]\u001b[0m Trial 847 finished with value: 0.08599868768891043 and parameters: {'x': 1.0257765268056573, 'y': 1.0814295110083743}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,846]\u001b[0m Trial 848 finished with value: 10.92005374896556 and parameters: {'x': 1.0976525081396409, 'y': 0.8745303001191967}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,855]\u001b[0m Trial 849 finished with value: 13.263353060786379 and parameters: {'x': 0.8944118671321323, 'y': 1.1640083583831649}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,864]\u001b[0m Trial 850 finished with value: 0.3181714541915562 and parameters: {'x': 1.1997624122265789, 'y': 1.3866788806012356}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,873]\u001b[0m Trial 851 finished with value: 0.14832793730707158 and parameters: {'x': 0.9830895519126356, 'y': 1.0049412901341037}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,884]\u001b[0m Trial 852 finished with value: 86.5624538545 and parameters: {'x': 1.3668456893211085, 'y': 0.9386011871475727}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,896]\u001b[0m Trial 853 finished with value: 9.263938073422853 and parameters: {'x': 0.734847705239771, 'y': 0.8432111816234444}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,906]\u001b[0m Trial 854 finished with value: 217.9985391248198 and parameters: {'x': -1.5992893118538232, 'y': 1.1043088330512183}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,915]\u001b[0m Trial 855 finished with value: 0.43851271059828495 and parameters: {'x': 1.0447654389453715, 'y': 1.0254660123698598}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,925]\u001b[0m Trial 856 finished with value: 31.835651850336752 and parameters: {'x': 0.8501048665173752, 'y': 1.2867100500196755}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,935]\u001b[0m Trial 857 finished with value: 77.97991430021804 and parameters: {'x': -0.2317615340936105, 'y': 0.9281428102001795}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,945]\u001b[0m Trial 858 finished with value: 0.7835760485012989 and parameters: {'x': 0.9252339769860735, 'y': 0.7678543923811956}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,955]\u001b[0m Trial 859 finished with value: 2.7771347774290267 and parameters: {'x': 1.1456205104850774, 'y': 1.1464364313179134}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,966]\u001b[0m Trial 860 finished with value: 3.0932344718394833 and parameters: {'x': 1.021605461585566, 'y': 0.8678150546595056}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,976]\u001b[0m Trial 861 finished with value: 17.371168503818552 and parameters: {'x': 0.7818709485511581, 'y': 1.0275383286103856}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,985]\u001b[0m Trial 862 finished with value: 10.456665436942847 and parameters: {'x': 0.9604428702727102, 'y': 1.2457939880563036}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:53,997]\u001b[0m Trial 863 finished with value: 43.21860773479472 and parameters: {'x': 1.2713171132641456, 'y': 0.9593987058000532}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,009]\u001b[0m Trial 864 finished with value: 1.0720748925548937 and parameters: {'x': 1.0988964757233168, 'y': 1.1045057982515818}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,025]\u001b[0m Trial 865 finished with value: 0.21400860016120188 and parameters: {'x': 0.8431018572532909, 'y': 0.667301599597993}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,041]\u001b[0m Trial 866 finished with value: 52.28805689789363 and parameters: {'x': 0.324442849904894, 'y': 0.825205378833227}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,055]\u001b[0m Trial 867 finished with value: 2.869606592094069 and parameters: {'x': 0.9308889383326368, 'y': 1.0358123099472065}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,069]\u001b[0m Trial 868 finished with value: 1.389589917162522 and parameters: {'x': 1.0301373009934918, 'y': 1.1790251968014471}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,090]\u001b[0m Trial 869 finished with value: 22.649260864411033 and parameters: {'x': 1.1794807197611803, 'y': 0.9156009303236775}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,109]\u001b[0m Trial 870 finished with value: 19.537967696929066 and parameters: {'x': 1.0816587111715106, 'y': 0.7280432685971424}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,124]\u001b[0m Trial 871 finished with value: 3.6823873344495888 and parameters: {'x': 0.8947626828158934, 'y': 0.9922069505495404}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,137]\u001b[0m Trial 872 finished with value: 2.0265912405289512 and parameters: {'x': 0.9762410089473036, 'y': 1.095385074034488}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,150]\u001b[0m Trial 873 finished with value: 6.149770743665364 and parameters: {'x': 0.7647393111030029, 'y': 0.8316950688455126}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,163]\u001b[0m Trial 874 finished with value: 16.889938810152618 and parameters: {'x': -0.9229330153430736, 'y': 1.2150169617019835}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,174]\u001b[0m Trial 875 finished with value: 10.914947930498641 and parameters: {'x': 1.111367125241053, 'y': 0.9049468615673937}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,187]\u001b[0m Trial 876 finished with value: 0.3975946514433739 and parameters: {'x': 1.0232154144273895, 'y': 0.9839574287098919}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,201]\u001b[0m Trial 877 finished with value: 11.634830040888389 and parameters: {'x': 0.8611612719374984, 'y': 1.0824147254709398}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,214]\u001b[0m Trial 878 finished with value: 1.8995109965380446 and parameters: {'x': 0.9542811027683299, 'y': 0.7729055255322659}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,230]\u001b[0m Trial 879 finished with value: 4.281520968804206 and parameters: {'x': 1.2352937663793218, 'y': 1.320374479243186}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,247]\u001b[0m Trial 880 finished with value: 8.17092200464053 and parameters: {'x': 1.0799093637493955, 'y': 0.8804677032035014}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,266]\u001b[0m Trial 881 finished with value: 51.354951644039474 and parameters: {'x': 0.6655297318858081, 'y': 1.1587725531467206}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,285]\u001b[0m Trial 882 finished with value: 5.4608549841607985 and parameters: {'x': 0.9008488186241628, 'y': 1.0450028758420342}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,304]\u001b[0m Trial 883 finished with value: 16.23492343908838 and parameters: {'x': 1.1729247840182122, 'y': 0.9731979507025099}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,316]\u001b[0m Trial 884 finished with value: 13.142839905945179 and parameters: {'x': 1.0178029848448793, 'y': 0.6733967381502074}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,328]\u001b[0m Trial 885 finished with value: 1.7718620461449688 and parameters: {'x': 0.8302850617469442, 'y': 0.8213982391995713}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,343]\u001b[0m Trial 886 finished with value: 0.0012557399788530588 and parameters: {'x': 0.9655643401856426, 'y': 0.9331507085993919}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,355]\u001b[0m Trial 887 finished with value: 1.2676157096362437 and parameters: {'x': 1.0783089529727237, 'y': 1.0504344192266082}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,366]\u001b[0m Trial 888 finished with value: 14.109946386827119 and parameters: {'x': 1.150555986085441, 'y': 0.9484488321076505}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,377]\u001b[0m Trial 889 finished with value: 2.0912076452468007 and parameters: {'x': 0.9927919700008468, 'y': 1.1302441834810668}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,389]\u001b[0m Trial 890 finished with value: 37.41351471973706 and parameters: {'x': 1.2824273530142487, 'y': 1.0336064174630113}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,399]\u001b[0m Trial 891 finished with value: 9.818015742675414 and parameters: {'x': 0.9758916664614766, 'y': 1.265692400611091}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,410]\u001b[0m Trial 892 finished with value: 6.277569117109171 and parameters: {'x': 1.081779475814117, 'y': 0.9198295578430418}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,418]\u001b[0m Trial 893 finished with value: 12.936770824073191 and parameters: {'x': 1.0303091380625253, 'y': 1.4212013772158212}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,429]\u001b[0m Trial 894 finished with value: 9.81108496653297 and parameters: {'x': 1.190625491108306, 'y': 1.1049431439245696}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,439]\u001b[0m Trial 895 finished with value: 12.043788266311429 and parameters: {'x': 0.9223448809437758, 'y': 1.1976748019361978}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,448]\u001b[0m Trial 896 finished with value: 4.583026394394743 and parameters: {'x': 1.1206869917172904, 'y': 1.0421997478235556}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,461]\u001b[0m Trial 897 finished with value: 0.006227476336021405 and parameters: {'x': 0.9775853421148257, 'y': 0.9632395133771556}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,472]\u001b[0m Trial 898 finished with value: 50.67486735108786 and parameters: {'x': 0.9575431803827347, 'y': 1.6287391004737368}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,484]\u001b[0m Trial 899 finished with value: 4.935608835185079 and parameters: {'x': 0.8326185147013775, 'y': 0.9147844528366015}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,503]\u001b[0m Trial 900 finished with value: 49.110881106955205 and parameters: {'x': 0.5162036000364669, 'y': 0.9655857612672328}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,514]\u001b[0m Trial 901 finished with value: 0.4392223115685757 and parameters: {'x': 0.898392941928874, 'y': 0.8726002069599528}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,524]\u001b[0m Trial 902 finished with value: 1.0054832148679604 and parameters: {'x': 1.036631347356962, 'y': 0.9743976963030996}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,536]\u001b[0m Trial 903 finished with value: 0.315319380357352 and parameters: {'x': 0.952847397358809, 'y': 0.8519631796384006}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,548]\u001b[0m Trial 904 finished with value: 7.737478286192224 and parameters: {'x': 0.8013076749212832, 'y': 0.9195466821822599}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,567]\u001b[0m Trial 905 finished with value: 124.8088893715683 and parameters: {'x': 1.4590384977673287, 'y': 1.0125578205733643}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,587]\u001b[0m Trial 906 finished with value: 7.720049819733832 and parameters: {'x': 1.0402932975794372, 'y': 0.8043895865358737}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,601]\u001b[0m Trial 907 finished with value: 2.648773377994963 and parameters: {'x': 1.1290008742786668, 'y': 1.11240450296209}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,614]\u001b[0m Trial 908 finished with value: 2.212289114743411 and parameters: {'x': 0.9001787945980235, 'y': 0.9587241816899589}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,626]\u001b[0m Trial 909 finished with value: 11.19491343460929 and parameters: {'x': 0.7262371975334638, 'y': 0.860886617726193}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,638]\u001b[0m Trial 910 finished with value: 4.952094060253301 and parameters: {'x': 0.9731970292833791, 'y': 1.169629325953424}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,652]\u001b[0m Trial 911 finished with value: 2.2334844061207315 and parameters: {'x': 1.07963063724685, 'y': 1.0163661454248043}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,663]\u001b[0m Trial 912 finished with value: 13.627354278008756 and parameters: {'x': 0.8504128138217617, 'y': 1.0920512178635253}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,676]\u001b[0m Trial 913 finished with value: 85.48561160690409 and parameters: {'x': -0.0154677253491885, 'y': 0.9192302020916282}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,689]\u001b[0m Trial 914 finished with value: 3.1614959753706677 and parameters: {'x': 0.9816287621493964, 'y': 0.7857985567198904}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,698]\u001b[0m Trial 915 finished with value: 6.709380891458874 and parameters: {'x': 1.228468395025747, 'y': 1.2511194219782322}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,707]\u001b[0m Trial 916 finished with value: 12.413922137843965 and parameters: {'x': 1.1494067483092538, 'y': 0.9691188314059854}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,716]\u001b[0m Trial 917 finished with value: 3.85498794767546 and parameters: {'x': 1.0386769989114453, 'y': 0.8825467741795424}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,725]\u001b[0m Trial 918 finished with value: 6.342317475329386 and parameters: {'x': 0.9056844166941177, 'y': 1.071927173022204}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,734]\u001b[0m Trial 919 finished with value: 29.991858160932118 and parameters: {'x': 0.7941182577773818, 'y': 1.1778849047025504}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,742]\u001b[0m Trial 920 finished with value: 116.16449458235681 and parameters: {'x': 1.3435966295760433, 'y': 0.7280033897183389}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,757]\u001b[0m Trial 921 finished with value: 0.3734416237966484 and parameters: {'x': 0.9713309978678978, 'y': 1.0045264919083514}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,771]\u001b[0m Trial 922 finished with value: 12.13661970369846 and parameters: {'x': 1.0970450305600965, 'y': 0.8552664751969972}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,782]\u001b[0m Trial 923 finished with value: 8.096732259959659 and parameters: {'x': 0.8707511503243209, 'y': 1.0424614486989465}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,792]\u001b[0m Trial 924 finished with value: 74.87644756778656 and parameters: {'x': 0.9966027325531851, 'y': 0.1279052937586308}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,802]\u001b[0m Trial 925 finished with value: 7.7912087610482565 and parameters: {'x': 1.1872764926120716, 'y': 1.1311270627977423}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,811]\u001b[0m Trial 926 finished with value: 5.991621228064254 and parameters: {'x': 1.0476983680072791, 'y': 1.3424032760284645}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,819]\u001b[0m Trial 927 finished with value: 1.0142399042307126 and parameters: {'x': 0.9224910608361644, 'y': 0.9514005270926327}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,830]\u001b[0m Trial 928 finished with value: 0.059979298730846606 and parameters: {'x': 1.1204507286355114, 'y': 1.234085923674159}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,839]\u001b[0m Trial 929 finished with value: 3.3732572596515285 and parameters: {'x': 0.7784171542696363, 'y': 0.7882560101753389}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,849]\u001b[0m Trial 930 finished with value: 298.0487966961886 and parameters: {'x': 0.9602944389730803, 'y': -0.8042390047575656}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,859]\u001b[0m Trial 931 finished with value: 1.9507332867825806 and parameters: {'x': 0.8620499494018018, 'y': 0.882115836484303}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,867]\u001b[0m Trial 932 finished with value: 0.0015286597026775317 and parameters: {'x': 1.039053799456763, 'y': 1.0798188210315616}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,875]\u001b[0m Trial 933 finished with value: 8.076988052055228 and parameters: {'x': 1.207853623463287, 'y': 1.1754710537542044}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,884]\u001b[0m Trial 934 finished with value: 1.746422102967956 and parameters: {'x': 1.1204355087164917, 'y': 1.1237733967207426}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,894]\u001b[0m Trial 935 finished with value: 0.19795705607443337 and parameters: {'x': 1.0609114041767498, 'y': 1.0814595623422432}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,905]\u001b[0m Trial 936 finished with value: 11.230458371471242 and parameters: {'x': 1.2716369337235376, 'y': 1.2830444474677596}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,917]\u001b[0m Trial 937 finished with value: 1.587961082551781 and parameters: {'x': 1.1578163557071366, 'y': 1.215516512297612}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,928]\u001b[0m Trial 938 finished with value: 0.1559424630843583 and parameters: {'x': 1.0223275206182274, 'y': 1.0845799395297}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,938]\u001b[0m Trial 939 finished with value: 0.08786936261078802 and parameters: {'x': 1.0638385265250827, 'y': 1.1606996047081155}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,950]\u001b[0m Trial 940 finished with value: 12.008984798790868 and parameters: {'x': 1.177865752760986, 'y': 1.0412846696361944}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,961]\u001b[0m Trial 941 finished with value: 5.515777614238094 and parameters: {'x': 1.0301434429494123, 'y': 1.296033094947865}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,970]\u001b[0m Trial 942 finished with value: 49.6286387740529 and parameters: {'x': 1.305630890283479, 'y': 1.0008593439351996}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,979]\u001b[0m Trial 943 finished with value: 621.2924229360588 and parameters: {'x': 0.9841084417386113, 'y': -1.5241038845417398}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:54,991]\u001b[0m Trial 944 finished with value: 0.6785434603214665 and parameters: {'x': 1.1006779082270226, 'y': 1.129735670179625}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,001]\u001b[0m Trial 945 finished with value: 23.759543965134696 and parameters: {'x': 1.2413761384116322, 'y': 1.0541750973796429}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,009]\u001b[0m Trial 946 finished with value: 15.314871110137576 and parameters: {'x': 0.9147952320365551, 'y': 1.228099741574333}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,018]\u001b[0m Trial 947 finished with value: 7.428324750967479 and parameters: {'x': 1.1216650512288897, 'y': 0.9858546443796213}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,026]\u001b[0m Trial 948 finished with value: 12.936955303218378 and parameters: {'x': 1.0303398984599752, 'y': 1.4212673022558255}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,034]\u001b[0m Trial 949 finished with value: 5.12129054982221 and parameters: {'x': 0.9492367054914838, 'y': 1.1272960663880371}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,043]\u001b[0m Trial 950 finished with value: 0.9437277965326125 and parameters: {'x': 1.0651057891558138, 'y': 1.0375230996507137}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,051]\u001b[0m Trial 951 finished with value: 21.120532032104123 and parameters: {'x': 0.848645104976477, 'y': 1.1795200108437534}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,060]\u001b[0m Trial 952 finished with value: 12.473757730483168 and parameters: {'x': -0.7884136054158792, 'y': 0.3170416747618459}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,069]\u001b[0m Trial 953 finished with value: 0.18337105721729344 and parameters: {'x': 0.9962419654925272, 'y': 0.9496778559581078}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,079]\u001b[0m Trial 954 finished with value: 678.3600682981871 and parameters: {'x': 1.1557201591119606, 'y': -1.2687990008178887}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,088]\u001b[0m Trial 955 finished with value: 34.277937755675545 and parameters: {'x': 0.7014152790054238, 'y': 1.0766951595382857}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,097]\u001b[0m Trial 956 finished with value: 1.6254387866697264 and parameters: {'x': 0.9040976432883583, 'y': 0.9445240366207017}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,105]\u001b[0m Trial 957 finished with value: 8.232824868548265 and parameters: {'x': 1.014506553433701, 'y': 1.3161488757208388}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,114]\u001b[0m Trial 958 finished with value: 0.014357654710708864 and parameters: {'x': 1.1031247613414386, 'y': 1.2229858276556094}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,122]\u001b[0m Trial 959 finished with value: 87.18412154347516 and parameters: {'x': 0.25910018177905125, 'y': 0.9979131629208827}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,131]\u001b[0m Trial 960 finished with value: 25.34136646664292 and parameters: {'x': 0.7826499078016583, 'y': 1.1154735317655458}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,141]\u001b[0m Trial 961 finished with value: 28.312385173171386 and parameters: {'x': 1.2129948744143608, 'y': 0.9396892035902377}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,153]\u001b[0m Trial 962 finished with value: 2.950723482207232 and parameters: {'x': 0.9393733426276298, 'y': 1.0540919564751268}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,168]\u001b[0m Trial 963 finished with value: 58.71922255290768 and parameters: {'x': 0.8626400376197624, 'y': 1.5103094022802646}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,182]\u001b[0m Trial 964 finished with value: 0.0719868679673692 and parameters: {'x': 1.0746519494085889, 'y': 1.1806477173608827}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,195]\u001b[0m Trial 965 finished with value: 0.4421235424283189 and parameters: {'x': 0.9867505766631871, 'y': 0.9071975312355237}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,207]\u001b[0m Trial 966 finished with value: 4.972456004159727 and parameters: {'x': 1.1077797606603443, 'y': 1.0044465764675243}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,220]\u001b[0m Trial 967 finished with value: 0.05726682287189258 and parameters: {'x': 0.918464677109982, 'y': 0.8210787378089368}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,236]\u001b[0m Trial 968 finished with value: 0.5307291668861844 and parameters: {'x': 1.0185902100928503, 'y': 1.1103534539878694}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,252]\u001b[0m Trial 969 finished with value: 46.89837508030211 and parameters: {'x': 0.8235396631359498, 'y': 1.362814077112961}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,269]\u001b[0m Trial 970 finished with value: 14.01154103932983 and parameters: {'x': 1.1710841468264732, 'y': 0.9975093256538344}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,287]\u001b[0m Trial 971 finished with value: 9.069352896272047 and parameters: {'x': 0.9693724069109599, 'y': 1.2408209519840787}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,301]\u001b[0m Trial 972 finished with value: 17.017579828705244 and parameters: {'x': 0.5776432930903839, 'y': 0.7440276518076206}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,318]\u001b[0m Trial 973 finished with value: 369.56878680146986 and parameters: {'x': 1.2758076727081162, 'y': -0.2945341165941423}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,330]\u001b[0m Trial 974 finished with value: 5.475269304238816 and parameters: {'x': 1.0590569000692642, 'y': 0.8876831218392857}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,342]\u001b[0m Trial 975 finished with value: 9.631798278622098 and parameters: {'x': 0.8799230356296451, 'y': 1.0843835548413978}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,352]\u001b[0m Trial 976 finished with value: 0.13185428828933762 and parameters: {'x': 0.9617801458584144, 'y': 0.9611310934202903}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,363]\u001b[0m Trial 977 finished with value: 2.544338385328512 and parameters: {'x': 1.1483069974328206, 'y': 1.1597900880539165}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,379]\u001b[0m Trial 978 finished with value: 17.381107081154646 and parameters: {'x': 0.7933709336134059, 'y': 1.045831620659648}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,394]\u001b[0m Trial 979 finished with value: 3.906548791244446 and parameters: {'x': 1.016303851129358, 'y': 0.8352303298354808}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,406]\u001b[0m Trial 980 finished with value: 19.80680168122799 and parameters: {'x': 0.7009146781794793, 'y': 0.9353236098849047}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,419]\u001b[0m Trial 981 finished with value: 403.02782731151325 and parameters: {'x': 1.7704566018663783, 'y': 1.1284402496965904}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,429]\u001b[0m Trial 982 finished with value: 22.66870623205051 and parameters: {'x': 1.0863868555165206, 'y': 0.7041981288645175}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,440]\u001b[0m Trial 983 finished with value: 149.98731164246118 and parameters: {'x': 1.579781075340303, 'y': 1.2723883142310641}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,451]\u001b[0m Trial 984 finished with value: 3.7357802039001866 and parameters: {'x': 0.9056029741845663, 'y': 1.013167760975593}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,463]\u001b[0m Trial 985 finished with value: 109.86588948377651 and parameters: {'x': 1.38885016476621, 'y': 0.8814570008850305}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,473]\u001b[0m Trial 986 finished with value: 7.061351561555672 and parameters: {'x': 1.0258800376710546, 'y': 0.7867104172276065}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,485]\u001b[0m Trial 987 finished with value: 17.832696325312483 and parameters: {'x': 1.2212628598850441, 'y': 1.0697752652489538}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,499]\u001b[0m Trial 988 finished with value: 16.74596177684063 and parameters: {'x': 0.8753698040939036, 'y': 1.1753007659248214}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,512]\u001b[0m Trial 989 finished with value: 861.0607822507044 and parameters: {'x': -1.9714847096109864, 'y': 0.967452282445443}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,524]\u001b[0m Trial 990 finished with value: 0.07230086197147723 and parameters: {'x': 0.953848554506328, 'y': 0.8833372733056536}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,538]\u001b[0m Trial 991 finished with value: 6.102180703996814 and parameters: {'x': 1.1465603331827212, 'y': 1.068009827875144}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,551]\u001b[0m Trial 992 finished with value: 3.349132505054176 and parameters: {'x': 1.0695261608104354, 'y': 0.9610119726918461}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,565]\u001b[0m Trial 993 finished with value: 36.897834467206465 and parameters: {'x': 0.796148705821561, 'y': 1.2409464869759679}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,578]\u001b[0m Trial 994 finished with value: 1.4557090966867903 and parameters: {'x': 0.9640483128869788, 'y': 0.8087899550190508}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,589]\u001b[0m Trial 995 finished with value: 0.5143964953003826 and parameters: {'x': 1.0305321224382806, 'y': 1.1336528776154784}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,602]\u001b[0m Trial 996 finished with value: 665.0508155327691 and parameters: {'x': 1.8999107065682765, 'y': 1.032373405389967}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,612]\u001b[0m Trial 997 finished with value: 2.1779964613411864 and parameters: {'x': 0.8687662627501445, 'y': 0.9017505392151903}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,622]\u001b[0m Trial 998 finished with value: 35.53396729477996 and parameters: {'x': 1.115356930254068, 'y': 0.6480289672080225}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 09:07:55,635]\u001b[0m Trial 999 finished with value: 57.49336644838834 and parameters: {'x': 1.2273639107918188, 'y': 0.748519325473754}. Best is trial 827 with value: 0.00025181702927100575.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1.0157192967949913, 'y': 1.0319029624649332}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    return {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
    "        \"temperature\": trial.suggest_int(\"temperature\", 2, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-25 09:08:49,761]\u001b[0m A new study created in memory with name: no-name-ca97f372-025a-449e-a9c9-0df01d89e7c5\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2226 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196933</td>\n",
       "      <td>0.583871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>0.819355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>0.876129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.897742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.904516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>0.909355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.910323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-0/checkpoint-2226/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:11:08,249]\u001b[0m Trial 0 finished with value: 0.9103225806451613 and parameters: {'num_train_epochs': 7, 'alpha': 0.17798034299133758, 'temperature': 19}. Best is trial 0 with value: 0.9103225806451613.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.194763</td>\n",
       "      <td>0.596452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.094897</td>\n",
       "      <td>0.834516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.062195</td>\n",
       "      <td>0.886129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>0.902903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.912903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.034047</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.030909</td>\n",
       "      <td>0.921613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.922581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.923548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.027515</td>\n",
       "      <td>0.923548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-3180\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-3180/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-1/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:14:30,159]\u001b[0m Trial 1 finished with value: 0.9235483870967742 and parameters: {'num_train_epochs': 10, 'alpha': 0.25110028793165706, 'temperature': 16}. Best is trial 1 with value: 0.9235483870967742.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.226033</td>\n",
       "      <td>0.592903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.115703</td>\n",
       "      <td>0.812581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.080383</td>\n",
       "      <td>0.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.891935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-2/checkpoint-1590/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:16:10,622]\u001b[0m Trial 2 finished with value: 0.8919354838709678 and parameters: {'num_train_epochs': 5, 'alpha': 0.8459934874296922, 'temperature': 7}. Best is trial 1 with value: 0.9235483870967742.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 02:57, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.207347</td>\n",
       "      <td>0.607419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.099792</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.064722</td>\n",
       "      <td>0.888710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.048381</td>\n",
       "      <td>0.902903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.040378</td>\n",
       "      <td>0.914516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>0.920968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>0.921290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.921613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-3/checkpoint-2862/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:19:09,284]\u001b[0m Trial 3 finished with value: 0.9216129032258065 and parameters: {'num_train_epochs': 9, 'alpha': 0.6439408975101338, 'temperature': 9}. Best is trial 1 with value: 0.9235483870967742.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1908/1908 01:59, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198854</td>\n",
       "      <td>0.579355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.102153</td>\n",
       "      <td>0.813871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.070718</td>\n",
       "      <td>0.871613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.056692</td>\n",
       "      <td>0.892258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.901613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.048501</td>\n",
       "      <td>0.904194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-4/checkpoint-1908/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:21:09,950]\u001b[0m Trial 4 finished with value: 0.9041935483870968 and parameters: {'num_train_epochs': 6, 'alpha': 0.8338147314386968, 'temperature': 20}. Best is trial 1 with value: 0.9235483870967742.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2226 02:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296175</td>\n",
       "      <td>0.643548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.126841</td>\n",
       "      <td>0.839677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.895484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.054073</td>\n",
       "      <td>0.905484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.045587</td>\n",
       "      <td>0.911613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.041252</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.917742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-5/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:23:28,805]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2862 02:17 < 00:39, 16.17 it/s, Epoch 7/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195792</td>\n",
       "      <td>0.596129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.096054</td>\n",
       "      <td>0.831613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.063475</td>\n",
       "      <td>0.883871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.901290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.040279</td>\n",
       "      <td>0.911935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.032646</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-6/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:25:47,791]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/1590 00:18 < 01:12, 17.43 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.204162</td>\n",
       "      <td>0.573226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:26:07,623]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289209</td>\n",
       "      <td>0.652581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.117745</td>\n",
       "      <td>0.847419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459200</td>\n",
       "      <td>0.066407</td>\n",
       "      <td>0.900968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.046886</td>\n",
       "      <td>0.908710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>0.918710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.925484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.030816</td>\n",
       "      <td>0.929355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.028948</td>\n",
       "      <td>0.930323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.028029</td>\n",
       "      <td>0.929677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.027581</td>\n",
       "      <td>0.928387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-3180\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-3180/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-8/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:29:20,774]\u001b[0m Trial 8 finished with value: 0.9283870967741935 and parameters: {'num_train_epochs': 10, 'alpha': 0.09045211045293378, 'temperature': 3}. Best is trial 8 with value: 0.9283870967741935.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2544 02:11 < 00:18, 16.90 it/s, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224330</td>\n",
       "      <td>0.614839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.106252</td>\n",
       "      <td>0.839032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.887742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.901613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>0.912258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.037577</td>\n",
       "      <td>0.919355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.035175</td>\n",
       "      <td>0.918710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-9/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:31:33,947]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.403994</td>\n",
       "      <td>0.661935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.071176</td>\n",
       "      <td>0.904194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.910645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.917742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.926452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.928387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-3180\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-3180/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-10/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:34:44,597]\u001b[0m Trial 10 finished with value: 0.93 and parameters: {'num_train_epochs': 10, 'alpha': 0.4578114064764249, 'temperature': 2}. Best is trial 10 with value: 0.93.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.403994</td>\n",
       "      <td>0.661935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.071176</td>\n",
       "      <td>0.904194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.910645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.917742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.926452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.928387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-3180\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-3180/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-11/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:37:56,396]\u001b[0m Trial 11 finished with value: 0.93 and parameters: {'num_train_epochs': 10, 'alpha': 0.47202019314285676, 'temperature': 2}. Best is trial 10 with value: 0.93.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2862 02:35 < 00:19, 16.38 it/s, Epoch 8/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406611</td>\n",
       "      <td>0.659355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>0.144257</td>\n",
       "      <td>0.846452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>0.073354</td>\n",
       "      <td>0.902581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.051969</td>\n",
       "      <td>0.909355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.043680</td>\n",
       "      <td>0.917097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.038633</td>\n",
       "      <td>0.926452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.036268</td>\n",
       "      <td>0.926129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>0.927742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-12/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:40:33,400]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 636/3180 00:38 < 02:35, 16.32 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199476</td>\n",
       "      <td>0.602258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.096351</td>\n",
       "      <td>0.834516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-13/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-13/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-13/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-13/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-13/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:41:14,012]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1272' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1272/2544 01:20 < 01:21, 15.69 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.235364</td>\n",
       "      <td>0.627419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.842258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.068589</td>\n",
       "      <td>0.891935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.902581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-14/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:42:36,502]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/3180 02:20 < 01:00, 15.86 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206232</td>\n",
       "      <td>0.607097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>0.840323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.890323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>0.046886</td>\n",
       "      <td>0.904839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.038857</td>\n",
       "      <td>0.915484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.922258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-15/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:44:58,326]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2862 00:18 < 02:31, 16.83 it/s, Epoch 1/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200813</td>\n",
       "      <td>0.599355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:45:18,632]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1272' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1272/2544 01:19 < 01:19, 16.00 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.235364</td>\n",
       "      <td>0.627419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.842258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.068589</td>\n",
       "      <td>0.891935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.902581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-17/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:46:39,467]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.403994</td>\n",
       "      <td>0.661935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.140970</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.639200</td>\n",
       "      <td>0.071176</td>\n",
       "      <td>0.904194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.910645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.917742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.926452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.928387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.031790</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1908\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1908/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2226\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2226/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2544\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2544/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2862\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2862/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-3180\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-3180/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-18/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2022-09-25 09:50:00,448]\u001b[0m Trial 18 finished with value: 0.93 and parameters: {'num_train_epochs': 10, 'alpha': 0.28486672922540035, 'temperature': 2}. Best is trial 10 with value: 0.93.\u001b[0m\n",
      "Trial:\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1908' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1908/2862 01:59 < 00:59, 16.01 it/s, Epoch 6/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.210892</td>\n",
       "      <td>0.610645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.100881</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.065050</td>\n",
       "      <td>0.889355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.048468</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.040366</td>\n",
       "      <td>0.914516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-318\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-318/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-636\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-636/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-954\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-954/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1272\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1272/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1590\n",
      "Configuration saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1590/config.json\n",
      "Model weights saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distilbert-base-uncased-finetuned-clinc/run-19/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "\u001b[32m[I 2022-09-25 09:52:01,193]\u001b[0m Trial 19 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_run = distilbert_trainer.hyperparameter_search(\n",
    "    n_trials=20, direction=\"maximize\", hp_space=hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BestRun(run_id='10', objective=0.93, hyperparameters={'num_train_epochs': 10, 'alpha': 0.4578114064764249, 'temperature': 2})\n"
     ]
    }
   ],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 03:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.713752</td>\n",
       "      <td>0.741613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.072100</td>\n",
       "      <td>0.867878</td>\n",
       "      <td>0.858387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.072100</td>\n",
       "      <td>0.507208</td>\n",
       "      <td>0.910323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.786300</td>\n",
       "      <td>0.373459</td>\n",
       "      <td>0.936774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.326915</td>\n",
       "      <td>0.943871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.304613</td>\n",
       "      <td>0.948065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.293774</td>\n",
       "      <td>0.947419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.288233</td>\n",
       "      <td>0.947742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.286316</td>\n",
       "      <td>0.948710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.284721</td>\n",
       "      <td>0.948387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-318\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-318/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-318/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-636\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-636/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-636/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-954\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-954/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-954/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-1272\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1272/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1272/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-1590\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1590/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1590/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-1908\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1908/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-1908/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-2226\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2226/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2226/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-2544\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2544/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2544/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-2862\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2862/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-2862/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3100\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to data/distillbert-base-uncased-distilled-clinc/checkpoint-3180\n",
      "Configuration saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-3180/config.json\n",
      "Model weights saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in data/distillbert-base-uncased-distilled-clinc/checkpoint-3180/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3180, training_loss=0.6335120686944925, metrics={'train_runtime': 199.2041, 'train_samples_per_second': 765.547, 'train_steps_per_second': 15.964, 'total_flos': 933776874167172.0, 'train_loss': 0.6335120686944925, 'epoch': 10.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in best_run.hyperparameters.items():\n",
    "    setattr(student_training_args, k, v)\n",
    "\n",
    "distilled_ckpt = \"data/distillbert-base-uncased-distilled-clinc\"\n",
    "student_training_args.output_dir = distilled_ckpt\n",
    "\n",
    "distill_trainer = DistillationTrainer(model_init=student_init,\n",
    "    teacher_model=teacher_model, args=student_training_args,\n",
    "    train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
    "    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/pipelines/base.py:1036: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 4.06 +\\- 1.51\n",
      "Accuracy on test set - 0.878\n"
     ]
    }
   ],
   "source": [
    "distilled_ckpt = \"data/distillbert-base-uncased-distilled-clinc/checkpoint-3180\"\n",
    "pipe = pipeline(\"text-classification\", model=distilled_ckpt, device=0)\n",
    "optim_type = \"Distillation\"\n",
    "pb = PerformanceBenchMark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_dict = pipe.model.state_dict()\n",
    "weights = state_dict[\"distilbert.transformer.layer.0.attention.out_lin.weight\"]\n",
    "plt.hist(weights.flatten().numpy(), bins=250, range=(-0.3,0.3), edgecolor=\"C0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5,  -7,   0,  ...,  -6,  -4,   8],\n",
       "        [  9,   2,   1,  ...,  -4,   7,   0],\n",
       "        [ -9,  -6,   5,  ...,   0,   5,  -4],\n",
       "        ...,\n",
       "        [  5,   0,  12,  ...,   0,   6,  -1],\n",
       "        [  0,  -2, -12,  ...,  12,  -7, -13],\n",
       "        [-13,  -1,  -9,  ...,   8,   2,  -2]], dtype=torch.int8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_point = 0\n",
    "scale = (weights.max() - weights.min()) / (127 - (-128))\n",
    "(weights / scale + zero_point).clamp(-128, 127).round().char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5,  -7,   0,  ...,  -6,  -4,   8],\n",
       "        [  9,   2,   1,  ...,  -4,   7,   0],\n",
       "        [ -9,  -6,   5,  ...,   0,   5,  -4],\n",
       "        ...,\n",
       "        [  5,   0,  12,  ...,   0,   6,  -1],\n",
       "        [  0,  -2, -12,  ...,  12,  -7, -13],\n",
       "        [-13,  -1,  -9,  ...,   8,   2,  -2]], dtype=torch.int8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import quantize_per_tensor\n",
    "\n",
    "dtype = torch.qint8\n",
    "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
    "quantized_weights.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35 ms ± 7.69 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "weights @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.quantized import QFunctional\n",
    "q_fn = QFunctional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.6 µs ± 552 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "q_fn.mul(quantized_weights, quantized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.999755879241598"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(weights.storage()) / sys.getsizeof(quantized_weights.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_ckpt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/distillbert-base-uncased-distilled-clinc/checkpoint-3180\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_ckpt)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m (AutoModelForSequenceClassification\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m.\u001b[39mfrom_pretrained(model_ckpt)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model_quantized \u001b[39m=\u001b[39m quantize_dynamic(model, {nn\u001b[39m.\u001b[39mLinear}, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mqint8)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.quantization import quantize_dynamic\n",
    "model_ckpt = \"data/distillbert-base-uncased-distilled-clinc/checkpoint-3180\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = (AutoModelForSequenceClassification\n",
    "        .from_pretrained(model_ckpt).to(\"cpu\"))\n",
    "model_quantized = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 132.40\n",
      "Average latency (ms) - 5.80 +\\- 0.68\n",
      "Accuracy on test set - 0.884\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model_quantized,\n",
    "            tokenizer=tokenizer)\n",
    "optim_type = \"Distillation + quantization\"\n",
    "pb = PerformanceBenchMark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from psutil import cpu_count\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = f\"{cpu_count()}\"\n",
    "os.environ[\"OMP_WAIT_POLICY\"] = \"ACTIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb Cell 54\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model_ckpt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/distillbert-base-uncased-distilled-clinc/checkpoint-3180\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m onnx_model_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39mdata/onnx/model.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m convert(framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39mmodel_ckpt, tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         output\u001b[39m=\u001b[39monnx_model_path, opset\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, pipeline_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext-classification\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers.convert_graph_to_onnx import convert\n",
    "\n",
    "model_ckpt = \"data/distillbert-base-uncased-distilled-clinc/checkpoint-3180\"\n",
    "onnx_model_path = Path(\"data/onnx/model.onnx\")\n",
    "convert(framework=\"pt\", model=model_ckpt, tokenizer=tokenizer,\n",
    "        output=onnx_model_path, opset=12, pipeline_name=\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions\n",
    "\n",
    "def create_model_for_provider(model_path, provider=\"CPUExecutionProvider\"):\n",
    "    options = SessionOptions()\n",
    "    options.intra_op_num_threads = 1\n",
    "    options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    session = InferenceSession(str(model_path), options, providers=provider)\n",
    "    session.disable_fallback()\n",
    "    return session\n",
    "\n",
    "providers = [\n",
    "    ('CUDAExecutionProvider', {\n",
    "        'device_id': 0,\n",
    "        'arena_extend_strategy': 'kNextPowerOfTwo',\n",
    "        'gpu_mem_limit': 2 * 1024 * 1024 * 1024,\n",
    "        'cudnn_conv_algo_search': 'EXHAUSTIVE',\n",
    "        'do_copy_in_default_stream': True,\n",
    "    }),\n",
    "    'CPUExecutionProvider',\n",
    "]\n",
    "onnx_model = create_model_for_provider(onnx_model_path, provider=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 151)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = clinc_enc[\"test\"][:1]\n",
    "del inputs[\"labels\"]\n",
    "logits_onnx = onnx_model.run(None, inputs)[0]\n",
    "logits_onnx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(logits_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc_enc[\"test\"][0][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "class OnnxPipeline:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, query):\n",
    "        model_inputs = self.tokenizer(query, return_tensors=\"pt\")\n",
    "        inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                        for k, v in model_inputs.items()}\n",
    "        logits = self.model.run(None, inputs_onnx)[0][0, :]\n",
    "        probs = softmax(logits)\n",
    "        pred_idx = np.argmax(probs).item()\n",
    "        return [{\"label\": intents.int2str(pred_idx), \"score\": probs[pred_idx]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.84260464}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = OnnxPipeline(onnx_model, tokenizer)\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxPerformanceBenchmark(PerformanceBenchMark):\n",
    "    def __init__(self, *args, model_path, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def compute_size(self):\n",
    "        size_mb = Path(self.model_path).stat().st_size / (1024 * 1024)\n",
    "        print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "        return {\"size_mb\": size_mb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 255.90\n",
      "Average latency (ms) - 12.49 +\\- 0.83\n",
      "Accuracy on test set - 0.878\n"
     ]
    }
   ],
   "source": [
    "optim_type = \"Distillation + ORT\"\n",
    "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type, model_path=\"data/onnx/model.onnx\")\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArIUlEQVR4nO3de3xU5bX/8c/KTEIuQERA5aLlIoJcg0ZROCqK2PaUSkv1VxAPoD16sK0X/KlV24pa+6qn0OqxWq2VKlaqKGpt6flZFe8XUMAoULCKgoIgdwgkIZlk/f7YO2nAXCYhk0ky3/frNa/s2bMvaxKYNc/z7L0ec3dERCR1pSU7ABERSS4lAhGRFKdEICKS4pQIRERSnBKBiEiKUyIQEUlxCU0EZnalma00s1VmdlW47nAze97MPgx/dkpkDCIiUreEJQIzGwxcApwMDAPGmVk/4Hpgkbv3AxaFz0VEJEkS2SI4Hljs7kXuHgNeAb4NjAfmhtvMBb6VwBhERKQe0QQeeyXwczPrDBQD/w4sBY50900A7r7JzI6oaWczuxS4FCAnJ+fEAQMGJDBUEZG2Z9myZdvcvWt92yUsEbj7ajP7b+B5YC/wHhBrwP73A/cD5Ofn+9KlSxMSp4hIW2Vm6+PZLqGDxe4+x91PcPfTgR3Ah8AXZtYNIPy5JZExiIhI3RJ91dAR4c9jgAnAo8BfgKnhJlOBZxIZg4iI1C2RYwQAT4ZjBGXAD9x9p5ndDjxuZt8DPgXOT3AMIiJSh4QmAnc/rYZ124ExiTyviEBZWRkbNmygpKQk2aFIgmVmZtKzZ0/S09MbtX+iWwQikiQbNmygQ4cO9OrVCzNLdjiSIO7O9u3b2bBhA717927UMVRiQqSNKikpoXPnzkoCbZyZ0blz50Nq+SkRiLRhSgKp4VD/zkoEIiIpTolARBImEomQl5fHsGHDOOGEE3jzzTcBWLduHVlZWeTl5VU9Hn74YQB69erFkCFDGDp0KGeccQbr16/n29/+Nnl5eRx77LHk5uZW7VN5vEqjR48mkTef9urVi23btgEwcuTIhJ2nuWmwWEQSJisri4KCAgD+/ve/c8MNN/DKK68A0Ldv36rXDvbSSy/RpUsXZs6cyW233cbTTz8NwMsvv8zs2bNZuHBhc4Rfp4OTUGumFoGIVCkqjbF5dwlFpXFXg4nbnj176NSpYVXnTz31VDZu3NigfR555BFGjhzJ4MGDefvttwF4++23GTlyJMOHD2fkyJF88MEHAKxatYqTTz6ZvLw8hg4dyocfflh1jMr1//Vf/0V5efmXztO+fXsgSE6jR4/mvPPOY8CAAUyePBl3B2DZsmWcccYZnHjiiXz1q19l06ZNDXovzUUtAhEBYPXne/jjkvXEyiuIRtKYcspXGNCt4yEds7i4mLy8PEpKSti0aRMvvvhi1Wtr164lLy+v6vlvfvMbTjvtwFuPnn32Wb71rW816Jz79u3jzTff5NVXX+Xiiy9m5cqVDBgwgFdffZVoNMoLL7zAjTfeyJNPPsl9993HlVdeyeTJkyktLaW8vJzVq1czf/583njjDdLT0/n+97/PvHnzmDJlSq3nfPfdd1m1ahXdu3dn1KhRvPHGG4wYMYLLL7+cZ555hq5duzJ//nx+/OMf84c//KFB76c5KBGICEWlMf64ZD3Z6RFy2rdj3/4YDy9ez0++cTzZGY3/mKjeNfTWW28xZcoUVq5cCdTdNXTmmWfyxRdfcMQRR3Dbbbc16JyTJk0C4PTTT2fPnj3s2rWLwsJCpk6dyocffoiZUVZWBgQtjp///Ods2LCBCRMm0K9fPxYtWsSyZcs46aSTgCCZHXFEjUWSq5x88sn07NkTgLy8PNatW8dhhx3GypUrGTt2LADl5eV069atQe+luSgRiAh7imPEyivIad8OgJx2UfaUlLGnOHZIiaC6U089lW3btrF169Z6t33ppZfIyclh2rRp3HTTTfz617+O+zwHX0ppZvz0pz/lzDPP5Omnn2bdunWMHj0agAsuuIARI0bwt7/9ja9+9as88MADuDtTp07lF7/4RdznbNeuXdVyJBIhFovh7gwaNIi33nor7uMki8YIRISOWVGikTT27Q/GBvbtjxGNpNExq+m+K65Zs4by8nI6d+4c1/ZZWVnceeedPPzww+zYsSPu88yfPx+A119/ndzcXHJzc9m9ezc9evQA4KGHHqra9uOPP6ZPnz5cccUVnHvuubz//vuMGTOGBQsWsGVLUBh5x44drF8fVzXnA/Tv35+tW7dWJYKysjJWrVrV4OM0ByUCESE7I8qUU75CUVk5m3YXU1RWzpRTvnLIrYHKMYK8vDy++93vMnfuXCKRCPCvMYLKx1133fWl/bt168akSZO455574j5np06dGDlyJNOnT2fOnDkAXHfdddxwww2MGjXqgIHf+fPnM3jwYPLy8lizZg1Tpkxh4MCB3HbbbZxzzjkMHTqUsWPHNmqQNyMjgwULFvCjH/2IYcOG1Xi5a0thlaPbLZkmphFpuNWrV3P88cc3aJ+i0hh7imN0zIo2WZeQNI+a/t5mtszd8+vbV39pEamSnaEEkIrUNSQikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARBKmsgz1oEGDGDZsGL/+9a+pqKgAYOnSpVxxxRW17rtu3Tr+9Kc/VT2vvv1DDz3ED3/4QwBuvvlmZs+eDcC0adPo3bs3eXl5DBgwgFtuuaVq/9GjR9O/f/+q+xbOO++8qv179OhBXl4eAwcO5NFHH+XBBx+s2i4jI4MhQ4aQl5fH9ddf37S/oBZC14mJSMJUrzW0ZcsWLrjgAnbv3s0tt9xCfn4++fm1X+JemQguuOACgHq3rzRr1izOO+88SkpKGDhwIFOmTKmay3fevHk1HmPGjBlcc801fPjhh5x44ols376diy66CAjmIKgsi91WqUUgIv9Sug/2fB78bGJHHHEE999/P3fffTfuzssvv8y4ceMAeOWVV6q+gQ8fPpzCwkKuv/56XnvtNfLy8rjjjjsO2D4elXP45uTkxL1Pv379yM7OZufOnQ17c62cWgQiEti8Et55AMpjEInCyZfAkYOa9BR9+vShoqKiqo5PpdmzZ3PPPfcwatQo9u7dS2ZmJrfffvsBk9C8/PLLcZ3j2muv5bbbbuOjjz7iiiuuOKBy6OTJk8nKygJg7NixzJo164B9ly9fTr9+/eqtNtrWqEUgIkEL4J0HIKM95PYIfr79+4S0DGoqazNq1Ciuvvpq7rrrLnbt2kU02vjvqLNmzaKgoIDNmzezaNGiA+r7zJs3j4KCAgoKCg5IAnfccQf9+/dnxIgR3HzzzY0+d2ulRCAiULI7aAlkhN0oGTnB85LdTXqajz/+mEgk8qVv3Ndffz0PPPAAxcXFnHLKKaxZs+aQz9W+fXtGjx7N66+/Xu+2M2bM4IMPPmD+/PlMmTKlqlspVSgRiAhk5gbdQZUtgNJ9wfPM3CY7xdatW5k+fTo//OEPvzRnwNq1axkyZAg/+tGPyM/PZ82aNXTo0IHCwsJGny8Wi7FkyRL69u0b9z4TJkwgPz+fuXPnNvq8rZESgYgELYCTL4HSvbB7Y/Dz5Ev+1UJopMoy1IMGDeLss8/mnHPOYebMmV/a7s4772Tw4MEMGzaMrKwsvv71rzN06FCi0SjDhg3jjjvuiPuc1157bdUcxEOGDGHChAlVr02ePLlqUPrss8+ucf/KiXAqL3NNBSpDLdJGNaYMNaX7gu6gzNxDTgLSvFSGWkSaRkaOEkAKUteQiEiKUyIQEUlxSgQiIilOiUBEJMUpEYiIpDglAhFJmOYuQ12bP//5z/zjH/+oen7TTTfxwgsvNPp9tTUJvXzUzGYA/wk4sAK4CBgA3AdkAjHg++7+diLjkNYlVhHj490f8+bnb/JZ4WeUxkrJiGZwdIejGdl9JH1z+xJJiyQ7TIlDMspQ1+TPf/4z48aNY+DAgQDceuutjTpOW5WwFoGZ9QCuAPLdfTAQASYCvwRucfc84KbwuQgAq7at4ldLf8XcVXPZWLiR3Ixcjsw5ktyMXDYWbmTuqrnMXjqbVdtWJTvUNqmorIgv9n1BUVlRkx+7OcpQ//73v+ekk05i2LBhfOc736GoqIg333yTv/zlL1V3HK9du5Zp06axYMECABYtWsTw4cMZMmQIF198Mfv37weCeQhmzpzJCSecwJAhQ5qk/lFLleiuoSiQZWZRIBv4nKB10DF8PTdcJ8LizxfzyOpHiFiEHu170CmzE9G0KGmWRjQtSqfMTvRo34OIRXhk9SMs/nxxskNuUz7Y8QGzl87mnoJ7mL10Nv/c8c8mP0d9ZagLCgp47bXXyMrK4vbbb+e0006joKCAGTNmxHX8CRMm8M477/Dee+9x/PHHM2fOHEaOHMm5555bVZW0eu2hkpISpk2bxvz581mxYgWxWIx777236vUuXbqwfPlyLrvssnq7n1qzhCUCd98IzAY+BTYBu939OeAqYJaZfRa+fkNN+5vZpWa21MyWbt26NVFhSguxatsqnln7DEdlH0V2enad22anZ3NU9lE8s/YZtQyaSFFZEfM/mE92NJujco4iO5rNYx88lpCWQSLLUK9cuZLTTjuNIUOGMG/ePFatqvvfxwcffEDv3r057rjjAJg6dSqvvvpq1euVdYpOPPFE1q1b16iYWoNEdg11AsYDvYHuQI6ZXQhcBsxw96OBGcCcmvZ39/vdPd/d87t27ZqoMKUFiFXEWPjxQjpndiY9kh7XPumRdDpndmbhxwspryhPcIRtX2FpIbGKWFUSzk7PJlYRo7C08dU/a5LoMtTTpk3j7rvvZsWKFcycObPectL11Vpr164dEAx6x2KxRsXUGiSya+hs4BN33+ruZcBTwEhgargM8ARwcgJjkFbg490fs6d0T70tgYNlp2ezp3QPH+/+OEGRpY4OGR2IpkWrWgBFZUVE06J0yOjQZOdojjLUhYWFdOvWjbKyMubNm1e1vrZjDRgwgHXr1vHRRx8B8Mc//pEzzjijEe+udUtkIvgUOMXMsi34q48BVhOMCVT+ps8CPkxgDNIKvPn5m2RHG5YEKmVFs3jj8zeaOKLUk52ezcT+EymKFbF532aKYkVM7D+xwcn5YM1dhvpnP/sZI0aMYOzYsQwYMKBq/cSJE5k1axbDhw9n7dq1VeszMzN58MEHOf/88xkyZAhpaWlMnz79kN5za5TQMtRmdgvwXYLLRN8luJT0JOB/CAaSSwguH11W13FUhrpt+9nin5GbkUs0reH9wmUVZewt3cuPT/lxAiJr3RpThrqorIjC0kI6ZHQ45CQgzavFlqF295nAwen/deDERJ5XWpfSWClp7RrXOI1YhJJYak0rmEjZ6dlKAClIdxZL0mVEM6jwxs0GVe7lZEYzmzgikdSiRCBJd3SHoxt9dUphaSE9OvRo4ohEUosSgSTdyO4jKYo17nr14lgxo7qPauKIRFKLEoEkXZ/cPnTM6Njgm5eKyoromNGRPrl9EhSZSGpQIpCki6ZFGddnHNtLtlNWXhbXPmXlZWwv2c64PuNUgE7kECkRSIswqMsgxvcdz+aizfW2DIrKithctJnxfcczqMugZopQGkNlqA9UWlrKVVddRd++fenXrx/jx49nw4YNVa9X/r4GDx7MN7/5TXbt2sWIESPIy8vjmGOOoWvXrlXF+Zqy5EVCLx8VaYhTup9Ch4wOLPx4IRv3biQrmkWHjA5ELEK5l1NYWkhxrJiOGR258PgLlQRagVQqQ33zzTfTq1cvpk2bVus2N954I4WFhfzzn/8kEonw4IMPMmHCBJYsWYKZHfD7mjp1Kvfccw9LliwBguS3dOlS7r777iaPXS0CaVEGdRnENfnXMG3QNHp26Mne0r18se8L9pbupWeHnkwbNI1r8q9REkigiuJivKJxl/PWJdXLUBcVFfHggw9yxx13EIkE3ZkXXXQR7dq148UXX/zS9qeeeiobN248pHPGSy0CaXEiaRH6depHv079kh1KSinfvZvtc+ZQUVyCtWtHx699lazBg5v0HPWVoR41ahR79+4lMzOT22+/ndmzZ7Nw4UIAXn755XqPP2HCBC655BIAfvKTnzBnzhwuv/xyzj33XMaNG8d55513wPaVZagXLVrEcccdx5QpU7j33nu56qqrgH+Vof7tb3/L7NmzeeCBBxr93j/66COOOeYYOnbseMD6/Px8Vq1axZgxY6rWlZeXs2jRIr73ve81+nwNoRaBiACw54UX8Fg5h0++gPQjj2TP35/DS0ub/DxtqQz1ihUrqloy9913HzfddFPV8+3btx+wrbt/qdjewesrazN17tyZHTt2MHbs2Aa9/8ZSIhARAPb/YzUdzh5DRq9eHPadCXhREbGDPswOVVsrQz1kyBAKCgooKChg+vTp3HrrrVXPO3fufMC2xx57LOvXr/9SFdTly5dXjV1UjhGsX7+e0tJS7rnnnnrfc1NQIhARANoNPJ7CFxZRum4du558CsvOJtqlC+5OWXkFpbEKysor6v3wrE2ql6HOyclh6tSpXH311ZSXB3NoPPzwwxQVFXHWWWcdsG1ubi533XUXs2fPpqwsvkuqD4USgYgA0PHss7FohB3z/kTpF1+QceYYthaXs3FnMZt3l7BlTwmbd5ewcWcxW/aUULQ/RkU9SUFlqA/0i1/8gszMTI477jj69evHE088wdNPP11jl9Hw4cMZNmwYjz32WMLiqZTQMtRNRWWoRRquMWWo3Z2iPXvZVZ5GBUYkzUgzo/rnlDtUuFNe4UTSjE7Z6WSmR2r8MJPmcyhlqNUiEBEgSAK7i8vYUR7B0tLIiKYRSTswCQCYQSTNyIgGHx/b9payu7is0V1Gkny6fFREqpJAYUmM9Ejalz78a1PZYthTEgyk5malq2XQCqlFINKGxfstvaSsvMFJoJIZZETSKCyJUVJW3ogo5VAdamtMiUCkjcrMzGT79u31fkhUuLOzqKzGbqB4VXYX7Swqq3cAWZqWu7N9+3YyMxs/QZO6hkTaqJ49e7Jhwwa2bt1a53alsQr27Y8RSTv0Lp3yCmdru2jV+IE0j8zMTHr27Nno/ZUIRNqo9PR0evfuXe92d7/4Edv2Bv37h2p3cRld2rfjh2cde8jHkuajtC2SwmLlFXy2o4j27ZrmO2H7dlE+21FErLzpi9ZJ4igRiKSwnUVlVOBN0i0EwThBBcGYg7QeSgQiKSxWUUFTX+xp4XGl9VAiEElh0bQ0mvoaHw+PK62H/loiKaxTdjppGOUVTZMOyiucNIKyE9J6KBGIpLBoJI2jD89m7/4vl1hujL37Yxx9eDbRiD5aWhP9tURS3KhjO7O3pGkSQWFJGaOO7Vz/htKiKBGIpLiB3TvSPjNyyK2CvftjdMxMZ2D3jvVvLC1KXInAzDqZ2SAz62NmSh4ibUi7aITvnnQ0O/aVNnqsoLzC2bGvlP9zUk/aRSNNHKEkWq0f6maWa2Y3mtkKYDHwO+BxYL2ZPWFmZzZXkCKSWAOO6siZ/buyYWdRg5NBeYWzYWcRZw04ggFHqTXQGtV1O+EC4GHgNHffVf0FMzsR+A8z6+PucxIYn4g0AzNj3NDumBkvrtnC4TkZcd1tvHd/jB37Shlz/JF8Y0g3laBupWr9S7v72DpeWwYsS0hEIpIUaWnGuKHdOPaIHOa/8xkbdhbRITOd9u2iB9x5XF7h7N0fo7CkjI6Z6Vx6em8GHNVRSaAVi7vAiJl1Ba4EsoB73f2jhEUlIklhZhzfLZcb/r09//h8D298tJ3PdhRRgWMEN4ulYRx9eDbj87ozsHtHjQm0AQ2pNPUr4BGCfwuPAiclJCIRSbp20QjDj+nE8GM6ESuvYGdRGbGKCqJpaXTKTtd9Am1MrYnAzJ4Ffu7ur4WrMoB1BImgXTwHN7MZwH+G+6wALnL3EjO7HPghEAP+5u7XNfodSNtXHoNtH8DaF2HHJxDbD9F2cHhv6HsWdB0AafpWmijRSBpdO8T1X15aqbpaBN8FfmpmlwE/DR8zCbqGvl/fgc2sB3AFMNDdi83scWCima0HxgND3X2/mR1xqG9C2rCNBfD+Y7B/N0SzIfOw4EO/ohx2rIMtd0O7XBg6EXrkJTdWkVaqrsHi3cA1ZtYH+DmwEfhBuL4hx88yszIgG/gcuAy43d33h+fZ0tjgpY1b+xK89yjkHAG5xxz4WiQNcroEy6X7YMm9MGwi9NVVzSINVdd9BH3MbBZB187/BZ4BHjezy82s3na4u28EZgOfApuA3e7+HHAccJqZLTGzV8ysxrEGM7vUzJaa2dL6ptqTNmhjQZAEOvaAjJy6t83IgY7dg+03FjRHdCJtSl0jPo8CzxLcTPZHd3/N3b8K7AGeq+/AZtaJoAuoN9AdyDGzCwlaCZ2AU4BrCZLLl647c/f73T3f3fO7du3awLclrVp5LOgOyjkCIhnx7RPJCLZ//7Gg20hE4lZXIsgEPgkf2ZUr3X0uMC6OY58NfOLuW929DHgKGAlsAJ7ywNtABdClkfFLW7Ttg2BMoL6WwMEycqBkF2z9ICFhibRVdQ0Wfx+YBZQC06u/4O7FcRz7U+AUM8sGioExwFLgfeAs4GUzO47gaqRtDQ9d2qy1LwYDw42RngNrF8GRA5s2JpE2rK7B4jeANxp7YHdfYmYLgOUEl4m+C9xPcCnpH8xsJUGSmeruTT1JkrRmOz4Jrg5qjMxc2LmuKaMRafPquo/grwSF5v4edu1Uf60PMA1Y5+5/qO0Y7j6T4JLTg13YqGglNcT2N/6+gLQIlJU0bTwibVxdXUOXAFcD/2NmO4CtBOMGvYC1wN3u/kzCI5TUE20XDPg25u7VinJIz2z6mETasLq6hjYD1wHXmVkvoBtBX/8/3b2oecKTlHR47+BmsZxGXENQshsO79XUEYm0aXF95XL3de7+lrsXKAlIwvU9C2KN/GdWtg/6jmnaeETaOFWOkpanS/+gbETpvobtV7ovGGTu2j8hYYm0VUoE0vJEokHtoH1boLw0vn3KS2Hf1mA/FaATaZB6E4GZjdM8xdLseuTBsEmwZ2P9LYPSfbDn86DWkArPiTRYPB/wE4EPzeyXZnZ8ogMSqdL3TBjxfaiIwa71sG8blJeBVwQ/920L1lfEYMRlKjgn0kj1Tkzj7heaWUdgEvCgmTnwIPCouxcmOkBJcT3yoNuQoGzE2kXBzWJlJcEloof3CgaGu/ZXd5DIIYhrhjJ332NmTxLMRXAV8G3gWjO7y91/k8D4RIIP+SMHqmyESILEM0bwTTN7GngRSAdOdvevA8OAaxIcn4iIJFg8LYLzgTvc/dXqK929yMwuTkxYIiLSXOJJBDMJJpYBwMyygCPDm8wWJSwyERFpFvFcNfQEwZwBlcrDdSIi0gbEkwii7l51V0+4HOe0USIi0tLFkwi2mtm5lU/MbDyaSEZEpM2IZ4xgOjDPzO4GDPgMmJLQqEREpNnEc0PZWoIpJ9sDppvIRETalrhuKDOzbwCDgEwzA8Ddb01gXCIi0kziuaHsPuC7wOUEXUPnA19JcFwiItJM4hksHunuU4Cd7n4LcCpwdGLDEhGR5hJPIqicCbzIzLoDZUDvxIUkIiLNKZ4xgr+a2WHALGA54MDvExmUiIg0nzoTQTghzSJ33wU8aWYLgUx3390cwYmISOLV2TXk7hXAr6o9368kICLStsQzRvCcmX3HKq8bFRGRNiWeMYKrgRwgZmYlBJeQurt3TGhkIiLSLOK5s7hDcwQiIiLJUW8iMLPTa1p/8EQ1IiLSOsXTNXRtteVM4GRgGXBWQiISEZFmFU/X0DerPzezo4FfJiwiERFpVvFcNXSwDcDgpg5ERESSI54xgt8Q3E0MQeLIA95LYEwiItKM4hkjWFptOQY86u5vJCgeERFpZvEkggVAibuXA5hZxMyy3b0osaGJiEhziGeMYBGQVe15FvBCYsIREZHmFk8iyHT3vZVPwuXseA5uZjPMbJWZrTSzR80ss9pr15iZm1mXhoctIiJNJZ5EsM/MTqh8YmYnAsX17WRmPYArgHx3HwxEgInha0cDY4FPGxO0iIg0nXjGCK4CnjCzz8Pn3Qimroz3+FlmVkbQiqg8xh3AdcAz8YcqIiKJEM8NZe+Y2QCgP0HBuTXuXhbHfhvNbDbBt/5i4Dl3f87MzgU2uvt7dRU0NbNLgUsBjjnmmLjejIiINFw8k9f/AMhx95XuvgJob2bfj2O/TsB4gmktuwM5ZjYF+DFwU337u/v97p7v7vldu3atb3MREWmkeMYILglnKAPA3XcCl8Sx39nAJ+6+NWxBPAVcRJAY3jOzdUBPYLmZHdXQwEVEpGnEM0aQZmbm7g7BfQRARhz7fQqcYmbZBF1DY4Cn3P3Myg3CZJDv7tsaHLmIiDSJeBLB34HHzew+glIT04Fn69vJ3ZeY2QKCCe9jwLvA/YcQq4iIJICFX/Rr3yCYwP5Sgq4eA54Dfh/OZ9ws8vPzfenSpfVvKCIiVcxsmbvn17ddvWME7l7h7ve5+3nu/h1gFfCbpghSRESSL56uIcwsD5hEcP/AJwQDvyIi0gbUmgjM7DiCO4EnAduB+QRdSWfWto+IiLQ+dbUI1gCvAd90948gqB3ULFGJiEizqWuM4DvAZuAlM/u9mY0hGCwWEZE2pNZE4O5Pu/t3gQHAy8AM4Egzu9fMzmmm+EREJMHiuWpon7vPc/dxBHcCFwDXJzowERFpHg2avN7dd7j779z9rEQFJCIizatBiUBERNoeJQIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ4JQIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ4JQIRkRSnRCAikuKUCEREUpwSgYhIilMiEBFJcUoEIiIpTolARCTFKRGIiKQ4JQIRkRSX0ERgZjPMbJWZrTSzR80s08xmmdkaM3vfzJ42s8MSGYOIiNQtYYnAzHoAVwD57j4YiAATgeeBwe4+FPgncEOiYhARkfolumsoCmSZWRTIBj539+fcPRa+vhjomeAYRESkDglLBO6+EZgNfApsAna7+3MHbXYx8P9q2t/MLjWzpWa2dOvWrYkKU0Qk5SWya6gTMB7oDXQHcszswmqv/xiIAfNq2t/d73f3fHfP79q1a6LCFBFJeYnsGjob+MTdt7p7GfAUMBLAzKYC44DJ7u4JjEFEROqRyETwKXCKmWWbmQFjgNVm9jXgR8C57l6UwPOLiEgcook6sLsvMbMFwHKCLqB3gfuBVUA74PkgP7DY3acnKg4REalbwhIBgLvPBGYetPrYRJ5TREQaRncWi4ikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKU6JQEQkxSkRiIikOCUCEZEUp0QgIpLiEpoIzGyGma0ys5Vm9qiZZZrZ4Wb2vJl9GP7slMgYRESkbglLBGbWA7gCyHf3wUAEmAhcDyxy937AovC5iIgkSaK7hqJAlplFgWzgc2A8MDd8fS7wrQTHICIidYgm6sDuvtHMZgOfAsXAc+7+nJkd6e6bwm02mdkRNe1vZpcCl4ZP95vZykTF2oS6ANuSHUQcFGfTaQ0xguJsaq0lzv7xbJSwRBD2/Y8HegO7gCfM7MJ493f3+4H7w2Mtdff8RMTZlBRn02oNcbaGGEFxNrXWFGc82yWya+hs4BN33+ruZcBTwEjgCzPrBhD+3JLAGEREpB6JTASfAqeYWbaZGTAGWA38BZgabjMVeCaBMYiISD0SOUawxMwWAMuBGPAuQVdPe+BxM/seQbI4P47D3Z+oOJuY4mxarSHO1hAjKM6m1qbiNHdPdCAiItKC6c5iEZEUp0QgIpLiWnQiMLM/mNmWlnwPgZkdbWYvmdnqsJzGlcmOqSZheY+3zey9MM5bkh1TXcwsYmbvmtnCZMdSGzNbZ2YrzKwg3sv0ksHMDjOzBWa2Jvx3emqyYzqYmfUPf4+Vjz1mdlWy4zpYTWVzkh1TTczsyjDGVfH8Hlv0GIGZnQ7sBR4Oy1S0OOElsN3cfbmZdQCWAd9y938kObQDhFdu5bj7XjNLB14HrnT3xUkOrUZmdjWQD3R093HJjqcmZraOoIRKi76xyMzmAq+5+wNmlgFku/uuJIdVKzOLABuBEe6+PtnxVArL5rwODHT3YjN7HPhfd38ouZEdyMwGA48BJwOlwLPAZe7+YW37tOgWgbu/CuxIdhx1cfdN7r48XC4kuES2R3Kj+jIP7A2fpoePFvktwMx6At8AHkh2LK2dmXUETgfmALh7aUtOAqExwNqWlASqqalsTktzPLDY3YvcPQa8Any7rh1adCJobcysFzAcWJLkUGoUdrcUENzE97y7t8g4gTuB64CKJMdRHweeM7NlYUmUlqgPsBV4MOxqe8DMcpIdVD0mAo8mO4iDuftGoLJsziZgt7s/l9yoarQSON3MOptZNvDvwNF17aBE0ETMrD3wJHCVu+9Jdjw1cfdyd88DegInh03IFsXMxgFb3H1ZsmOJwyh3PwH4OvCDsCuzpYkCJwD3uvtwYB8tuOJv2HV1LvBEsmM52EFlc7oDOQ0pm9Nc3H018N/A8wTdQu8R3MtVKyWCJhD2uT8JzHP3p5IdT33CroGXga8lN5IajQLODfvfHwPOMrNHkhtSzdz98/DnFuBpgj7ZlmYDsKFa628BQWJoqb4OLHf3L5IdSA1qK5vT4rj7HHc/wd1PJ+her3V8AJQIDlk4CDsHWO3uv052PLUxs65mdli4nEXwj3pNUoOqgbvf4O493b0XQRfBi+7e4r51mVlOeHEAYVfLOQRN8hbF3TcDn5lZZRXKMUCLupDhIJNogd1CodrK5rQ4lVWdzewYYAL1/E4TVmKiKZjZo8BooIuZbQBmuvuc5Eb1JaOA/wBWhP3vADe6+/8mL6QadQPmhldkpAGPu3uLvTSzFTgSeDr4PCAK/Mndn01uSLW6HJgXdrt8DFyU5HhqFPZnjwX+K9mx1KSOsjkt0ZNm1hkoA37g7jvr2rhFXz4qIiKJp64hEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBNLszOzbZuZmNiDZsdQnrDDapZ5tbmyueGo4d5aZvRJeFnwoxxliZg81UVjSyigRSDJMIqjiOLEpDnaoH4JNIGmJALgYeMrdyw/lIO6+AugZ3oAkKUaJQJpVWJNpFPA9wkRgZl8PS/pWbjPazP4aLp9jZm+Z2XIzeyLcv/Kb+k1m9jpwvpldYmbvhPMtPBnenISZ9TWzxeFrt5rZ3mrnuTZc/77FMT+Dmf05LDC3qrLInJndTlCNssDM5oXrLrRg7ocCM/tdZaIys71m9vMwxsVmdmS4/kgzezpc/56ZjTSzn1m1uS3C/a6oIazJwDPVfm+vmNnjZvZPM7vdzCaHsawws77hdudbUKv+PTN7tdqx/koTJWdpZdxdDz2a7QFcCMwJl98kqHsTJbh9Pydcf2+4XRfg1WrrfwTcFC6vA66rdtzO1ZZvAy4PlxcCk8Ll6cDecPkcgrtCjeAL0ULg9BriXQd0CZcPD39mEZST6Bw+31tt++MJPlDTw+e/BaaEyw58M1z+JfCTcHk+QbFCgAiQC/QiqLlDGN/a6u8xXJ8BbK72fDSwi+Au8nYENf1vCV+7ErgzXF4B9AiXD6u2/yjgr8n+N6JH8z/UIpDmNomgmBzhz0ke1Ex/FvimBXXev0HwLfcUYCDwRli+YyrwlWrHml9tebCZvWZmKwi+JQ8K15/KvypZ/qna9ueEj3cJSgYMAPrVE/sVZvYesJigrG9N248BTgTeCWMeQ1AKGoJJQirLeiwj+LAHOIsg+eFBhdjd7r4O2G5mwyvjdPftB52rC8EHf3XveDBHxn6C5FFZJnlFtfO9ATxkZpcQJJ5KWwiqakqKadG1hqRtCWufnEXwoe0EH0JuZtcRfKj/gKBS4jvuXhgW9nre3SfVcsh91ZYfIpgZ7j0zm0bw7bjOcIBfuPvv4ox9NEGhvlPdvcjMXgZqmqbQgLnufkMNr5W5e2VNl3Lq///3ADANOAr4Qw2vF9cQw/5qyxXVnldUns/dp5vZCIKEW2BmeWGSyQyPKSlGLQJpTucRTDv6FXfv5e5HA58A/0ZQFvsE4BL+9U1/MTDKzI6FoCiZmR1Xy7E7AJssKAk+udr6xcB3wuXq/d9/By6uNubQo7JiYy1ygZ1hEhhA0FqpVBaeF2ARcF616o+Hm9lXqNsi4LJw+4gFs4pBUNr6a8BJYbwH8KCQWMQaOG+umfV19yXufhOwjX9NWnIcLbCCqiSeEoE0p0kEH27VPQlc4MFVLwsJ6tEvBHD3rQTfiB81s/cJPtRru+T0pwQzwz3PgeW1rwKuNrO3CfrOd4fHfo6gq+itsDtpAUEyqc2zQDSM42dhLJXuB943s3kezFX9E4KZy94P4+lWx3Eh6L8/M4xjGWG3lruXAi8RVIqt7aqg5wgSaUPMCgePVxKMwbwXrj8T+FsDjyVtgKqPSpsWXj1U7O5uZhMJxiTGJzuueJhZGsH4xfley8Tj4RjC1e7+H4d4rnYEc9v+WzhmIylEYwTS1p0I3B2ON+wiuO6+xTOzgQQto6drSwIA7v6umb1kZpE6Wg3xOAa4XkkgNalFICKS4jRGICKS4pQIRERSnBKBiEiKUyIQEUlxSgQiIinu/wMPOzN/nthbOgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime.quantization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39monnxruntime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m quantize_dynamic, QuantType\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/onnx/model.onnx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/onnx/model.quant.onnx\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime.quantization'"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_input = \"data/onnx/model.onnx\"\n",
    "model_output = \"data/onnx/model.quant.onnx\"\n",
    "quantize_dynamic(model_input, model_output, weight_type=QuantType.QInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 64.22\n",
      "Average latency (ms) - 5.92 +\\- 0.49\n",
      "Accuracy on test set - 0.885\n"
     ]
    }
   ],
   "source": [
    "onnx_quantized_model = create_model_for_provider(model_output)\n",
    "pipe = OnnxPipeline(onnx_quantized_model, tokenizer)\n",
    "optim_type = \"Distillation + ORT (quantized)\"\n",
    "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type, model_path=model_output)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "batch_size = 48\n",
    "\n",
    "finetuned_ckpt = \"distilbert-base-uncased-tensorrt-clinc\"\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=f\"data/{finetuned_ckpt}\", evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=5, learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, alpha=1,\n",
    "    report_to=\"none\", weight_decay=0.01, save_strategy=\"epoch\",\n",
    "    torchdynamo=\"fx2trt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/guhangsong/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Torchdynamo is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb Cell 70\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tensorrt_trainer \u001b[39m=\u001b[39m DistillationTrainer(model_init\u001b[39m=\u001b[39;49mstudent_init,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     teacher_model\u001b[39m=\u001b[39;49mteacher_model, args\u001b[39m=\u001b[39;49mstudent_training_args,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mclinc_enc[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], eval_dataset\u001b[39m=\u001b[39;49mclinc_enc[\u001b[39m'\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics, tokenizer\u001b[39m=\u001b[39;49mstudent_tokenizer)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m tensorrt_trainer\u001b[39m.\u001b[39mtrain()\n",
      "\u001b[1;32m/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb Cell 70\u001b[0m in \u001b[0;36mDistillationTrainer.__init__\u001b[0;34m(self, teacher_model, *args, **kwargs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, teacher_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/guhangsong/Documents/Notebook/tech/nlp/transformers/efficience.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mteacher_model \u001b[39m=\u001b[39m teacher_model\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:635\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mtorchdynamo:\n\u001b[1;32m    634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torchdynamo_available():\n\u001b[0;32m--> 635\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorchdynamo is not installed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    636\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorchdynamo\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdynamo\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizations\u001b[39;00m \u001b[39mimport\u001b[39;00m backends\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Torchdynamo is not installed."
     ]
    }
   ],
   "source": [
    "tensorrt_trainer = DistillationTrainer(model_init=student_init,\n",
    "    teacher_model=teacher_model, args=student_training_args,\n",
    "    train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
    "    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "tensorrt_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87998d4b2a08f200e53bd85c2d7b01bf2b69127f748e5c1e9a18138bae014c82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
